# Exploring data #1

[Download](https://github.com/geanders/RProgrammingForResearch/raw/master/slides/CourseNotes_Week3.pdf) a pdf of the lecture slides covering this topic.

## Data from a package

So far we've covered three ways to get data into R:

1. From flat files (either on your computer or online)
2. From files like SAS and Excel
3. From R objects (i.e., using `load()`)

Many R packages come with their own data, which is very easy to load and use. For example, the `faraway` package, which complements Julian Faraway's book *Linear Models with R* (available as an ebook from the CSU library), has a dataset called `worldcup` that I'll use for some examples and that you'll use for part of this week's in-course exercise. To load this dataset, first load the package with the data (`faraway`) and then use the `data()` function with the dataset name ("worldcup") as the argument to the `data` function:

```{r}
library(faraway)
data("worldcup")
```

Unlike most data objects you'll work with, datasets that are part of an R package will often have their own help files. You can access this help file for a dataset using the `?` operator with the dataset's name:

```{r, eval = FALSE}
?worldcup
```

This helpful will usually include information about the size of the dataset, as well as definitions for each of the columns.

To get a list of all of the datasets that are available in the packages you currently have loaded, run `data()` without an option inside the parentheses:

```{r, eval = FALSE}
data()
```

```{block, type = "rmdnote"}
If you run the `library` function without any arguments (`library()`), it works in a similar way-- R will open a list of all the R packages that you have installed on your computer and can open with a `library` call. 
```

## Plots to explore data

Exploratory data analysis is a key step in data analysis, and plotting your data in different ways is an important part of this process. In this section, I will focus on the basics of `ggplot2` plotting, to get you started creating some plots to explore your data. 
This section will focus on making **useful**, rather than **attractive** graphs, since at this stage we are focusing on exploring data for yourself rather than presenting results  to others. Next week, I will explain more about how you can customize ggplot objects, to help you make plots to communicate with others.  


All of the plots we'll make today will use the `ggplot2` package (another member of the tidyverse!). If you don't already have that installed, you'll need to install it. You then need to load the package in your current session of R:

```{r}
# install.packages("ggplot2")  ## Uncomment and run if you don't have `ggplot2` installed
library(ggplot2)
```

The process of creating a plot using `ggplot2` follows conventions that are a bit different than most of the code you've seen so far in R (although it is somewhat similar to the idea of piping I introduced in the last chapter). The basic steps behind creating a plot with `ggplot2` are:

1. Create an object of the `ggplot` class, typically specifying the **data** and some or all of the **aesthetics**; 
2. Add on **geoms** and other elements to create and customize the plot, using `+`.

You can add on one or many geoms and other elements to create plots that range from very simple to very customized. This week, we'll focus on simple geoms and added elements, and then explore more detailed customization next week. 

```{block type = "rmdwarning"}
If R gets to the end of a line and there is not some indication that the call is not over (e.g., `%>%` for piping or `+` for `ggplot2` plots), R interprets that as a message to run the call without reading in further code. A common error when writing `ggplot2` code is to put the `+` to add a geom or element at the beginning of a line rather than the end of a previous line-- in this case, R will try to execute the call too soon. To avoid errors, be sure to end lines with `+`, don't start lines with it. 
```

### Initializing a ggplot object

The first step in creating a plot using `ggplot2` is to create a ggplot object. This object will not, by itself, create a plot with anything in it. Instead, it typically specifies the data frame you want to use and which aesthetics will be mapped to certain columns of that data frame (aesthetics are explained more in the next subsection). 

Use the following conventions to initialize a ggplot object:

```{r, eval = FALSE}
## Generic code
object <- ggplot(dataframe, aes(x = column_1, y = column_2))
```

The data frame is the first parameter in a `ggplot` call and, if you like, you can use the parameter definition with that call (e.g., `data = dataframe`). Aesthetics are defined within an `aes` function call that typically is used within the `ggplot` call. 

```{block type = "rmdnote"}
While the `ggplot` call is the place where you will most often see an `aes` call, `aes` can also be used within the calls to add specific geoms. This can be particularly useful if you want to map aesthetics differently for different geoms in your plot. We'll see some examples of this use of `aes` more in later sections, when we talk about customizing plots. The `data` parameter can also be used in geom calls, to use a different data frame from the one defined when creating the original ggplot object, although this tends to be less common. 
```

### Plot aesthetics

**Aesthetics** are properties of the plot that can show certain elements of the data. For example, in Figure \@ref(fig:aesmapex), color shows (is mapped to) gender, x-position shows height, and y-position shows weight in a sample data set of measurements of children in Nepal. 

```{r aesmapex, echo = FALSE, warning = FALSE, fig.width = 6, fig.height = 4, fig.align = "center", message = FALSE, fig.cap = "Example of how different properties of a plot can show different elements to the data. Here, color indicates gender, position along the x-axis shows height, and position along the y-axis shows weight. This example is a subset of data from the `nepali` dataset in the `faraway` package."}
library(dplyr)
data("nepali") 
nepali %>%
  tbl_df() %>% 
  distinct(id, .keep_all = TRUE) %>%
  mutate(sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female"))) %>%
  ggplot(aes(x = ht, y = wt, color = sex)) + 
  geom_point() + 
  xlab("Height (cm)") + ylab("Weight (kg)")
```

```{block type = "rmdnote"}
Any of these aesthetics could also be given a constant value, instead of being mapped to an element of the data. For example, all the points could be red, instead of showing gender.
```

Which aesthetics are required for a plot depend on which geoms (more on those in a second) you're adding to the plot. You can find out the aesthetics you can use for a geom in the "Aesthetics" section of the geom's help file (e.g., `?geom_point`). Required aesthetics are in bold in this section of the help file and optional ones are not. Common plot aesthetics you might want to specify include: 

```{r echo = FALSE}
aes_vals <- data.frame(aes = c("`x`", "`y`", "`shape`",
                               "`color`", "`fill`", "`size`",
                               "`alpha`", "`linetype`"),
                       desc = c("Position on x-axis", 
                                "Position on y-axis", 
                                "Shape",
                                "Color of border of elements", 
                                "Color of inside of elements",
                                "Size", 
                                "Transparency (1: opaque; 0: transparent)",
                                "Type of line (e.g., solid, dashed)"))
knitr::kable(aes_vals, col.names = c("Code", "Description"))
```

### Adding geoms

Next, you'll want to add one or more `geoms` to create the plot. You can add these with `+` after the `ggplot` statement to initialize the ggplot object. Some of the most common geoms are:

```{r echo = FALSE}
plot_funcs <- data.frame(type = c("Histogram (1 numeric variable)",
                                  "Scatterplot (2 numeric variables)",
                                  "Boxplot (1 numeric variable, possibly 1 factor variable)",
                                  "Line graph (2 numeric variables)"), 
                         ggplot2_func = c("`geom_histogram`",
                                          "`geom_point`",
                                          "`geom_boxplot`",
                                          "`geom_line`"))
knitr::kable(plot_funcs, col.names = c("Plot type",
                                       "ggplot2 function"))
```

### Constant aesthetics

Instead of mapping an aesthetic to an element of your data, you can use a constant value for it. For example, you may want to make all the points green, rather than having color map to gender: 

```{r echo = FALSE, warning = FALSE, fig.align = "center", out.width = "0.6\\textwidth", message = FALSE, fig.width = 5, fig.height = 3}
nepali %>%
  tbl_df() %>% 
  distinct(id, .keep_all = TRUE) %>%
  mutate(sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female"))) %>%
  ggplot(aes(x = ht, y = wt)) + 
  geom_point(color = "darkgreen") + 
  xlab("Height (cm)") + ylab("Weight (kg)")
```

In this case, you'll define that aesthetic when you add the geom, outside of an `aes` statement. In R, you can specify the shape of points with a number. Figure \@ref(fig:shapeexamples) shows the shapes that correspond to the numbers 1 to 25 in the `shape` aesthetic. This figure also provides an example of the difference between color (black for all these example points) and fill (red for these examples). You can see that some point shapes include a fill (21 for example), while some are either empty (1) or solid (19).

```{r shapeexamples, echo = FALSE, fig.width = 5, fig.height = 3, fig.align = "center", fig.cap = "Examples of the shapes corresponding to different numeric choices for the `shape` aesthetic. For all examples, `color` is set to black and `fill` to red."}
x <- rep(1:5, 5)
y <- rep(1:5, each = 5)
shape <- 1:25
to_plot <- data_frame(x = x, y = y, shape = shape)
ggplot(to_plot, aes(x = x, y = y)) + 
  geom_point(shape = shape, size = 4, color = "black", fill = "red") + 
  geom_text(label = shape, nudge_x = -0.25) +
  xlim(c(0.5, 5.5)) + 
  theme_void() + 
  scale_y_reverse()
```

If you want to set color to be a constant value, you can do that in R using character strings for different colors. Figure \@ref(fig:colorexamples) gives an example of some of the different blues available in R. To find links to listings of different R colors, google "R colors" and search by "Images".

```{r colorexamples, echo = FALSE, fig.width = 5, fig.height = 3, fig.align = "center", fig.cap = "Example of available shades of blue in R."}
x <- rep(0, 6)
y <- 1:6
color <- c("blue", "blue4", "darkorchid", "deepskyblue2", 
           "steelblue1", "dodgerblue3")
to_plot <- data_frame(x = x, y = y, color = color)
ggplot(to_plot, aes(x = x, y = y)) + 
  geom_point(color = color, size = 2) + 
  geom_text(label = color, hjust = 0, nudge_x = 0.05) + 
  theme_void() + 
  xlim(c(-1, 1.5)) +
  scale_y_reverse()
```

### Useful plot additions

There are also a number of elements that you can add onto a `ggplot` object using `+`. A few that are used very frequently are: 

```{r echo = FALSE}
plot_adds <- data.frame(add = c("`ggtitle`",
                                "`xlab`, `ylab`",
                                "`xlim`, `ylim`"),
                        descrip = c("Plot title",
                                    "x- and y-axis labels",
                                    "Limits of x- and y-axis"))
knitr::kable(plot_adds, col.names = c("Element", "Description"))
```

### Example dataset

For the example plots, I'll use a dataset in the `faraway` package called `nepali`. This gives data from a study of the health of a group of Nepalese children. 

```{r}
library(faraway)
data(nepali)
```

I'll be using functions from `dplyr` and `ggplot2`, so those need to be loaded:

```{r message = FALSE, warning = FALSE}
library(dplyr)
library(ggplot2)
```

Each observation is a single measurement for a child; there can be multiple observations per child. I used the following code to select only the columns for child id, sex, weight, height, and age. I also used `distinct` to limit the dataset to only include one measurement for each chile, the child's first measurement in the dataset. 

```{r message = FALSE}
nepali <- nepali %>%
  select(id, sex, wt, ht, age) %>%
  mutate(id = factor(id),
         sex = factor(sex, levels = c(1, 2),
                      labels = c("Male", "Female"))) %>%
  distinct(id, .keep_all = TRUE)
```

After this cleaning, the data looks like this:

```{r}
head(nepali)
```

### Histograms

Histograms show the distribution of a single variable. Therefore, `geom_histogram()` requires only one main aesthetic, `x`, the (numeric) vector for which you want to create a histogram. For example, to create a histogram of children's heights for the Nepali dataset (Figure \@ref(fig:nepalihist1)), run: 

```{r, nepalihist1, fig.width = 4, fig.height = 3, message = FALSE, warning = FALSE, fig.align = "center", fig.cap = "Basic example of plotting a histogram with `ggplot2`. This histogram shows the distribution of heights for the first recorded measurements of each child in the `nepali` dataset."}
ggplot(nepali, aes(x = ht)) + 
  geom_histogram()
```

```{block type = "rmdnote"}
If you run the code with no arguments for `binwidth` or `bins` in `geom_histogram`, you will get a message saying "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.". This message is just saying that a default number of bins was used to create the histogram. You can use arguments to change the number of bins used, but often this default is fine. You may also get a message that observations with missing values were removed. 
```

You can add some elements to the histogram now to customize it a bit. For example (Figure \@ref()), you can add a figure title (`ggtitle`) and clearer labels for the x-axis (`xlab`). You can also change the range of values shown by the x-axis (`xlim`).

```{r, nepalihist2, fig.width = 4, fig.height = 3, fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Example of adding ggplot elements to customize a histogram."}
ggplot(nepali, aes(x = ht)) + 
  geom_histogram(fill = "lightblue", color = "black") + 
  ggtitle("Height of children") + 
  xlab("Height (cm)") + xlim(c(0, 120))
```

The geom `geom_histogram` also has special argument for setting the number of width of the bins used in the histogram. Figure \@ref(fig) shows an example of how you can use the `bins` argument to change the number of bins that are used to make the histogram of height for the `nepali` dataset.  

```{r, nepalihist3, fig.width = 4, fig.height = 3, fig.align = "center", warning = FALSE, message = FALSE, fig.cap = "Example of using the `bins` argument to change the number of bins used in a histogram."}
ggplot(nepali, aes(x = ht)) + 
  geom_histogram(fill = "lightblue", color = "black",
                 bins = 40) 
```

Similarly, the `binwidth` argument can be used to set the width of bins. Figure \@ref(fig:nepalihist4) shows an example of using this function to create a histogram of the Nepali children's heights with binwidths of 10 centimeters (note that this argument is set in the same units as the x variable).

```{r, nepalihist4, fig.width = 4, fig.height = 3, fig.align = "center", warning = FALSE, message = FALSE, fig.cap = "Example of using the `binwidth` argument to set the width of each bin used in a histogram."}
ggplot(nepali, aes(x = ht)) + 
  geom_histogram(fill = "lightblue", color = "black",
                 binwidth = 10) 
```

### Scatterplots

A scatterplot shows how one variable changes as another changes. You can use the `geom_point` geom to create a scatterplot. For example, to create a scatterplot of height versus age for the Nepali data (Figure \@ref(fig:nepaliscatter1)), you can run the following code: 

```{r nepaliscatter1, fig.width = 5, fig.height = 4, warning = FALSE, fig.align = "center", fig.cap = "Example of using `geom_point` to create a scatterplot. This scatterplot shows the relationship between children's heights and weights within the `nepali` dataset."}
ggplot(nepali, aes(x = ht, y = wt)) + 
  geom_point()
```

Again, you can use some of the options and additions to change the plot appearance. For example, to add a title, change the x- and y-axis labels, and change the color and size of the points on the scatterplot (Figure \@ref(fig:nepaliscatter2)), you can run:

```{r nepaliscatter2, fig.width = 5, fig.height = 4, fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Example of adding ggplot elements to customize a scatterplot."}
ggplot(nepali, aes(x = ht, y = wt)) + 
  geom_point(color = "blue", size = 0.5) + 
  ggtitle("Weight versus Height") + 
  xlab("Height (cm)") + ylab("Weight (kg)")
```

You can also try mapping another variable in the dataset to the `color` aesthetic. For example, to use color to show the sex of each child in the scatterplot (Figure \@ref(fig:nepaliscatter3)), you can run:

```{r nepaliscatter3, fig.width = 5, fig.height = 4, fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Example of mapping color to an element of the data in a scatterplot."}
ggplot(nepali, aes(x = ht, y = wt, color = sex)) + 
  geom_point(size = 0.5) + 
  ggtitle("Weight versus Height") + 
  xlab("Height (cm)") + ylab("Weight (kg)")
```

### Boxplots 

Boxplots can be used to show the distribution of a continuous variable. To create a boxplot, you can use the `geom_boxplot` geom. To plot a boxplot for a single, continuous variable, you can map that variable to `y` in the `aes` call, and map `x` to the constant `1`. For example, to create a boxplot of the heights of children in the Nepali dataset (Figure \@ref(fig:nepaliboxplot1)), you can run:

```{r nepaliboxplot1, fig.height = 4, fig.width = 4, warning = FALSE, fig.align="center", fig.cap = "Example of creating a boxplot with `geom_boxplot`. The example shows the distribution of height data for children in the `nepali` dataset."}
ggplot(nepali, aes(x = 1, y = ht)) + 
  geom_boxplot() + 
  xlab("")+ ylab("Height (cm)")
```

You can also create separate boxplots, one for each level of a factor (Figure \@ref(fig:nepaliboxplot2)). In this case, you'll need to include two aesthetics (`x` and `y`) when you initialize the ggplot object The `y` variable is the variable for which the distribution will be shown, and the `x` variable should be a discrete (categorical or TRUE/FALSE) variable, and will be used to group the variable. This `x` variable should also be specified as the grouping variable, using `group` within the aesthetic call.

```{r nepaliboxplot2, fig.height = 4, fig.width = 5, fig.align = "center", warning = FALSE, fig.cap = "Example of creating separate boxplots, divided by a categorical grouping variable in the data."}
ggplot(nepali, aes(x = sex, y = ht, group = sex)) + 
  geom_boxplot() + 
  xlab("Sex")+ ylab("Height (cm)") 
```

### Extensions of `ggplot2`

There are lots of R extensions for creating other interesting plots. For example, you can use the `ggpairs` function from the `GGally` package to plot all pairs of scatterplots for several variables (Figure \@ref(fig:ggallyexample)). 

```{r ggallyexample, out.width = "\\textwidth", fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Example of using `ggpairs` from the `GGally` package for exploratory data analysis."}
library(GGally)
ggpairs(nepali %>% select(sex, wt, ht, age))
```

Notice how this output shows continuous and binary variables differently. For example, the center diagonal shows density plots for continuous variables, but a bar chart for the categorical variable. 

See https://www.ggplot2-exts.org to find more `ggplot2` extensions.

## Simple statistics functions

### Summary statistics

To explore your data, you'll need to be able to calculate some simple statistics for vectors, including calculating the mean and range of continuous variables and counting the number of values in each category of a factor or logical vector. 

Here are some simple statistics functions you will likely use often:

Function  | Description
--------- | -----------------
`range()` | Range (minimum and maximum) of vector 
`min()`, `max()` | Minimum or maximum of vector
`mean()`, `median()` | Mean or median of vector
`sd()` | Standard deviation of vector
`table()` | Number of observations per level for a factor vector
`cor()` | Determine correlation(s) between two or more vectors
`summary()` | Summary statistics, depends on class

All of these functions take, as the main argument, the vector or vectors for which you want the statistic. If there are missing values in the vector, you'll typically need to add an argument to say what to do with the missing values. The parameter name for this varies by function, but for many of these functions it's `na.rm = TRUE` or `use="complete.obs"`.

```{r}
mean(nepali$wt, na.rm = TRUE)
range(nepali$ht, na.rm = TRUE)
sd(nepali$ht, na.rm = TRUE)
table(nepali$sex)
```

Most of these functions take a single vector as the input. The `cor` function, however, calculates the correlation between vectors and so takes two or more vectors. If you give it multiple values, it will give the correlation matrix for all the vectors.

```{r}
cor(nepali$wt, nepali$ht, use = "complete.obs")
cor((nepali %>% select(wt, ht, age)), use = "complete.obs")
```

R supports object-oriented programming. Your first taste of this shows up with the `summary` function. For the `summary` function, R does not run the same code every time. Instead, R first checks what type of object was input to `summary`, and then it runs a function (*method*) specific to that type of object. For example, if you input a continuous vector, like the `ht` column in `nepali`, to `summary`, the function will return the mean, median, range, and 25th and 75th percentile values: 

```{r}
summary(nepali$wt)
```

However, if you submit a factor vector, like the `sex` column in `nepali`, the `summary` function will return a count of how many elements of the vector are in each factor level (as a note, you could do the same thing with the `table` function):

```{r}
summary(nepali$sex)
```

The `summary` function can also input other data structures, including dataframes, lists, and special object types, like regression model objects. In each case, it performs different actions specific to the object type. Later in this section, we'll cover regression models, and see what the `summary` function returns when it is used with regression model objects.

### `summarize` function

You will often want to use these functions in conjunction with the `summarize` function in `dplyr`. For example, to create a new dataframe with the mean weight of children in the `nepali` dataset, you can use `mean` inside a `summarize` function: 

```{r}
nepali %>%
  summarize(mean_wt = mean(wt, na.rm = TRUE))
```

There are also some special functions that you can use with `summarize`. For example, the `n` function will calculate the number of observations and the `first` function will return the first value of a column: 

```{r}
nepali %>%
  summarize(n_children =n(), 
            first_id = first(id))
```

See the "summary function" section of the [the RStudio Data Wrangling cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) for more examples of these special functions. 

Often, you will be more interested in summaries within certain groupings of your data, rather than overall summaries. For example, you may be interested in mean height and weight by sex, rather than across all children, for the `nepali` data. It is very easy to calculate these grouped summaries using `dplyr`-- you just need to group data using the `group_by` function (also a `dplyr` function) before you run the `summarize` function:

```{r}
nepali %>%
  group_by(sex) %>%
  summarize(mean_wt = mean(wt, na.rm = TRUE),
            n_children =n(), 
            first_id = first(id))
```

```{block, type = "rmdnote"}
Don't forget that you need to save the output to a new object if you want to use it later. The above code, which creates a dataframe with summaries for Nepali children by sex, will only be printed out to your console if run as-is. If you'd like to save this output as an object to use later (for example, for a plot or table), you need to assign it to an R object. 
```

## Logical vectors

Last week, you learned a lot about logical statements and how to use them with the `filter` function. You can also use logical vectors, created with these logical statements, for a lot of other things. For example, you can use them directly in the square bracket indexing (`[..., ...]`) to pull out just the rows of a dataframe that meet a certain condition.

When you run a logical statement on a vector, you create a logical vector the same length as the original vector:

```{r}
is_male <- nepali$sex == "Male"
length(nepali$sex)
length(is_male)
```

The logical vector (`is_male` in this example) will have the value `TRUE` at any position where the original vector (`nepali$sex` in this example) met the logical condition you tested, and `FALSE` anywhere else:

```{r}
head(nepali$sex)
head(is_male)
```

You can "flip" this logical vector (i.e., change every `TRUE` to `FALSE` and vice-versa) using the *bang operator*, `!`:

```{r}
head(is_male)
head(!is_male)
```

The bang operator turns out to be very useful. You will often find cases where it's difficult to write a logical vector to get what you want, but fairly easy to write the inverse (find everything you don't want). One example is filtering down to non-missing values-- the `is.na` function will return `TRUE` for any value that is `NA`, so you can use `!is.na()` to identify any non-missing values. 

You can do a few cool things with a logical vector. For example, you can use it with indexing to pull out just the rows of a dataframe where `is_male` is `TRUE`:

```{r}
head(nepali[is_male, ])
```

Or, with `!`, just the rows where `is_male` is `FALSE`:

```{r}
head(nepali[!is_male, ])
```

For these cases, the length of the logical vector and the number of rows in the dataframe will match. 

You can also use `sum()` and `table()` with a logical vector to find out how many of the values in the vector are `TRUE` AND `FALSE`. In the example, you can use these functions to find out how many males and females are in the dataset:

```{r}
sum(is_male)
sum(!is_male)
table(is_male)
```

Note that you could also achieve the same thing with `dplyr` functions. For example, you could use `mutate` with a logical statement to create an `is_male` column in the `nepali` dataframe, then group by the new `is_male` column and summarize, using the `n` function to count the number of observations in each group:

```{r}
nepali %>%
  mutate(is_male = sex == "Male") %>%
  group_by(is_male) %>%
  summarize(n_children = n())
```

## Regression models 

### Formula structure

*Regression models* can be used to estimate how the expected value of a *dependent variable* changes as *independent variables* change. \medskip

In R, regression formulas take this structure:

```{r eval = FALSE}
## Generic code
[response variable] ~ [indep. var. 1] +  [indep. var. 2] + ...
```

Notice that a tilde, `~`, is used to separate the independent and dependent variables and that a plus sign, `+`, is used to join independent variables. This format mimics the statistical notation:

$$
Y_i \sim X_1 + X_2 + X_3
$$

You will use this type of structure in R fo a lot of different function calls, including those for linear models (ift with the `lm` function) and generalized linear models (fit with the `glm` function).

There are some conventions that can be used in R formulas. Common ones include: 

```{r echo = FALSE}
for_convs <- data.frame(Convention = c("`I()`", "`:`", "`*`", "`.`",
                                       "`-`", "`1`"),
                        Meaning = c("calculate the value inside before fitting (e.g., `I(x1 + x2)`)",
                                    "fit the interaction between two variables (e.g., `x1:x2`)",
                                    "fit the main effects and interaction for both variables (e.g., `x1*x2` equals `x1 + x2 + x1:x2`)",
                                    "fit all variables other than the response (e.g., `y ~ .`)",
                                    "do not include a variable (e.g., `y ~ . - x1`)",
                                    "intercept (e.g., `y ~ 1` for an intercept-only model)"))
pander::pander(for_convs, split.cells = c(1,1,58),
               justify = c("center", "left"))
```

### Linear models

To fit a linear model, you can use the function `lm()`. This function is part of the `stats` package, which comes installed with base R. In this function, you can use the `data` option to specify the dataframe from which to get the vectors. 

```{r}
mod_a <- lm(wt ~ ht, data = nepali)
```

This previous call fits the model:

$$ Y_{i} = \beta_{0} + \beta_{1}X_{1,i} + \epsilon_{i} $$

where: 

- $Y_{i}$ : weight of child $i$
- $X_{1,i}$ : height of child $i$


If you run the `lm` function without saving it as an object, R will fit the regression and print out the function call and the estimated model coefficients: 

```{r}
lm(wt ~ ht, data = nepali)
```

However, to be able to use the model later for things like predictions and model assessments, you should save the output of the function as an R object: 

```{r}
mod_a <- lm(wt ~ ht, data = nepali)
```

This object has a special class, `lm`: 

```{r}
class(mod_a)
```

This class is a special type of list object. If you use `is.list` to check, you can confirm that this object is a list: 

```{r}
is.list(mod_a)
```

There are a number of functions that you can apply to an `lm` object. These include:

```{r echo = FALSE}
mod_objects <- data.frame(Function = c("`summary`", "`coefficients`", 
                                   "`fitted`",
                                   "`plot`", "`residuals`"),
                          Description = c("Get a variety of information on the model, including coefficients and p-values for the coefficients",
                                   "Pull out just the coefficients for a model",
                                   "Get the fitted values from the model (for the data used to fit the model)",
                                   "Create plots to help assess model assumptions",
                                   "Get the model residuals"))
pander::pander(mod_objects, split.cells = c(1,1,58),
               justify = c("center", "left"))
```

For example, you can get the coefficients from the model by running:

```{r}
coefficients(mod_a)
```

The estimated coefficient for the intercept is always given under the name "(Intercept)". Estimated coefficients for independent variables are given based on their column names in the original data ("ht" here, for $\beta_1$, or the estimated increase in expected weight for a one unit increase in height).

You can use the output from a `coefficients` call to plot a regression line based on the model fit on top of points showing the original data (Figure \@ref(fig:modelcoefplot)). 

```{r modelcoefplot, fig.height = 3.5, fig.width = 5, warning = FALSE, fig.align = "center", fig.cap = "Example of using the output from a `coefficients` call to add a regression line to a scatterplot."}
mod_coef <- coefficients(mod_a)
ggplot(nepali, aes(x = ht, y = wt)) + 
  geom_point(size = 0.2) + 
  xlab("Height (cm)") + ylab("Weight (kg)") + 
  geom_abline(aes(intercept = mod_coef[1],
                  slope = mod_coef[2]), col = "blue")
```

```{block, type = "rmdnote"}
You can also add a linear regression line to a scatterplot by adding the geom `geom_smooth` using the argument `method = "lm"`.
```

You can use the function `residuals` on an `lm` object to pull out the residuals from the model fit:

```{r}
head(residuals(mod_a))
```

The result of a `residuals` call is a vector with one element for each of the non-missing observations (rows) in the dataframe you used to fit the model. Each value gives the different between the model fitted value and the observed value for each of these observations, in the same order the observations show up in the dataframe. The residuals are in the same order as the observations in the original dataframe. 

```{block, type = "rmdtip"}
You can also use the shorter function `coef` as an alternative to `coefficients` and the shorter function `resid` as an alternative to `residuals`.
```

The `summary()` function gives you a lot of information about the model: 

```{r, eval = FALSE}
summary(mod_a)
```

```{r, echo = FALSE}
summary(mod_a)
```

The object created when you use the `summary()` function on an `lm` object has several different parts you can pull out using the `$` operator:

```{r}
names(summary(mod_a))
summary(mod_a)$coefficients
```

You can use `plot` with an `lm` object to get a number of useful diagnostic plots to check regression assumptions:

```{r eval = FALSE}
plot(mod_a)
```

```{r echo = FALSE, out.width = '\\textwidth', fig.align = "center"}
oldpar <- par(mfrow = c(2, 2))
plot(mod_a)
par(oldpar)
```

You can also use binary variables or factors as independent variables in regression models:

```{r}
mod_b <- lm(wt ~ sex, data = nepali)
summary(mod_b)$coefficients
```

This call fits the model:

$$ Y_{i} = \beta_{0} + \beta_{1}X_{1,i} + \epsilon_{i} $$

where $X_{1,i}$ : sex of child $i$, where 0 = male; 1 = female

### Generalized linear models (GLMs)

You can fit a variety of models, including linear models, logistic models, and Poisson models, using generalized linear models (GLMs). \medskip

For linear models, the only difference between `lm` and `glm` is how they're fitting the model (least squares versus maximum likelihood). You should get the same results regardless of which you pick. 

For example:

```{r}
mod_c <- glm(wt ~ ht, data = nepali)
summary(mod_c)$coef
summary(mod_a)$coef
```

You can fit other model types with `glm()` using the `family` option:

```{r echo = FALSE}
glm_types <- data.frame(type = c("Linear", "Logistic", "Poisson"),
                        opt = c("`family = gaussian(link = 'identity')`",
                                "`family = binomial(link = 'logit')`", 
                                "`family = poisson(link = 'log')`"))
knitr::kable(glm_types, col.names = c("Model type", "`family` option"))
```

For example, say we wanted to fit a logistic regression for the `nepali` data of whether the probability that a child weighs more than 13 kg is associated with the child's height. \medskip

First, create a binary variable for `wt_over_13`:

```{r}
nepali <- nepali %>% 
  mutate(wt_over_13 = wt > 13)
head(nepali)
```

Now you can fit a logistic regression:

```{r}
mod_d <- glm(wt_over_13 ~ ht, data = nepali,
             family = binomial(link = "logit"))
summary(mod_d)$coef
```

Here, the model coefficient gives the **log odds** of having a weight higher than 13 kg associated with a unit increase in height.

### References-- statistics in R

A great (and free for CSU students) resource to find out more about using R for basic statistics:

- [Introductory Statistics with R](http://discovery.library.colostate.edu/Record/.b44705323)

If you want all the details about fitting linear models and GLMs in R, Faraway's books are fantastic:

- [Linear Models with R](http://discovery.library.colostate.edu/Record/.b41119691) (also freely available through our library)
- [Extending the Linear Model with R](http://www.amazon.com/Extending-Linear-Model-Generalized-Nonparametric/dp/158488424X/ref=sr_1_1?ie=UTF8&qid=1442252668&sr=8-1&keywords=extending+linear+model+r)

## In-course exercise

### Loading data from an R package

The data we'll be using today is from a dataset called `worldcup` in the package `faraway`. Load that data so you can use it on your computer (note: you will need to load and install the `faraway` package to do this). Use the help file for the data to find out more about the dataset. Use some basic functions, like `head`, `tail`, `colnames`, `str`, and `summary` to check out the data a bit. See if you can figure out:

- What variables are included in this dataset? (Check the column names.)
- What class is each column currently? In particular, which are numbers and which are factors?

#### Example R code:

Load the `faraway` package using `load()` and then load the data using `data()`:

```{r}
## Uncomment the next line if you need to install the package
# install.packages("faraway")
library(faraway)
data("worldcup")
```

Check out the help file for the `worldcup` dataset to find out more about the data. (Note: Only datasets that are parts of packages will have help files.)

```{r, eval = FALSE}
?worldcup
```

Check out the data a bit:

```{r}
str(worldcup)
head(worldcup)
tail(worldcup)
colnames(worldcup)
summary(worldcup)
```

### Basic plots of the data

Use some basic plots to check out this data. Try the following:

- Plot histograms of all the numeric variables (`Time`, `Shot`, `Passes`, `Tackles`, `Saves`)
- Plot scatterplots of different combinations of numeric variables (e.g., `Time` vs. `Shots`). Try doing this using the `geom_point()` geom from `ggplot2`. Also try doing it using the `ggpairs()` function from the `GGally` package, to plot several of these at the same time. Try using different constant or mapped values with the `color` aesthetic. 
- Create boxplots of `Time`, `Shots`, `Passes` and `Saves` by position.
- Go online and find out which teams were the top four teams in this World Cup (i.e., first through fourth places). Create a `top_teams` subset with just these teams. Plot boxplots of `Shots` and `Saves` by team for just these teams. 
- Did you notice any interesting features of the data when you did any of the graphs in this section?

#### Example R code:

Use histograms to explore the distribution of different variables. If you want to change the number of bins in the histogram, try playing around with the `bins` and `binwidth` arguments. You can use the `bins` argument to say how many bins you want (e.g., `bins = 50`). You can use the `binwidth` argument to say how wide you want the bins to be (e.g., `binwidth = 10` if you wanted bins to be 10 units wide, in the units of the variable mapped to the `x` aesthetic. Try using `fill` and `color` to change the appearance of the plot. Google "R colors" and search the images to find links to listings of different R colors.

```{r, message = FALSE, fig.align = "center", fig.width = 5, fig.height = 3}
library(ggplot2)
ggplot(worldcup, aes(x = Time)) + 
  geom_histogram()

ggplot(worldcup, aes(x = Time)) + 
  geom_histogram(bins = 50)

ggplot(worldcup, aes(x = Time)) + 
  geom_histogram(binwidth = 100)

ggplot(worldcup, aes(x = Time)) + 
  geom_histogram(binwidth = 50, color = "white", fill = "cyan4")
```

Create a scatterplot of `Time` versus `Passes`. To change the size of the points, use the `size` argument (use a number lower than 1 for smaller points, higher than 1 for larger points). Try changing the color and transparency of the points using the aesthetics `color` and `alpha`. Try using color to show each player's position by mapping `Position` to the `color` aesthetic. 

```{r, fig.align = "center", fig.width = 5, fig.height = 3}
ggplot(worldcup, aes(x = Time, y = Passes)) + 
  geom_point()

ggplot(worldcup, aes(x = Time, y = Passes)) + 
  geom_point(size = 0.5)

ggplot(worldcup, aes(x = Time, y = Passes)) + 
  geom_point(size = 2, color = "blue", alpha = 0.25)

ggplot(worldcup, aes(x = Time, y = Passes, color = Position)) + 
  geom_point()
```

Use the `ggpairs` function from the `GGally` package to plot scatterplots of all combinations of several numeric variables.

```{r, message=FALSE, warning=FALSE, fig.align = "center"}
library(GGally)
library(dplyr)
ggpairs(select(worldcup, Time, Shots, Passes, Tackles, Saves))
```

To create a boxplot of `Shots` by `Position`, you can use `geom_boxplot`:

```{r, fig.width=5, fig.height=3, fig.align = "center"}
ggplot(worldcup, aes(x = Position, y = Shots)) + 
  geom_boxplot()
```

The top four teams in this World Cup were Spain, the Netherlands, Germany, and Uruguay. Create a subset with just the data for these four teams:

```{r}
top_teams <- worldcup %>%
  filter(Team %in% c("Spain", "Netherlands", "Germany", "Uruguay")) %>% 
  mutate(Team = factor(Team))
```

This dataset will still have all the levels saved for the `Team` factor, even though it isn't using them all. You can re-set this by resetting `Team` as a factor, which is what I've done with the `mutate` line. When R creates a factor from a vector, its default is to only use as levels the values that show up in the vector. 

Now, you can plot the boxplots, mapping `Team` to the `x` aesthetic and `Shots` or `Saves` to the `y` aesthetic:

```{r, fig.width = 6, fig.height = 3, fig.align = "center"}
ggplot(top_teams, aes(x = Team, y = Shots)) + 
  geom_boxplot() + 
  ggtitle("Shots")

ggplot(top_teams, aes(x = Team, y = Saves)) + 
  geom_boxplot() + 
  ggtitle("Saves")
```

#### If you have extra time:

If you wanted to do the same plot for several different variables, you could loop through your code (we'll be covering more about loops in a few weeks). For example, you could create histograms for all of the numeric variables (if you do this in RStudio, you'll need to use the arrows on the plot window to move through and see all the different plots once you've created them):

```{r, fig.width = 3, fig.height = 2.5}
## Create an object with the column names for all of the numeric variables
my_vars <- colnames(worldcup)[3:7]

## Loop through all of those variables. Print out a histogram with the 
## variable, and have it print on the plot, as the main title, the 
## column name for that variable
for(var in my_vars){
  worldcup$to_plot <- worldcup[ , var]
  a <- ggplot(worldcup, aes(x = to_plot)) + 
    geom_histogram(bins = 20, color = "white", fill = "navy") + 
    xlab(var) + 
    ggtitle(paste("Histogram of", var))
  plot(a)
}
```

A few things to note in this example: 

- To map an element of the data to an aesthetic, it's easiest if that element is saved in a column in the dataframe. Within this loop, I'm making an extra column called `to_plot`, where I'm copying the column of the variable I want to plot each time the loop runs. That way, I can always use `x = to_plot` in the aesthetic mapping for the ggplot object. 
- If you run code to create a ggplot object within a loop, it won't automatically print. Instead, you need to use `print` to get the object to print out. One way to do that is to save the final ggplot object as an R object (here I'm saving it to `a`) and then use the `print` function to print that object. 
- Next week, we'll talk some about faceting, which can create multiple plots by variable like this in a lot less code. However, it's useful at this point to start thinking about how to extend code to use in loops, to save yourself time when you need to repeat something similar many times.

### Exploring the data using simple statistics and logical statements

Next, try checking out the data using some basic commands for simple statistics, like `mean()`, `range()`, `max()`, and `min()`. Use these, along with some logical statements, to help you answer the following questions:

- What is the range of time that players spent in the game? Who played the most World Cup time in this World Cup? For the minimum of the range of `Time`, how many players played this amount of time?
- What is the mean number of saves that players made? What is the mean number of saves just among the goalkeepers? How many of the players are goalkeepers? Did any non-goalkeeper make a save?

#### Example R code:

Use `range()` to find out the range of time these players played in the World Cup. 
```{r}
range(worldcup$Time)
```

To figure out who played the most time, you need to subset out the rows of the dataset where the `Time` variable equals the maximum of the `Time` variable for the whole dataset. There are a few ways to do that. Here I'm showing two: (1) using logic within the "square-bracket indexing", to pull out just rows where it is TRUE that the `Time` for that row equals `max(worldcup$Time)` and (2) using `filter` from the `dplyr` package to filter down to rows where where it is TRUE that the `Time` for that row equals `max(Time)` for the whole dataset. 

```{r}
max(worldcup$Time)
head(worldcup$Time == max(worldcup$Time))

worldcup[worldcup$Time == max(worldcup$Time), ]

worldcup %>%
  filter(Time == max(Time))
```

*Note*: You may have noticed that you lost the players names when you did this using the `dplyr` pipechain. That's because `dplyr` functions convert the data to a dataframe format that does not include rownames. If you want to keep players' names, use `mutate` to move those names from the rownames of the data into a column in the dataframe:

```{r}
worldcup %>%
  mutate(Name = rownames(worldcup)) %>%
  filter(Time == max(Time))
```

To calculate the mean number of saves among all the players, use the `mean` function, either by itself or within a `summarize` call:

```{r}
mean(worldcup$Saves)

worldcup %>%
  summarize(mean_saves = mean(Saves))
```

For the next parts of the question, it will be convenient to have a logical vector for whether each player is a goalkeeper, so here's how you would create that:

```{r}
goalie <- worldcup$Position == "Goalkeeper"
```

This new object, `goalie`, is a vector the same length as `worldcup$Position`. Each element of `goalie` says whether it is TRUE or FALSE that `worldcup$Position` is equal to "Goalkeeper" at that spot on the `worldcup$Position` vector. 

```{r}
head(goalie)
```

The `summary()` function will count up the total number of times that `goalie` is TRUE and FALSE.

```{r}
summary(goalie)
```

There are a few ways to use this vector to figure out how many players were goalkeepers. First, you could use `summary` (which I just showed) or `table`, and just read how many times this vector has the value `TRUE`. Second, since R saves logical vectors with `TRUE` as 1 and `FALSE` as 0, you could just the `sum` function to add up the vector to find out how often it's `TRUE` (`sum` adds up every value in the vector).

```{r}
table(goalie)
sum(goalie)
```

You could also answer this question by using `summarize` from `dplyr`. You need to `group_by` player position and then you can use the `n` function in `summarize` to count up the total number of observations in each group:

```{r}
worldcup %>%
  group_by(Position) %>%
  summarize(n_players = n())
```

Now, you can answer the questions about mean saves for goalies and max saves for non-goalies. First, try doing that using the `goalie` logical vector you created. If you put `goalie` in the square bracket indexing for the dataframe as the rows value (i.e., the index before the comma), R will subset out just the rows where `goalie` is equal to TRUE. If you put `!goalie` in the square bracket indexing as the rows value, R will just subset out the rows where `goalie` is equal to FALSE. You can use this index subsetting to figure out the mean number of saves per goalie and also whether any non-goalie made a save (by checking the maximum value or range of saves for non-goalies).

```{r}
head(worldcup[goalie, ])
mean(worldcup[goalie, "Saves"])
range(worldcup[!goalie, "Saves"])
```

You could also answer this quesiton using a `dplyr` pipe chain to summarize the data after grouping it by position:

```{r}
worldcup %>%
  group_by(Position) %>%
  summarize(number_players = n(), 
            mean_saves = mean(Saves),
            max_saves = max(Saves))
```

### Using regression models to explore data

For this part of the exercise, you'll use a dataset on weather, air pollution, and mortality counts in Chicago, IL. This dataset is called `chicagoNMMAPS` and is part of the `dlnm` package. Change the name of the dataframe to something shorter, like `chic`. Check out the data a bit to see what variables you have, and then perform the following tasks:

- Write out (on paper, not in R) the regression equation for regressing dewpoint temperature on temperature. 
- Try fitting a linear regression of dew point temperature (`dptp`) on temperature (`temp`). (Bonus points: Notice anything that seems unusual about these two variables in this dataset? You can find out with `summary`, but it helps if you know a bit about what dewpoint temperature measures.)
Save this model as the object `mod_1`. 
- Based on this regression, does there seem to be a relationship between temperature and dewpoint temperature in Chicago? (Hint: Try using `summary()` on the model object to get more information about the model you fit.) What is the p-value for the coefficient for temperature?
- Plot temperature (x-axis) versus dewpoint temperature (y-axis) for Chicago. Add in the regression line from the model you fit.
- Use `plot()` on the model object to check if some of the assumptions for the regression model seem appropriate.
- Try fitting the regression as a GLM, using `glm()`. Are your coefficients different?
- Does $PM_{10}$ vary by day of the week? (Hint: The `dow` variable is a factor that gives day of the week. You can do an ANOVA analysis by fitting a linear model using this variable as the independent variable, and then run `anova()` on that model, and R will compare it to an intercept-only model.) What day of the week is PM10 generally highest? (Check the model coefficients to figure this out.) Try to write out (on paper) the regression equation for the model you're fitting.
- Try using `glm()` to run a Poisson regression of respiratory deaths (`resp`) on temperature during summer days. Start by creating a subset with just summer days called `summer`. (Hint: Use the `month` variable to do this-- just pull out the subset where the month is 6, 7, or 8, for June, July, and August.) Try to write out the regression equation for the model you're fitting.
- The coefficient for the temperature variable in this model is our best estimate (based on this model) of the **log relative risk** for a one degree Celcius increase in temperature. What is the **relative risk** associated with a one degree Celsius increase?

#### Example R code:

Install and load the `dlnm` package and then load the `chicagoNMMAPS` data. Change the name of the dataframe to `chic`, so it will be shorter to call for the rest of your work. 

```{r, message = FALSE, warning = FALSE}
# install.packages("dlnm")
library(dlnm)
data("chicagoNMMAPS")
chic <- chicagoNMMAPS
```

Fit a linear regression of `dptp` on `temp` and save as the object `mod_1`:

```{r}
mod_1 <- lm(dptp ~ temp, data = chic)
mod_1
```

Use `summary()` to check out a bit more about the model you fit. 

```{r}
summary(mod_1)
```

There does seem to be an association between temperature and dewpoint temperature: a unit increase in temperature is associated with a `r round(coef(mod_1)[2], 1)` unit increase in dewpoint temperature. The p-value for the temperature coefficient is <2e-16. This is far below 0.05, which suggests we would be very unlikely to see such a strong association by chance if the null hypothesis, that the two variables are not associated, were true.

Plot these two variables and add in the regression line from the model (note: I've used the `color` option to make the color of the points gray). Use the values from `coef` with a `geom_abline` to add the regression line for the model you fit. 

```{r}
mod_coefs <- coef(mod_1)
ggplot(chic, aes(x = temp, y = dptp)) + 
  geom_point(size = 0.5, col = "gray") + 
  geom_abline(aes(intercept = mod_coefs[1], slope = mod_coefs[2]))
```

Plot some plots to check model assumptions for the model you fit using the `plot()` function on your model object:

```{r, fig.width = 6, fig.height = 6}
par(mfrow = c(2, 2)) # Set to four plots per panel -- 2 rows, 2 columns
plot(mod_1)
par(mfrow = c(1, 1)) # Reset to one plot per panel
```

Try fitting the model using `glm()`. Call it `mod_1a`. Compare the coefficients for the two models. You can use the `coef()` function on an `lm` or `glm` object to pull out just the model coefficients.

```{r}
mod_1a <- glm(dptp ~ temp, data = chic)

coef(mod_1)
coef(mod_1a)
```

The results from the two models are identical.

Fit a model of $PM_{10}$ regressed on day of week, where day of week is a factor. 

```{r}
mod_2 <- lm(pm10 ~ dow, data = chic)
summary(mod_2)
```

Use the `anova()` command to compare this model to a model with only an intercept (i.e., one that only fits a global mean and uses that as the expected value for all of the observations).

```{r}
anova(mod_2)
```

The p-value for an ANOVA of the model with day-of-week coefficients versus the model that just has an intercept is < 2.2e-16. This is well below 0.05, which suggests that day-of-week is associated with PM10 concentration, as a model that includes day-of-week does a much better job of explaining variation in PM10 than a model without it does. (Note, too, that the F value and Pr(>F) for the `anova()` call are identical to the F-statistic information given in the `summary()` of the model object. This will always be true when you're using `anova()` to compare a model to a model with just an intercept.)

Use a boxplot to visually compare PM10 by day of week. 

```{r, fig.height = 3, fig.width = 6, warning = FALSE}
ggplot(chic, aes(x = dow, y = pm10)) + 
  geom_boxplot()
```

Now try the same plot, but try using the `ylim = ` option to change the limits on the y-axis for the graph, so you can get a better idea of the pattern by day of week (some of the extreme values are very high, which makes it hard to compare by eye when the y-axis extends to include them all).

```{r, fig.height = 3, fig.width = 6, message = FALSE}
ggplot(chic, aes(x = dow, y = pm10)) + 
  geom_boxplot() + 
  ylim(c(0, 100))
```

Create a subset called `summer` with just the summer days:

```{r}
summer <- chic %>%
  filter(month %in% 6:8)
```

Use `glm()` to fit a Poisson model of respiratory deaths regressed on temperature. Since you want to fit a Poisson model, use the option `family = poisson(link = "log")`. 

```{r}
mod_3 <- glm(resp ~ temp, data = summer,
             family = poisson(link = "log"))
summary(mod_3)
```

Use the fitted model coefficient to determine the relative risk for a one degree Celcius increase in temperature. First, remember that you can use the `coef()` function to read out the model coefficients. The second of these is the value for the temperature coefficient. That means that you can use indexing (`[2]`) to get just that value. That's the log relative risk; take the exponent to get the relative risk.

```{r}
coef(mod_3)
coef(mod_3)[2]
exp(coef(mod_3)[2])
```
