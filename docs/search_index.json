[
["index.html", "R Programming for Research Online course book, ERHS 535", " R Programming for Research Colorado State University, ERHS 535 Brooke Anderson and Rachel Severson 2018-09-09 Online course book, ERHS 535 This is the online book for Colorado State University’s ERHS 535 R Programming for Research course. This book includes course information, course notes, links to download pdfs of lecture slides, in-course exercises, homework assignments, and vocabulary lists for quizzes for this course. ““Give someone a program, you frustrate them for a day; teach them how to program, you frustrate them for a lifetime.”—David Leinweber” This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. "],
["course-information.html", "Course information 0.1 Course overview 0.2 Time and place 0.3 Detailed schedule 0.4 Grading 0.5 Course set-up 0.6 Coursebook", " Course information Download a pdf of the lecture slides covering this topic. 0.1 Course overview This document provides the course notes for Colorado State University’s ERHS 535 course for Fall 2018. The course offers in-depth instruction on data collection, data management, programming, and visualization, using data examples relevant to academic research. 0.2 Time and place This course meets in Room 120 of the Environmental Health Building on Mondays and Wednesdays, 10:00 am–12:00 pm. Exceptions to these meeting times are: There will be no meeting on Labor Day (Monday, Sept. 3). There are no course meetings the week of Thanksgiving (week of Nov. 19). I will be away from Fort Collins for two course dates (Aug. 27 and 29). I will videotape the lectures for these two class dates and post them online. I will offer a (voluntary) session on Aug. 31, 10:00-11:00 am, for anyone who would like to join to work on the in-course group exercises with classmates and with my feedback. Office hours for Fall 2018 will be 10:00–11:00 AM on Fridays in EH 120. 0.3 Detailed schedule Here is a more detailed view of the schedule for this course for Fall 2016: Dates Level Lecture content Graded items Aug. 20, 22 Preliminary R Preliminaries Aug. 27, 29 Basic Entering and cleaning data Sept. 5 Basic Exploring data Quiz (W) Sept. 10, 12 Basic Reporting data results Quiz (M), HW #1 (W) Sept. 17, 19 Basic Reproducible Research Quiz (M) Sept. 24, 26 Intermediate Entering and cleaning data Quiz (M), HW #2 (W) Oct. 1, 3 Intermediate Exploring data Quiz (M) Oct. 8, 10 Intermediate Reporting data results Quiz (M), HW #3 (W) Oct. 15, 17 Intermediate Reproducible Research Quiz (M), Group choices (M) Oct. 22, 24 Advanced Entering and cleaning data Quiz (M), Project proposal (M), HW #4 (W) Oct. 29, 31 Advanced Exploring data Nov. 5, 7 Advanced Reporting data results HW #5 (W) Nov. 12, 14 Advanced Mapping in R Nov. 26, 28 Advanced Package development 1 HW #6 (W) Dec. 3, 5 Advanced Package development 2 Project draft (M) Week of Dec. 10 Group presentations Final project (M) 0.4 Grading Course grades will be determined by the following five components: Assessment component Percent of grade Final group project 30 Weekly in-class quizzes, weeks 3-10 25 Homework 25 Attendance and class participation 10 Weekly in-course group exercises 10 0.4.1 Attendance and class participation Because so much of the learning for this class is through interactive work in class, it is critical that you come to class. Out of a possible 10 points for class attendance, you will get: 10 points if you attend all classes 8 points if you miss one class 6 points if you miss two classes 4 points if you miss three classes 2 points if you miss four classes 0 points if you miss five or more classes Exceptions: Attendance on the first day of class (Aug. 20) will not be counted. If you miss classes for “University-sanctioned”&quot; activities. These can include attending a conference, travel to collect data for your dissertation), For these absences, you must inform prior to the date that you will be absence. No points will be lost for attendance if you provide a signed letter from your research advisor by Dec. 11, 2017 (start of finals week), and you can make arrangements with me to make up any missed work. For more details, see CSU’s Academic Policies on Course Attendance. If you have to miss class for a serious medical issue (e.g., operation, sickness severe enough to require a doctor’s visit), the absence will be excused if you bring in a note from a doctor of other medical professional giving the date you missed and that it was for a serious medical issue. 0.4.2 Weekly in-course group exercises Part of each class will be spent doing in-course group exercises. Ten points of your final grade will be based on your participation in these exercises. As long as you are in class and participate in these exercises, you will get full credit for this component. If you miss a class, to get credit towards this component of your grade, you will need to turn in a one-page document describing what you learned from doing the in-course exercise on your own time. All in-class exercises are included in the online course book at the end of the chapter on the associated material. 0.4.3 In-class quizzes You will have eight total in-class quizzes. You will have one for each of the Week 3–10 class meetings. There will be at least 10 questions per quiz. You will get 1/3 point for each correct answer. If you do the math, you can get full credit for this if you get at least 75% of your answers right. You can not get more than the maximum of 25 points for this component– once you reach 25 points on quizzes, you will have achieved full credit for the quiz component of the course grade. All quiz questions will be multiple choice, matching, or some other form of “close-answered” question (i.e., no open-response-style questions). You can not make up a quiz for a class period you missed. You can still get full credit on your total possible quiz points if you miss a class, but it means you will have to work harder and get more questions right for days you are in class. Because grading format for these quizzes allows for you to miss some questions and still get the full quiz credit for the course, I will not ever re-consider the score you got on a previous quiz, give points back for a wrong answer on a poorly-worded question, etc. However, if a lot of people got a particular question wrong, I will be sure to cover it in the next class period. Also, especially if a question was poorly worded and caused confusion, I will work a similar question into a future quiz– in addition to the 10 guaranteed questions for that quiz– so every student will have the chance to get an extra 1/3 point of credit for the question. The “Vocabulary” appendix of our online book has the list of material for which you will be responsible for this quiz. Most of the functions and concepts will have been covered in class, but some may not. You are responsible for going through the list and, if there are things you don’t know or remember from class, learning them. To do this, you can use help functions in R, Google, StackOverflow, books on R, ask a friend, and any other resource you can find. The final version of the Vocabulary list you will be responsible will be posted by the Wednesday evening before each quiz. In general, using R frequently in your research or other coursework will help you to prepare and do well on these quizzes. 0.4.4 Homework There will be six homework assignments, starting a few weeks into the course and then due approximately every two weeks (see the detailed schedule in the online course book for exact due dates). The first homework (HW #1) should be done individually. For some other homeworks, you may be given the option to work in small groups of approximately three students. For later homeworks, a subset of the full set of questions will be selected for which I will do a detailed grading of the code itself, with substantial feedback on coding. All other questions in the homework will be graded for completeness and based on the final answer produced. For homeworks with a heavy coding component, I will provide solution code for all questions. Homework is due by the start of class on the due date. Your grade will be reduced by 10 points for each day it is late, and will receive no credit if it is late by over a week. 0.4.5 Final group project For the final project, you will work in small groups (3–4 people) on an R programming challenge. The final grade will be based on the resulting R software, as well as on a short group presentation and written report describing your work. You will be given a lot of in-class time during the last third of the semester to work with your group on this project, and you will also need to spend some time working outside of class to complete the project. More details on this project will be provided later in the semester. 0.5 Course set-up Please be sure you have the latest version of R and RStudio (Desktop version, Open Source edition) installed. Both are free for anyone to download. Also, be sure to sign up for a free GitHub account. Here are useful links for this set-up: R: https://cran.r-project.org RStudio: https://www.rstudio.com/products/rstudio/#Desktop Sign-up for a GitHub account: https://github.com 0.6 Coursebook This coursebook will serve as the only required textbook for this course. I am still in the process of editing and adding to this book, so content may change somewhat over the semester (particularly for the second half of the book, which is currently in a rawer draft than the beginning of the book). We typically cover about a chapter of the book each week of the course. This coursebook includes: Links to the slides presented in class for each topic In-course exercises, typically including links to the data used in the exercise An appendix with homework assignments A list of vocabulary and concepts that should be mastered for each quiz If you find any typos or bugs, or if you have any suggestions for how the book can be improved, feel free to post it on the book’s GitHub Issues page. This book was developed using Yihui Xie’s phenomenal bookdown framework. The book is built using code that combines R code, data, and text to create a book for which R code and examples can be re-executed every time the book is re-built, which helps identify bugs and broken code examples quickly. The online book is hosted using GitHub’s free GitHub Pages. All material for this book is available and can be explored at the book’s GitHub repository. 0.6.1 Other helpful books (not required) The best book to supplement the coursebook and lectures for this course is R for Data Science, by Garrett Grolemund and Hadley Wickham. The entire book is freely available online through the same format at the coursebook. You can also purchase a paper version of the book (published by O’Reilly) through Amazon, Barnes &amp; Noble, etc., for around $40. This book is an excellent and up-to-date reference by some of the best R programmers in the world. There are a number of other useful books available on general R programming, including: R for Dummies R Cookbook R Graphics Cookbook Roger Peng’s Leanpub books Various books on bookdown.org The R programming language is used extensively within certain fields, including statistics and bioinformatics. If you are using R for a specific type of analysis, you will be able to find many books with advice on using R for both general and specific statistical analysis, including many available in print or online through the CSU library. "],
["r-preliminaries.html", "Chapter 1 R Preliminaries 1.1 Objectives 1.2 R and R Studio 1.3 The “package” system 1.4 Basic code conventions of R 1.5 R’s most basic object types 1.6 Using R functions 1.7 R scripts 1.8 In-course Exercise", " Chapter 1 R Preliminaries Download a pdf of the lecture slides covering this topic. 1.1 Objectives After this chapter, you should: Know what free and open source software is and some of its advantages over proprietary software Understand the difference between R and RStudio Be able to download both R and RStudio to your own computer Understand that R has a basic core of code that you initially download, and that this “base R” can be expanded by installing a variety of packages Be able to install a package from CRAN to your computer Be able to load a package that you have installed to use its functions within an R session Be able to access help documentation (vignettes, helpfiles) for a package and its functions Know what an R object is and how to assign an R object a name to reference it in later code Be able to create vector objects of numeric and character classes Be able to explore and extract elements from vector objects Be able to create dataframe objects Be able to explore and extract elements from dataframe objects Understand the structure for calling a function and specifying options for that function Describe the difference between running R code from the console versus writing and running R code in an R script 1.2 R and R Studio 1.2.1 What is R? R in an open-source programming language that evolved from the S language. The S language was developed at Bell Labs in the 1970s, which is the same place (and about the same time) that the C programming language was developed. R itself was developed in the 1990s–2000s at the University of Auckland. It is open-source software, freely and openly distributed under the GNU General Public License (GPL). The base version of R that you download when you install R on your computer includes the critical code for running R, but you can also install and run “packages” that people all over the world have developed to extend R. With new developments, R is becoming more and more useful for a variety of programming tasks. However, where it really shines is in working with data and doing statistical analysis. R is currently popular in a number of fields, including: Statistics Machine learning Data journalism / data analysis R has some of the same strengths (quick and easy to code, interfaces well with other languages, easy to work interactively) and weaknesses (slower than compiled languages) as Python. For data-related tasks, R and Python are fairly neck-and-neck (with Julia an up-and-coming option). However, R is still the first choice of statisticians in most fields, so I would argue that R has a an advantage if you want to have access to cutting-edge statistical methods. “The best thing about R is that it was developed by statisticians. The worst thing about R is that… it was developed by statisticians.” -Bo Cowgill, Google, at the Bay Area R Users Group 1.2.2 Open-source software “Life is too short to run proprietary software.” – Bdale Garbee R is open-source software. Many other popular statistical programming languages, conversely, are proprietary. It’s useful to know what it means for software to be “open-source”, both conceptually and in terms of how you will be able to use and add to R in your own work. R is free, and it’s tempting to think of open-source software just as “free software”. Things, however, are a little more subtle than that. It helps to consider some different meanings of the word “free”. “Free” can mean: Gratis: Free as in beer Libre: Free as in speech Figure 1.1: An overview of how software can be each type of free (beer and speech). For software programs developed using a compiled programming language, the final product that you open on your computer is run by machine-readable binary code. A developer can give you this code for free (as in beer) without sharing any of the original source code with you. This means you can’t dig in to figure out how the software works and how you can extend it. By contrast, open-source software (free as in speech) is software for which you have access to the human-readable code that was used as in input in creating the software binaries. With open-source code, you can figure out exactly how the program is coded. Open-source software software is the libre type of free (Figure 1.1). This means that, with software that is open-source, you can: Access all of the code that makes up the software Change the code as you’d like for your own applications Build on the code with your own extensions Share the software and its code, as well as your extensions, with others Popular open source licenses for R and R packages include the GPL and MIT licenses. “Making Linux GPL’d was definitely the best thing I ever did.” – Linus Torvalds In practice, this means that, once you are familiar with the software, you can dig deeply into the code to figure out exactly how it’s performing certain tasks. This can be useful for finding bugs and eliminating bugs, and also can help researchers figure out if there are any limitations in how the code works for their specific research. It also means that you can build your own software on top of existing R software and its extensions. I explain a bit more about R packages a bit later, but this open-source nature of R (and other languages, including Python) has created a large community of people worldwide who develop and share extensions to R. As a result, you can pull in packages that let you do all kinds of things in R, like visualizing Tweets, cleaning up accelerometer data, analyzing complex surveys, fitting maching learning models, and a wealth of other cool things. “Despite its name, open-source software is less vulnerable to hacking than the secret, black box systems like those being used in polling places now. That’s because anyone can see how open-source systems operate. Bugs can be spotted and remedied, deterring those who would attempt attacks. This makes them much more secure than closed-source models like Microsoft’s, which only Microsoft employees can get into to fix.” – Woolsey and Fox. To Protect Voting, Use Open-Source Software. New York Times. August 3, 2017. You can download the latest version of R from CRAN. Be sure to select the distribution for your type of computer system. R is updated occasionally; you should plan to re-install R at least once a year, to make sure you’re working with one of the newer versions. Check your current R version (one way is by running sessionInfo() at the R console) to make sure you’re not using an outdated version of R. Defaults should be fine for everything. “The R engine … is pretty well uniformly excellent code but you have to take my word for that. Actually, you don’t. The whole engine is open source so, if you wish, you can check every line of it. If people were out to push dodgy software, this is not the way they’d go about it.” - Bill Venables, R-help (January 2004) “Talk is cheap. Show me the code.” - Linus Torvalds 1.2.3 What is RStudio? To get the R software, you’ll download R from the R Project for Statistical Computing. This is enough for you to use R on your own computer. However, I would suggest one additional, free piece of software to improve your experience while working with R, RStudio. RStudio is an integrated development environment (IDE) for R. This basically means that it provides you an interface for running R and coding in R, with a lot of nice extras that will make your life easier. You download RStudio separately from R—you’ll want to download and install R itself first, and then you can download RStudio. You want the Desktop version with the free license. Defaults should be fine for everything. The company that develops this IDE is a fantastic contributer to the global R community. RStudio currently: RStudio (the company) is a leader in the R community. Currently, the company: Develops and freely provides the RStudio IDE Provides excellent resources for learning and using R (e.g., cheatsheets, free online books) Is producing some of the most-used R packages Employs some of the top people in R development Is a key member of The R Consortium (others include Microsoft, IBM, and Google) R has been advancing by leaps in bounds in terms of what it can do and the elegance with which it does it, in large part because of the enormous contributions of people involved with RStudio. 1.3 The “package” system 1.3.1 R packages “Any doubts about R’s big-league status should be put to rest, now that we have a Sudoku Puzzle Solver. Take that, SAS!” - David Brahm (announcing the sudoku package), R-packages (January 2006) Your original download of R is only a starting point. You can expand functionality of R with what are called packages, or extensions with new code and functionality that add to the basic “base R” environment. To me, this is a bit like the toy train set that my son was obsessed with for a while. You first buy a very basic set that looks something like Figure 1.2. Figure 1.2: The toy version of base R. To take full advantage of R, you’ll want to add on packages. In the case of the train set, at this point, a doting grandparent adds on extensively through birthday presents, so you end up with something that looks like Figure 1.3. Figure 1.3: The toy version of what your R set-up will look like once you find cool packages to use for your research. Each package is basically a bundle of extra R functions. You can get these “add-on” packages in a number of ways. The main source for installing packages for R remains the Comprehensive R Archive Network, or CRAN. However, GitHub is growing in popularity, especially for packages that are still in development. You can also create and share packages among your collaborators or co-workers, without ever posting them publicly. In the “Advanced” section of this course, you will learn how to write your own R package. 1.3.2 Installing from CRAN Figure 1.4: Celebrating CRAN’s 10,000th package. The most popular place from which to get packages is currently CRAN, which has over 10,000 R packages available (Figure 1.4). You can install packages from CRAN using R code, with the install.packages function. For example, telephone keypads include letters for each number (Figure 1.5), which allow companies to have “named” phone numbers that are easier for people to remember, like 1-800-GO-FEDEX and 1-800-FLOWERS. Figure 1.5: Telephone keypad with letters corresponding to each number. The phonenumber package is a cool little package that will convert between numbers and letters based on the telephone keypad. Since this package is on CRAN, you can install the package to your computer using the install.packages function: install.packages(&quot;phonenumber&quot;) This downloads the package from CRAN and saves it in a special location on your computer where R can load it when you’re ready to use it. Once you’ve installed a package to your computer this way, you don’t need to re-run this install.packages for the package ever again (unless the package maintainer posts an updated version). Just like R itself, packages often evolve and are updated by their maintainers. You should update your packages as new versions come out. Typically, you have to reinstall packages when you update your version of R, so this is a good chance to get the most up-to-date version of the packages you use. 1.3.3 Loading an installed package Once you have installed a package, it will be saved to your computer. However, you won’t be able to access its functions within an R session until you load it in that R session. Loading a package essentially makes all of the package’s functions available to you. You can load a package in an R session using the library function, with the package name inside the parentheses. library(&quot;phonenumber&quot;) Once a package is loaded, you can use all its exported (i.e., public) functions by calling them directly. For example, the phonenumber has a function called letterToNumber that converts a character string to a number. If you have not loaded the phonenumber package in your current R session and try to use this function, you will get an error. However, once you’ve loaded phonenumber using the library function, you can use this function in your R session: fedex_number &lt;- &quot;GoFedEx&quot; letterToNumber(fedex_number) ## [1] &quot;4633339&quot; R vectors can have several different classes. One common class is the character class, which is the class of the character string we’re using here (“GoFedEx”). You’ll always put character strings in quotation marks. Another key class is numeric (numbers). Later in the course, we’ll introduce other classes that vectors can have, including factors and dates. When you open RStudio, unless you reload the history of a previous R session (which I typically strongly do not recommend), you will start your work in a “fresh” R session. This means that, once you open RStudio, you will need to run the code to load any packages, define any objects, and read in any data that you will need for analysis in that session. If you are using a package in academic research, you should cite it, especially if it implements an algorithm or method that is not standard. You can use the citation function to get the information you need about how to cite a package: citation(&quot;phonenumber&quot;) ## ## To cite package &#39;phonenumber&#39; in publications use: ## ## Steve Myles (2015). phonenumber: Convert Letters to Numbers and ## Back as on a Telephone Keypad. R package version 0.2.2. ## https://CRAN.R-project.org/package=phonenumber ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {phonenumber: Convert Letters to Numbers and Back as on a Telephone Keypad}, ## author = {Steve Myles}, ## year = {2015}, ## note = {R package version 0.2.2}, ## url = {https://CRAN.R-project.org/package=phonenumber}, ## } We’ve talked here about loading packages using the library function to access their functions. However, this is not the only way to access the package’s functions. The syntax [package name]::[function name] (e.g., phonenumber::letterToNumber(fedex)) will allow you to use a function from a package you have installed on your computer, even if its package has not been loaded in the current R session. Typically, this syntax is not used much in data analysis scripts, in part because it makes the code much longer. However, you will occassionally see it used to distinguish between two functions from different packages that have the same name, as this format makes the desired function unambiguous. One example where this syntax often is needed is when both plyr and dplyr packages are loaded in an R session, since these share functions with the same name. Packages typically include some documentation to help users. These include: Package vignettes: Longer, tutorial-style documents that walk the user through the basics of how to use the package and often give some helpful example cases of the package in use. Function helpfiles: Files for each external function (i.e., the package maintainer wants it to be used by others) within the package, following an established structure. These include information about what inputs are required and optional for the function, what output will be created, and what options can be selected by the user. In many cases, these also include examples of using the function. To determine which vignettes are available for a package, you can use the vignette function, with the package’s name specified for the package option: vignette(package = &quot;phonenumber&quot;) From the output of this, you can call any of the package’s vignettes directly. For example, the previous call tells you that this package only has one vignette, and that vignette has the same name as the package (“phonenumber”). Once you know the name of the vignette you would like to open, you can also use vignette to open it: vignette(&quot;phonenumber&quot;) To access the helpfile for any function within a package you’ve loaded, you can use ? followed by the function’s name: ?letterToNumber 1.4 Basic code conventions of R 1.4.1 R objects In R, a variety of different types and structures of data can be saved in what’s called objects. For right now, you can just think of an R object as a discrete container of data in R. You can assign any R object you create its own name. Once you do this, you can use that object name to refer to the object. This means that you don’t need to re-create the object each time you need it—instead you can create it once and then just reference it by name each time you need it after that. For example, you can read in data from an external file as a dataframe object and assign it an object name. Then, when you need that data later, you won’t need to read it in again from the external file. You can think of object names as a bit like acronyms, in terms of being able to define something early in a document and then being able to use that short and simple name as a convenient way to refer to something complex every time you need to later in the document. 1.4.2 R’s MVP: The gets arrow The gets arrow, &lt;-, is R’s assignment operator. It takes whatever you’ve created on the right hand side of the &lt;- and saves that object with the object name you put on the left hand side of the &lt;-. The basic structure of a call with a gets arrow looks like this: ## Note: Generic code [name of object] &lt;- [thing I want to save] Sometimes, we’ll show “generic” code in a code block, that doesn’t actually work if you put it in R, but instead shows the generic structure of an R call. We’ll try to always include a comment with any generic code, so you’ll know not to try to run it in R. In R, objects are the way to save something to use again later in your code. If you do not assign something to an object with the gets arrow, R will just print it back out to you at the console. For example, if I just type &quot;GoFedEx&quot; at the R console, R will print that string back to me, but won’t save it anywhere for me to use later: &quot;GoFedEx&quot; ## [1] &quot;GoFedEx&quot; However, if I assign &quot;GoFedEx&quot; to an object using a gets arrow, I can print it out or use it later by typing (“referencing”) that object name: fedex_number &lt;- &quot;GoFedEx&quot; fedex_number ## [1] &quot;GoFedEx&quot; letterToNumber(fedex_number) ## [1] &quot;4633339&quot; You can assign the output of a function call directly to an object. For example, if you wanted to save the output of the letterToNumber call in the above code to its own object, you could do that with the call: fedex_actual_number &lt;- letterToNumber(fedex_number) fedex_actual_number ## [1] &quot;4633339&quot; If you give two objects the same name, the most recent definition will be used (i.e., objects can be overwritten by assigning new content to the same object name). For example: a &lt;- 1:10 b &lt;- LETTERS [1:3] a ## [1] 1 2 3 4 5 6 7 8 9 10 b ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; a &lt;- b a ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; If you would like to see all the R objects that are currently defined (i.e., have their own object names) in your R session, you can do that with the ls command: ls() ## [1] &quot;a&quot; &quot;b&quot; &quot;fedex_actual_number&quot; ## [4] &quot;fedex_number&quot; If you want to see the contents of an object, just print its name. For example, to see what we have stored in the fedex_number object, you can run: fedex_number ## [1] &quot;GoFedEx&quot; In R, at heart everything is an object, so this printing even works for things like functions. For example, to see the source code with which the letterToNumber function is defined, you can run (notice the lack of parentheses): letterToNumber ## function (value, qz = 1) ## { ## value &lt;- as.character(value) ## value &lt;- gsub(&quot;[^A-Za-z0-9]&quot;, &quot;-&quot;, value) ## value &lt;- toupper(value) ## valueSplit &lt;- strsplit(value, &quot;&quot;)[[1]] ## numString &lt;- as.character() ## mapphone &lt;- function(char) { ## if (qz == 0 &amp;&amp; (char == LETTERS[17] | char == LETTERS[26])) { ## &quot;0&quot; ## } ## else { ## ifelse(is.element(char, LETTERS[1:3]), &quot;2&quot;, ifelse(is.element(char, ## LETTERS[4:6]), &quot;3&quot;, ifelse(is.element(char, LETTERS[7:9]), ## &quot;4&quot;, ifelse(is.element(char, LETTERS[10:12]), ## &quot;5&quot;, ifelse(is.element(char, LETTERS[13:15]), ## &quot;6&quot;, ifelse(is.element(char, LETTERS[16:19]), ## &quot;7&quot;, ifelse(is.element(char, LETTERS[20:22]), ## &quot;8&quot;, ifelse(is.element(char, &quot;-&quot;) | suppressWarnings(!is.na(as.numeric(char))), ## char, &quot;9&quot;)))))))) ## } ## } ## numString &lt;- lapply(valueSplit, mapphone) ## return(paste0(numString, collapse = &quot;&quot;)) ## } ## &lt;bytecode: 0x7fe36ed29a60&gt; ## &lt;environment: namespace:phonenumber&gt; 1.4.3 Assignment operator wars: &lt;- vs. = You can make assignments in R using either the gets arrow (&lt;-) or =. When you read other people’s code, you’ll see both. R gurus advise using &lt;- rather than = when coding in R, and as you move to doing more complex things, some subtle problems might crop up if you use =. I have heard from someone in the know that you can tell the age of a programmer by whether he or she uses the gets arrow or =, with = more common among the young and hip. For this course, however, I am asking you to code according to Hadley Wickham’s R style guide, which specifies using the gets arrow for assignment. While you will be coding with the gets arrow exclusively in this course, it will be helpful for you to know that the two assignment arrows do pretty much the same thing: one_to_ten &lt;- 1:10 one_to_ten ## [1] 1 2 3 4 5 6 7 8 9 10 one_to_ten = 1:10 one_to_ten ## [1] 1 2 3 4 5 6 7 8 9 10 While the gets arrow takes two key strokes instead of one (like the equals sign), you can somewhat get around this limitation by using RStudio’s keyboard shortcut for the gets arrow. This shortcut is Alt + - on Windows and Option + - on Macs. To see a full list of RStudio keyboard shortcuts, go to the “Help” tab in RStudio and select “Keyboard Shortcuts”. 1.4.4 Naming objects When you assign objects, you will need to choose names for them. This object name is what you will type later in your code to reference the object and use it in functions, figures, etc. For example, with the following code, I am assigning the character string “GoFedEx” to an object that I am naming fedex_number: fedex_number &lt;- &quot;GoFedEx&quot; There are only two fixed rules for naming objects in R: Use only letters, numbers, and underscores Don’t start with anything but a letter In addition to these fixed rules, there are also some guidelines for naming objects that you should adopt now, since they will make your life easier as you advance to writing more complex code in R. The following three guidelines for naming objects are from Hadley Wickham’s R style guide: Use lower case for variable names (fedex_number, not FedExNumber) Use an underscore as a separator (fedex_number, not fedex.number or fedexNumber) Avoid using names that are already defined in R (e.g., don’t name an object mean, because a function named mean already exists) “Don’t call your matrix ‘matrix’. Would you call your dog ‘dog’? Anyway, it might clash with the function ‘matrix’.” - Barry Rowlingson, R-help (October 2004) Another good practice is to name objects after nouns (e.g., fedex_number) and later, when you start writing functions, name those after verbs (e.g., call_fedex). You’ll want your object names to be short enough that they don’t take forever to type as you’re coding, but not so short that you can’t remember what they stand for. Sometimes, you’ll want to create an object that you won’t want to keep for very long. For example, you might want to create a small object to test some code, but you plan to not need the object again once you’ve done that. You may want to come up with some short, generic object names that you use for these kinds of objects, so that you’ll know that you can delete them without problems when you want to clean up your R session. There are all kinds of traditions for these placeholder variable names in computer science. foo and bar are two popular choices, as are, evidently, xyzzy, spam, ham, and norf. There are different placeholder names in different languages: for example, toto, truc, and azerty (French); and pippo, pluto, paperino (Disney character names; Italian). See the Wikipedia page on metasyntactic variables to find out more. 1.5 R’s most basic object types An R object stores some type of data that you want to use later in your R code, without fully recreating it. The content of R objects can vary from very simple (the &quot;GoFedEx&quot; string in the example code above) to very complex objects with lots of elements (for example, a machine learning model). There are a variety of different object types in R, shaped to fit different types of objects ranging from the simple to complex. In this section, we’ll start by describing two object types that you will use most often in basic data analysis, vectors (1-dimensional objects) and dataframes (2-dimensional objects). 1.5.1 Vectors To get an initial grasp of the vector object type in R, think of it as a 1-dimensional object, or a string of values. All values in a vector must be of the same class (i.e., all numbers, all characters, all dates). If you try to create a vector with elements from different classes (like “FedEx”, which is a character, and 3, a number), R will coerce all of the elements to the most generic class of any of the elements (i.e., “FedEx” and “3” will both become characters, since “3” can be changed to a character, but “FedEx” can’t be changed to a number). To create a vector from different elements, you’ll use the concatenation function, c to join them together, with commas between the elements. For example, to create a vector with the first five elements of the Fibonacci sequence, you can run: fibonacci &lt;- c(1, 1, 2, 3, 5) fibonacci ## [1] 1 1 2 3 5 Here is an example of creating a vector using elements with the character class instead of numbers (note the quotation marks used around each element for character strings): one_to_five &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;) one_to_five ## [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; If you mix classes when you create the vector, R will coerce all the elements to most generic of the elements’ classes: mixed_classes &lt;- c(1, 3, &quot;five&quot;) mixed_classes ## [1] &quot;1&quot; &quot;3&quot; &quot;five&quot; A vector’s length is the number of elements in the vector. You can use the length function to determine a vector’s length: length(mixed_classes) ## [1] 3 Once you create an object, you will often want to reference the whole object in future code. However, there will be some times when you’ll want to reference just certain elements of the object (for example, the first three values). You can pull out certain values from a vector by using indexing with square brackets ([...]) to identify the locations of the elements you want to pull, with a numeric vector inside the brackets that lists the numbered positions of the elements you want to get: fibonacci[2] # Get the second value ## [1] 1 fibonacci[c(1, 5)] # Get first and fifth values ## [1] 1 5 fibonacci[1:3] # Get the first three values ## [1] 1 1 2 You can also use logic to pull out some values of a vector. For example, you might only want to pull out even values from the fibonacci vector. We’ll cover using logical statements to index vectors later in the book. One thing that people often find confusing when they start using R is knowing when to use and not use quotation marks. The general rule is that you use quotation marks when you want to refer to a character string literally, but no quotation marks when you want to refer to the value in a previously-defined object. For example, if you saved the string “Anderson” as the object my_name (my_name &lt;- “Anderson”), then in later code, if you type my_name (no quotation marks), you’ll get “Anderson”, while if you type out “my_name” (with quotation marks), you’ll get “my_name” (what you typed, literally). One thing that makes this rule confusing is that there are a few cases in R where you really should (by this rule) use quotation marks, but the function is coded to let you be lazy and get away without them. One example is the library function. In the code earlier in this section to load the “phonenumber” package, you want to literally load the package “phonenumber”, rather than load whatever character string is saved in the object named phonenumber. However, library is one of the functions where you can be lazy and skip the quotation marks, and it will still load “phonenumber” for you. Therefore, if you want, this function also works if you call library(phonenumber) (without the quotation marks) instead of how we actually called it (library(phonenumber)). 1.5.2 Dataframes A dataframe is a 2-dimensional object, and is made of one or more vectors of the same length stuck together side-by-side. It is the closest R has to an Excel spreadsheet-type structure. For example, here’s a dataframe with some basic information about the Beatles: ## # A tibble: 4 x 4 ## first_name last_name birth_year alive ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 John Lennon 1940. FALSE ## 2 Paul McCartney 1942. TRUE ## 3 Ringo Starr 1940. TRUE ## 4 George Harrison 1943. FALSE Note that each row of this dataframe gives a different observation (in this case, our unit of observation is a Beatle). Each column gives a different type of information (first name, last name, birth year, and whether they’re still alive) for each of the observations (Beatles). Notice that the number of elements in each of the columns must be the same in this dataframe, but that the different columns can have different classes of data (e.g., character vectors for first_name and last_name, logical value of TRUE or FALSE for alive). You can create dataframes using the data_frame function from the tibble package. However, most often you will create a dataframe by reading in data from a file, using something like read_csv from the readr package. There are base R functions for both of these tasks (data.frame and read.csv, respectively), eliminating the need to load additional packages with a library call. However, the series of packages that make up what’s called the “tidyverse” have brought a huge improvement in the ease and speed of working with data in R. We will be teaching these tools in this course, and that’s why we’re going directly to data_frame and read_csv from the start, rather than base R equivalents. Later in the course, we’ll talk more about this “tidyverse” and what makes it so great. To create a dataframe, you can use the data_frame function from the tibble package. The general format for using data_frame is: ## Note: Generic code [name of object] &lt;- data_frame([1st column name] = [1st column content], [2nd column name] = [2nd column content]) with an equals sign between the column name and column content for each column, and commas between each of the columns. Here is an example of the code used to create the beatles object shown above: library(tibble) beatles &lt;- data_frame(first_name = c(&quot;John&quot;, &quot;Paul&quot;, &quot;Ringo&quot;, &quot;George&quot;), last_name = c(&quot;Lennon&quot;, &quot;McCartney&quot;, &quot;Starr&quot;, &quot;Harrison&quot;), birth_year = c(1940, 1942, 1940, 1943), alive = c(FALSE, TRUE, TRUE, FALSE)) You can also create a dataframe by sticking together vectors you already have saved as R objects. For example: fibonacci_seq &lt;- data_frame(num_in_seq = one_to_five, fibonacci_num = fibonacci) fibonacci_seq ## # A tibble: 5 x 2 ## num_in_seq fibonacci_num ## &lt;chr&gt; &lt;dbl&gt; ## 1 one 1. ## 2 two 1. ## 3 three 2. ## 4 four 3. ## 5 five 5. Note that this call requires that the one_to_five and fibonacci vectors are the same length, although they don’t have to be (and in this case aren’t) the same class of objects (one_to_five is a character class, fibonacci is numeric). You can put more than one function call in a single line of R code, as in this example (the c creates a vector, while the data.frame creates a dataframe, using the vectors created by the calls to c). When you use multiple functions within a single R call, R will evaluate starting from the inner-most parentheses out, much like the order of operations in a math equation with parentheses. You can use square-bracket indexing ([..., ...]) for dataframes, too, but now they’ll have two dimensions (rows, then columns). Put the rows you want before the comma, the columns after. If you want all of something (e.g., all rows in the dataframe), leave the designated spot blank. Here are two examples of using square-bracket indexing to pull a subset of the fibonacci_seq dataframe we created above: fibonacci_seq[1:2, 2] # First two rows, second column ## # A tibble: 2 x 1 ## fibonacci_num ## &lt;dbl&gt; ## 1 1. ## 2 1. fibonacci_seq[5, ] # Last row, all columns ## # A tibble: 1 x 2 ## num_in_seq fibonacci_num ## &lt;chr&gt; &lt;dbl&gt; ## 1 five 5. If you forget to put the comma in the indexing for a dataframe (e.g., fibonacci_seq[1:2]), you will index out the columns that fall at that position or positions. To avoid confusion, I suggest that you always use indexing with a comma when working with dataframes. So far, we’ve only shown how to create dataframes from scratch within an R session. Usually, however, you’ll create R dataframes instead by reading in data from an outside file using the read_csv from the readr package and related functions. For example, you might want to analyze data on all the guests that came on the Daily Show, circa Jon Stewart. If you have this data in a comma-separated (csv) file on your computer called “daily_show_guests.csv”, you can read it into your R session with the following code: library(readr) daily_show &lt;- read_csv(&quot;daily_show_guests.csv&quot;, skip = 4) In this code, the read_csv function is reading in the data from the file “daily_show_guests.csv”, while the gets arrow (&lt;-) assigns that data to the object daily_show, which you can then reference in later code to explore and plot the data. Once you’ve read in the data and saved the resulting dataframe as an object, you can use square-bracket indexing to look at the first two rows in the data: daily_show[1:2, ] ## # A tibble: 2 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard You can use the functions dim, nrow, and ncol to figure out the dimensions (number of rows and columns) of a dataframe: dim(daily_show) ## [1] 2693 5 nrow(daily_show) ## [1] 2693 ncol(daily_show) ## [1] 5 1.6 Using R functions 1.6.1 Function structure In general, functions in R take the following structure: ## Generic code function.name(parameter 1 = argument 1, parameter 2 = argument 2, parameter 3 = argument 3) The result of the function will be output to your R session, unless you choose to save the output in an object: ## Generic code new_object &lt;- function.name(parameter 1 = argument 1, parameter 2 = argument 2, parameter 3 = argument 3) Here are some example function calls, to give you examples of this structure: The head function prints out the first few rows of a dataframe. By default, it prints out six rows. With the n option, you can change the number of rows it prints out: head(daily_show) ## # A tibble: 6 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin head(daily_show, n = 3) ## # A tibble: 3 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman The read_csv function (from the readr package) reads data from a comma-separated flat file into R. The skip option allows you to skip some of the first few lines of the file, in case the data starts a few lines into the file. daily_show &lt;- read_csv(&quot;daily_show_guests.csv&quot;, skip = 4) Within the function call, parameters allow you to customize the function to run in a certain way (e.g., use a certain dataframe as an input, change the number of lines printed out from the default value, skip some lines when reading in data). Some function parameters will have default arguments, which means that you don’t have to put a value for that parameter for the function to run, but you can if you want the function to do something other than the default. 1.6.2 Function help files You can find out more about a function, include what parameters it has and what the default values, if any, are by using ? before the function name in the R console. For example, to find out more about the read_csv command, run: ?read_csv From the “Usage” section of the help file, you can figure out that the only required parameter is file, the pathname of the file that you want to read in, since this is the only argument in the “Usage” example without an argument value: read_csv(file, col_names = TRUE, col_types = NULL, locale = default_locale(), na = c(&quot;&quot;, &quot;NA&quot;), quoted_na = TRUE, quote = &quot;\\&quot;&quot;, comment = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = show_progress()) You can also see from this “Usage” section that the default value of col_names is TRUE (use the first row of the data as the column names), the default value of skip is 0 (don’t skip any lines), etc. The “Arguments” section explains each of the parameters, and possible arguments that each can take. For example, here is the explanation of the n_max parameter in the read_csv function: n_max: Maximum number of records to read. From this, you can determine that you should put in a whole number, 0 or higher, and the function will skip that many line of the file before it starts reading in a dataframe when you run read_csv. 1.6.3 Function parameters Each function parameter has a name (e.g., n_max, col_names, file). The safest way to call a function in R is to use the structure parameter name = argument value for every parameter, like this: head(x = daily_show, n = 3) However, you can also give argument values by position. For example, in the head function, the first parameter is x, the object you want to look at, and the second is n, the number of elements you want to include when you look at the object. If you know this, you can call head using the shorter call: head(daily_show, 3) If you use position alone, you will have problems if you don’t include arguments in exactly the right order. However, if you use parameter names to set each argument, it doesn’t matter what order you include arguments when calling a function: # These two calls return the exact same object head(x = daily_show, n = 3) head(n = 3, x = daily_show) Because code tends to be more robust to errors when you use parameter names to set arguments, we recommend against using position, rather than name, to give arguments when calling functions, at least while you’re learning R. It’s too easy to forget the exact order and get errors in your code. However, there is one exception– the first argument to a function is almost always required (i.e., there’s not a default value), and you very quickly learn what the first parameter of most functions are as soon as you start using the function regularly. Therefore, it’s fine to use position alone to specify the first argument in a function, but for now always use the parameter name to set any later arguments: head(daily_show, n = 3) Using the full parameter names for arguments can take a bit more time, since it requires more typing. However, RStudio helps you out with that by offering code completion or tab completion. Once you start typing the first few letters of a parameter name within a function call, try pressing the tab key. All possible arguments that start with those letters should show up, and you can scroll through to pick the right one, or keep typing until the argument you want is atnthe top of the list of choices, and then press the tab key again. 1.7 R scripts This is a good point in learning R for you to start putting your code in R scripts, rather than entering commands at the console. An R script is a plain text file where you can save a series of R commands. You can save the script and open it up later to see (or re-do) what you did earlier, just like you could with something like a Word document when you’re writing a paper. To open a new R script in RStudio, go to the menu bar and select “File” -&gt; “New File” -&gt; “R Script”. Alternatively, you can use the keyboard shortcut Command-Shift-N. Figure 1.6 gives an example of an R script file opened in RStudio and points out some interesting elements. Figure 1.6: Example of an R script in RStudio. To save a script you’re working on, you can click on the “Save” button (which looks like a floppy disk) at the top of your R script window in RStudio or use the keyboard shortcut Command-S. You should save R scripts using a “.R” file extension. Within the R script, you’ll usually want to type your code so there’s one command per line. If your command runs long, you can write a single call over multiple lines. It’s unusual to put more than one command on a single line of a script file, but you can if you separate the commands with semicolons (;). These rules all correspond to how you can enter commands at the console. Running R code from a script file is very easy in RStudio. You can use either the “Run” button or Command-Return, and any code that is selected (i.e., that you’ve highlighted with your cursor) will run at the console. You can use this functionality to run a single line of code, multiple lines of code, or even just part of a specific line of code. If no code is highlighted, then R will instead run all the code on the line with the cursor and then move the cursor down to the next line in the script. You can also run all of the code in a script. To do this, use the “Source” button at the top of the script window. You can also run the entire script either from the console or from within another script by using the source() function, with the filename of the script you want to run as the argument. For example, to run all of the code in a file named “MyFile.R” that is saved in your current working directory, run: source(&quot;MyFile.R&quot;) You can add comments into an R script to let others know (and remind yourself) what you’re doing and why. To do this, use R’s comment character, #. Any line on a script line that starts with # will not be read by R. You can also take advantage of commenting to comment out certain parts of code that you don’t want to run at the moment. While it’s generally best to write your R code in a script and run it from there rather than entering it interactively at the R console, there are some exceptions. A main example is when you’re initially checking out a dataset, to make sure you’ve read it in correctly. It often makes more sense to run commands for this task, like str(), head(), tail(), and summary(), at the console. These are all examples of commands where you’re trying to look at something about your data right now, rather than code that builds toward your analysis, or helps you read in or clean up your data. 1.7.1 Commenting code Sometimes, you’ll want to include notes in your code. You can do this in all programming languages by using a comment character to start the line with your comment. In R, the comment character is the hash symbol, #. R will skip any line that starts with # in a script. For example, if you run the following code: # Don&#39;t print this. &quot;But print this&quot; ## [1] &quot;But print this&quot; R will only print the second, uncommented line. You can also use a comment in the middle of a line, to add a note on what you’re doing in that line of the code. R will skip any part of the code from the hash symbol on. For example: &quot;Print this&quot; ## But not this, it&#39;s a comment. ## [1] &quot;Print this&quot; There’s typically no reason to use code comments when running commands at the R console. However, it’s very important to get in the practice of including meaningful comments in R scripts. This helps you remember what you did when you revisit your code later. “You know you’re brilliant, but maybe you’d like to understand what you did 2 weeks from now.” – Linus Torvalds 1.8 In-course Exercise 1.8.1 About the dataset For today’s class, you’ll be using a dataset of all the guests on The Daily Show when Jon Stewart was the host. This data was originally collected by Nate Silver’s website, FiveThirtyEight and is available on FiveThirtyEight’s GitHub page under the Creative Commons Attribution 4.0 International License. I have copied this data into my GitHub repository for this class. The only change made to the original file was to add (commented) attribution information at the start of the file. First, check out a bit more about this data and its source: Check out the Creative Commons license. What are we allowed to do with this data? What restrictions are there on using the data? It’s often helpful to use prior knowledge to help check out or validate your dataset. One thing we might want to know about this data is if it covers the whole time that Jon Stewart hosted The Daily Show. Use Google to find out the dates he started and finished as host. Briefly browse around FiveThirtyEight’s GitHub data page. What are some other datasets available that you find interesting? For any dataset, you can scroll to the bottom of the page to get to the compiled README.md content, which gives the full titles and links to relevant datasets. You can also click on any dataset to get more information. Look at the GitHub page for this Daily Show data. How many columns will be in this dataset? What kind of information does the data include? What do the columns show? What do the rows show? In this exercise, you’re using data posted by FiveThirtyEight on GitHub. We’ll be using a lot of data that’s on GitHub this semester, and GitHub is being used behind-the-scenes for both this book and the course note slides. We’ll talk more about GitHub later, but you might find it interesting to explore a bit now. It’s a place where people can post, work on, and share code in a number of programming languages– it’s been referred to as “Facebook for Nerds”. You can search GitHub repositories and code specifically by programming language, so it can be a good way to find example R code from which to learn. If you have extra time: Check out the related article on FiveThirtyEight. What are some specific questions they used this data to answer for this article? Who is Nate Silver? 1.8.2 Manually creating vectors and a dataframe Start by manually creating some vectors and data frames with a small subset of this data. Use the concatenate function (c) to create a vector “from scratch” with the names of the five guests to appear on the show (these could be the first five guests, or you could also randomly pick five guests). Assign this vector to an object named five_guests. What class (numeric or character) do you think this vector will be? Will you need to use quotation marks for each element you add to the vector? Use square bracket indexing to print out the following subsets of this vector (you’ll have one R call per subset): (1) The first guest in the vector; (2) The third and fifth guests; (3) The second through fourth guests. Create a new vector called first_guest with just the first set, using the square bracket indexing you used in the previous step. In the same way, create a vector with the year of each of these guests’ appearances. Assign this vector to an object named appearance_year. What class (numeric or character) do you think this vector will be? Will you need to use quotation marks for each element you add to the vector? Use the class function to determine the classes (e.g., numeric, character) of each of the vectors you just created. Combine these two vectors to create a dataframe named guest_list. For the columns, use the same column names used in the original, raw data for the guest names and appearance year. Print out this dataframe at the R console to make sure it looks like you thought it would. Use square bracket indexing to print out the following subsets of this dataframe (you’ll have one R call per subset): (1) The appearance year of the first guest; (2) Names of the third through fifth guests; (3) Names of all guests; (4) Both names and appearance years of the first and third guests. The str function can be used to figure out the structure of a dataframe. Run this command on the guest_list dataframe you created. What information does this give you? Use the helpfile for str to help you figure this out (which you can access by running ?str). Do you see anything that surprises you? Use the ls function to list all the objects you currently have defined in your R session. Compare this list to the “Environment” pane in RStudio. Example R code: # I picked five random guests from throughout the dataset. The guests you pick will # likely be different. # Create a vector with the names of five guests five_guests &lt;- c(&quot;Miss Piggy&quot;, &quot;Stanley Tucci&quot;, &quot;Kermit the Frog&quot;, &quot;Hank Azaria&quot;, &quot;Al Gore&quot;) # Use square-bracket indexing to print out some subsets of the data five_guests[1] ## [1] &quot;Miss Piggy&quot; five_guests[c(3, 5)] ## [1] &quot;Kermit the Frog&quot; &quot;Al Gore&quot; five_guests[2:4] ## [1] &quot;Stanley Tucci&quot; &quot;Kermit the Frog&quot; &quot;Hank Azaria&quot; # Save just the first guest in a separate object first_guest &lt;- five_guests[1] first_guest ## [1] &quot;Miss Piggy&quot; # Create a vector with the year of the appearance of each guest appearance_year &lt;- c(1999, 2000, 2001, 2001, 2002) # Figure out the classes of the two vectors you just created class(five_guests) ## [1] &quot;character&quot; class(appearance_year) ## [1] &quot;numeric&quot; # Create the data frame, then print it out to make sure it looks like you thought # it would library(tibble) guest_list &lt;- data_frame(Raw_Guest_List = five_guests, YEAR = appearance_year) guest_list ## # A tibble: 5 x 2 ## Raw_Guest_List YEAR ## &lt;chr&gt; &lt;dbl&gt; ## 1 Miss Piggy 1999. ## 2 Stanley Tucci 2000. ## 3 Kermit the Frog 2001. ## 4 Hank Azaria 2001. ## 5 Al Gore 2002. # Use square bracket indexing to print subsets of the data frame guest_list[1, 2] ## # A tibble: 1 x 1 ## YEAR ## &lt;dbl&gt; ## 1 1999. guest_list[3:5, 1] ## # A tibble: 3 x 1 ## Raw_Guest_List ## &lt;chr&gt; ## 1 Kermit the Frog ## 2 Hank Azaria ## 3 Al Gore guest_list[ , 1] ## # A tibble: 5 x 1 ## Raw_Guest_List ## &lt;chr&gt; ## 1 Miss Piggy ## 2 Stanley Tucci ## 3 Kermit the Frog ## 4 Hank Azaria ## 5 Al Gore guest_list[c(1, 3), ] ## # A tibble: 2 x 2 ## Raw_Guest_List YEAR ## &lt;chr&gt; &lt;dbl&gt; ## 1 Miss Piggy 1999. ## 2 Kermit the Frog 2001. # Use `str` to check out the structure of the data frame you created str(guest_list) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ Raw_Guest_List: chr &quot;Miss Piggy&quot; &quot;Stanley Tucci&quot; &quot;Kermit the Frog&quot; &quot;Hank Azaria&quot; ... ## $ YEAR : num 1999 2000 2001 2001 2002 1.8.3 Installing and using a package The stringr package includes a number of functions that make it easier to work with character strings in R. In particular, it includes functions to change the capitalization of words in character stings. Here, you’ll install and load this package and then use it to work with the five_guests vector we created in the last section. If you have not already installed the stringr package, install it from CRAN. Load the stringr package in your current R session, so you will be able to use its functions. Check if the package has a vignette. If so, check out out that vignette. See if you can use the str_to_lower function from the stringr package to convert all the names in your five_guests vector to lowercase. See if you can find a function in the stringr package that you can use to convert all the names in your five_guests vector to uppercase. (Hint: At the R console, try typing ?stringr:: and then the Tab key.) Example R code: # If you need to, install the package from CRAN install.packages(&quot;stringr&quot;) # Load the package into your current R session library(stringr) # Open the package&#39;s vignette vignette(&quot;stringr&quot;) # Convert the `five_guests` strings to lowercase str_to_lower(five_guests) ## [1] &quot;miss piggy&quot; &quot;stanley tucci&quot; &quot;kermit the frog&quot; &quot;hank azaria&quot; ## [5] &quot;al gore&quot; # Convert the `five_guests` strings to uppercase str_to_upper(five_guests) ## [1] &quot;MISS PIGGY&quot; &quot;STANLEY TUCCI&quot; &quot;KERMIT THE FROG&quot; &quot;HANK AZARIA&quot; ## [5] &quot;AL GORE&quot; 1.8.4 Getting the data onto your computer Next, we will work with the whole dataset. Download the data from GitHub onto your computer. In class, we created an R Project for you to use for this class. Put the Daily Show data in that directory. Take the following steps to get the data onto your computer Download the file from GitHub. Right click on Raw and then choose “Download linked file”. Put the file into the directory you created for this course. Use the list.files command to make sure that the “daily_show_guests.csv” file is in your current working directory (we’ll talk more about workign directories, listing files in your working directory, and R Projects later in the semester). # List the files in your current working directory list.files() [1] &quot;daily_show_guests.csv&quot; 1.8.5 Getting the data into R Now that you have the dataset in your working directory, you can read it into R. This dataset is in a csv (comma separated values) format. (We will talk more about different file formats in Week 2.) You can read csv files into R using the function read_csv from the readr package. Read the data into your R session If you do not already have it, install the readr package. Then load this package within your current R session using library. Use the read_csv function from the readr package to read the data into R and save it as the object daily_show. Use the help file for the read_csv function to figure out how this function works. To pull that up, type ?read_csv at the R console. Can you figure out why it’s critical to use the skip option and set it to 4? (We will be talking a lot more about the read_csv function in Week 2, so don’t worry if you don’t completely understand it right now.) Note that you need to put the file name in quotation marks. What would have happened if you’d used read_csv but hadn’t saved the result as the object daily_show? (For example, you’d run the code read_csv(&quot;daily_show_guests.csv&quot;, skip = 4) rather than daily_show &lt;- read_csv(&quot;daily_show_guests.csv&quot;).) Example R code: # Install (if needed) and load the `readr` package install.packages(&quot;readr&quot;) # You only need to do this if you # do not already have the `readr` # package. library(readr) # Read in dataframe from the csv file with Daily Show guests daily_show &lt;- read_csv(&quot;daily_show_guests.csv&quot;, skip = 4) ## Parsed with column specification: ## cols( ## YEAR = col_integer(), ## GoogleKnowlege_Occupation = col_character(), ## Show = col_character(), ## Group = col_character(), ## Raw_Guest_List = col_character() ## ) # Print out the first few rows daily_show ## # A tibble: 2,693 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin ## 7 1999 Singer-lyricist 1/20/99 Musician Michael Stipe ## 8 1999 model 1/21/99 Media Carmen Electra ## 9 1999 actor 1/25/99 Acting Matthew Lillard ## 10 1999 stand-up comedian 1/26/99 Comedy David Cross ## # ... with 2,683 more rows If you have extra time: Say this was a really big dataset. You want to check out just the first 10 rows to make sure that you’ve got your code right before you take the time to pull in the whole dataset. Use the help file for read_csv to figure out how to only read in a few rows. Look through the help file for other options available for read_csv. Can you think of examples when some of these options would be useful? Look again at the version of this raw data on FiveThirtyEight’s GitHub page (rather than the course’s GitHub repository, where you downloaded the data for the course exercise). How are these two versions of the raw data different? How would you need to change your read_csv call if you changed to use the FiveThirtyEight version of the raw data? Example R code: # Read in only the first 10 rows of the dataset daily_show_first10 &lt;- read_csv(&quot;daily_show_guests.csv&quot;, skip = 4, n_max = 10) ## Parsed with column specification: ## cols( ## YEAR = col_integer(), ## GoogleKnowlege_Occupation = col_character(), ## Show = col_character(), ## Group = col_character(), ## Raw_Guest_List = col_character() ## ) # Check the dataframe daily_show_first10 ## # A tibble: 10 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin ## 7 1999 Singer-lyricist 1/20/99 Musician Michael Stipe ## 8 1999 model 1/21/99 Media Carmen Electra ## 9 1999 actor 1/25/99 Acting Matthew Lillard ## 10 1999 stand-up comedian 1/26/99 Comedy David Cross 1.8.6 Checking out the data You now have the data available in your current R session as the daily_show object. You’ll want to check it out to make sure it read in correctly, and also to get a feel for the data. Throughout, you can use the help pages to figure out more about any of the functions being used (for example, ?dim). Take the following steps to check out the dataset Use the dim function to find out how many rows and columns this dataframe has. Based on what you found out about the data from the GitHub page, does it have the number of columns you expected? Based on what you know about the data (that it includes all the guests who came on The Daily Show with Jon Stewart), do you think it has about the right number of rows? Use indexing to look at the first two rows of the dataset. Based on this, what does each row “measure” (unit of observation)? What information (variables) do you get for each “measurement”? As a reminder, indexing uses square brackets immediately after the object name. If the object has two dimensions, like a dataframe (rows and columns), you put the rows you want, then a comma, then the columns you want. If you want all rows (or columns), you leave that space blank. For example, if you wanted to get the first two rows and the first three columns, you’d use daily_show[1:2, 1:3]. If you wanted to get the first five rows and all the columns, you’d use daily_show[1:5, ]. The head function can be used to explore the first few rows of dataframes (see the helpfile at ?head). Use the head function to look at the first few rows of the dataframe. Does it look like the rows go in order by date? What was the date of Jon Stewart’s first show? Does it look like this dataset covers that first show? Use the tail function to look at the last few rows of the dataframe. What is the last show date covered by the dataframe? Who was the last guest? Use the str function to get more details about the daily_show dataframe you read in. Example R code: # Use indexing to see a subset of the data daily_show[1:2, ] ## # A tibble: 2 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard # Check the dimensions of the data dim(daily_show) ## [1] 2693 5 head(daily_show) ## # A tibble: 6 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin tail(daily_show) ## # A tibble: 6 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2015 actor 7/28/15 Acting Tom Cruise ## 2 2015 biographer 7/29/15 Media Doris Kearns Goodwin ## 3 2015 director 7/30/15 Media J. J. Abrams ## 4 2015 stand-up comedian 8/3/15 Comedy Amy Schumer ## 5 2015 actor 8/4/15 Acting Denis Leary ## 6 2015 comedian 8/5/15 Comedy Louis C.K. If you have extra time: Say you wanted to look at the first ten rows of the dataframe, rather than the first six. How could you use an option with head to do this? Example R code: # Look at the first few rows of the data head(daily_show, n = 10) ## # A tibble: 10 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin ## 7 1999 Singer-lyricist 1/20/99 Musician Michael Stipe ## 8 1999 model 1/21/99 Media Carmen Electra ## 9 1999 actor 1/25/99 Acting Matthew Lillard ## 10 1999 stand-up comedian 1/26/99 Comedy David Cross 1.8.7 Using the data to answer questions Nate Silver was a guest on The Daily Show. Let’s use this data to figure out how many times he was a guest and when he was on the show. Find out more about Nate Silver on The Daily Show The subset function can be combined with logical statements to help you create a specific subset of data. For example, if you only wanted data from guest visits in 1999, you could run subset(daily_show, YEAR == 1999). Check out the helpfile for subset and use the function to create a new dataframe that only has the rows of daily_show when Nate Silver was a guest (Raw_Guest_List == &quot;Nate Silver&quot;). Save this as an object named nate_silver. Print out the full nate_silver dataframe by typing nate_silver. (You could just use this to answer both questions, but still try the next steps. They would be important with a bigger dataset.) To count the number of times Nate Silver was a guest, you’ll need to count the number of rows in the new dataset. You can either use the dim function or the nrow function to do this. What additional information does the dim function give you? To get the dates when Nate Silver was a guest, you can print out just the Show column of the dataframe. There are a few ways you can do this using indexing: nate_silver[ , 3] (since Show is the third column), nate_silver[ , &quot;Show&quot;], or nate_silver$Show. Try these. Example R code: # Create a subset of the data with just Nate Silver appearances nate_silver &lt;- subset(daily_show, Raw_Guest_List == &quot;Nate Silver&quot;) # Investigate this subset of the data nate_silver ## # A tibble: 3 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2012 Statistician 10/17/12 Media Nate Silver ## 2 2012 Statistician 11/7/12 Media Nate Silver ## 3 2014 Statistician 3/27/14 Media Nate Silver dim(nate_silver) ## [1] 3 5 nrow(nate_silver) ## [1] 3 nate_silver[ , 3] ## # A tibble: 3 x 1 ## Show ## &lt;chr&gt; ## 1 10/17/12 ## 2 11/7/12 ## 3 3/27/14 nate_silver[ , &quot;Show&quot;] ## # A tibble: 3 x 1 ## Show ## &lt;chr&gt; ## 1 10/17/12 ## 2 11/7/12 ## 3 3/27/14 If you have extra time: Was Nate Silver the only statistician to be a guest on the show? What were the occupations that were only represented by one guest visit? Since GoogleKnowlege_Occupation is a factor, you can use the table function to create a new vector with the number of times each value of GoogleKnowlege_Occupation shows up. You can put this information into a new vector and then pull out only the values that equal 1 (so, only had one guest). (Note that “Statistician” doesn’t show up– there was only one person who was a guest, but he had three visits.) Pick your favorite “one-off” example and find out who the guest was for that occupation. Example R code: statisticians &lt;- subset(daily_show, GoogleKnowlege_Occupation == &quot;Statistician&quot;) statisticians ## # A tibble: 3 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2012 Statistician 10/17/12 Media Nate Silver ## 2 2012 Statistician 11/7/12 Media Nate Silver ## 3 2014 Statistician 3/27/14 Media Nate Silver num_visits &lt;- table(daily_show[ , 2]) head(num_visits) # Note: This is a vector rather than a dataframe ## ## - 0 academic Academic accountant activist ## 1 4 3 3 1 14 head(names(num_visits[num_visits == 1])) ## [1] &quot;-&quot; &quot;accountant&quot; &quot;administrator&quot; ## [4] &quot;advocate&quot; &quot;aei president&quot; &quot;afghan politician&quot; subset(daily_show, GoogleKnowlege_Occupation == &quot;chess player&quot;) ## # A tibble: 1 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2012 chess player 11/8/12 Misc Katie Dellamaggiore and P… subset(daily_show, GoogleKnowlege_Occupation == &quot;mathematician&quot;) ## # A tibble: 1 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005 mathematician 9/14/05 Academic Dr. William A. Dembski subset(daily_show, GoogleKnowlege_Occupation == &quot;orca trainer&quot;) ## # A tibble: 1 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2015 orca trainer 3/26/15 Athletics John Hargrove subset(daily_show, GoogleKnowlege_Occupation == &quot;Puzzle Creator&quot;) ## # A tibble: 1 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2003 Puzzle Creator 8/20/03 Media Will Shortz subset(daily_show, GoogleKnowlege_Occupation == &quot;Scholar&quot;) ## # A tibble: 1 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005 Scholar 6/13/05 Academic Larry Diamond 1.8.8 Writing your code as an R script While the R console is fine for initially exploring data, you should get in the habit of writing up R code in an R script for most of your data analysis projects in R. Open a new R script and save it to your current working directory (i.e., wherever you saved the data you downloaded for this exercise). Take some of the code that you wrote for this exercise (including the function to read the data into R). Put it in the R script. Do not put more than one function call per line (but it’s fine to have longer function calls span a few lines). Use the “Run” button to run a single line of this code. Check the console to see what happens when you do. Highlight a few lines of the code and use “Run” to run them. Try using the keyboard shortcut (Command-Return) to run the line of code your cursor is currently on. Try doing this with a function call that runs across several lines of the R script file– what do you see at the console? Try running the whole script using “Source”. Again, look at the console after you “source” the script. Close your R session (and save any changes to your R script). Do not save your R session history. Re-open R and see if you can re-open your R script and re-run it. Try using ls() to list the objects in your R session before and after you re-run your script. Does anything about the result surprise you? "],
["entering-and-cleaning-data-1.html", "Chapter 2 Entering and cleaning data #1 2.1 Overview 2.2 Reading data into R 2.3 Directories and pathnames 2.4 Data cleaning 2.5 Dates and filtering 2.6 Piping 2.7 In-course Exercise", " Chapter 2 Entering and cleaning data #1 Download a pdf of the lecture slides covering this topic. 2.1 Overview There are four basic steps you will often repeat as you prepare to analyze data in R: Identify where the data is (If it’s on your computer, which directory? If it’s online, what’s the url?) Read data into R (e.g., read_delim, read_csv from the readr package) using the file path you figured out in step 1 Check to make sure the data came in correctly (dim, head, tail, str) Clean the data up In this chapter, I’ll go basics for each of these steps, as well as dive a bit deeper into some related topics you should learn now to make your life easier as you get started using R for research. 2.2 Reading data into R The following video covers the slides in this section on “Reading data into R”: Data comes in files of all shapes and sizes. R has the capability to read data in from many of these, even proprietary files for other software (e.g., Excel and SAS files). As a small sample, here are some of the types of data files that R can read and work with: Flat files (much more about these in just a minute) Files from other statistical packages (SAS, Excel, Stata, SPSS) Tables on webpages (e.g., the table on ebola outbreaks near the end of this Wikipedia page) Data in a database (e.g., MySQL, Oracle) Data in JSON and XML formats Really crazy data formats used in other disciplines (e.g., netCDF files from climate research, MRI data stored in Analyze, NIfTI, and DICOM formats) Geographic shapefiles Data through APIs Often, it is possible to read in and clean up even incredibly messy data, by using functions like scan and readLines to read the data in a line at a time, and then using regular expressions (which I’ll cover in the “Intermediate” section of the course) to clean up each line as it comes in. In over a decade of coding in R, I think the only time I’ve come across a data file I couldn’t get into R was for proprietary precision agriculture data collected at harvest by a combine. 2.2.1 Reading local flat files Much of the data that you will want to read in will be in flat files. Basically, these are files that you can open using a text editor; the most common type you’ll work with are probably comma-separated files (often with a .csv or .txt file extension). Most flat files come in two general categories: Fixed width files; and Delimited files: “.csv”: Comma-separated values “.tab”, “.tsv”: Tab-separated values Other possible delimiters: colon, semicolon, pipe (“|”) Fixed width files are files where a column always has the same width, for all the rows in the column. These tend to look very neat and easy-to-read when you open them in a text editor. For example, the first few rows of a fixed-width file might look like this: Fixed width files used to be very popular, and they make it easier to look at data when you open the file in a text editor. However, now it’s pretty rare to just use a text editor to open a file and check out the data, and these files can be a bit of a pain to read into R and other programs because you sometimes have to specify exactly how wide each of the columns is. You may come across a fixed width file every now and then, though, particularly when working with older data sets, so it’s useful to be able to recognize one and to know how to read it in. Course Number Day Time Intro to Epi 501 M/W/F 9:00-9:50 Advanced Epi 521 T/Th 1:00-2:15 Delimited files use some delimiter (for example, a column or a tab) to separate each column value within a row. The first few rows of a delimited file might look like this: Course, Number, Day, Time &quot;Intro to Epi&quot;, 501, &quot;M/W/F&quot;, &quot;9:00-9:50&quot; &quot;Advanced Epi&quot;, 521, &quot;T/Th&quot;, &quot;1:00-2:15&quot; Delimited files are very easy to read into R. You just need to be able to figure out what character is used as a delimiter (commas in the example above) and specify that to R in the function call to read in the data. These flat files can have a number of different file extensions. The most generic is .txt, but they will also have ones more specific to their format, like .csv for a comma-delimited file or .fwf for a fixed with file. R can read in data from both fixed with and delimited flat files. The only catch is that you need to tell R a bit more about the format of the flat file, including whether it is fixed width or delimited. If the file is fixed width, you will usually have to tell R the width of each column. If the file is delimited, you’ll need to tell R which delimiter is being used. If the file is delimited, you can use the read_delim family of functions from the readr package to read it in. This family of functions includes several specialized functions. All members of the read_delim family are doing the same basic thing. The only difference is what defaults each function has for the delimiter (delim). Members of the read_delim family include: Function Delimiter read_csv comma read_csv2 semi-colon read_table2 whitespace read_tsv tab You can use read_delim to read in any delimited file, regardless of the delimiter. However, you will need to specify the delimiter using the delim parameters. If you remember the more specialized function call (e.g., read_csv for a comma delimited file), therefore, you can save yourself some typing. For example, to read in the Ebola data, which is comma-delimited, you could either use read_table with a delim argument specified or use read_csv, in which case you don’t have to specify delim: library(readr) # The following two calls do the same thing ebola &lt;- read_delim(&quot;data/country_timeseries.csv&quot;, delim = &quot;,&quot;) ebola &lt;- read_csv(&quot;data/country_timeseries.csv&quot;) ## Parsed with column specification: ## cols( ## Date = col_character(), ## Day = col_integer(), ## Cases_Guinea = col_integer(), ## Cases_Liberia = col_integer(), ## Cases_SierraLeone = col_integer(), ## Cases_Nigeria = col_integer(), ## Cases_Senegal = col_integer(), ## Cases_UnitedStates = col_integer(), ## Cases_Spain = col_integer(), ## Cases_Mali = col_integer(), ## Deaths_Guinea = col_integer(), ## Deaths_Liberia = col_integer(), ## Deaths_SierraLeone = col_integer(), ## Deaths_Nigeria = col_integer(), ## Deaths_Senegal = col_integer(), ## Deaths_UnitedStates = col_integer(), ## Deaths_Spain = col_integer(), ## Deaths_Mali = col_integer() ## ) The message that R prints after this call (“Parsed with column specification:..”) lets you know what classes were used for each column (this function tries to guess the appropriate class and typically gets it right). You can suppress the message using the cols_types = cols() argument. If readr doesn’t correctly guess some of the columns classes you can use the type_convert() function to take another go at guessing them after you’ve tweaked the formats of the rogue columns. This family of functions has a few other helpful options you can specify. For example, if you want to skip the first few lines of a file before you start reading in the data, you can use skip to set the number of lines to skip. If you only want to read in a few lines of the data, you can use the n_max option. For example, if you have a really long file, and you want to save time by only reading in the first ten lines as you figure out what other options to use in read_delim for that file, you could include the option n_max = 10 in the read_delim call. Here is a table of some of the most useful options common to the read_delim family of functions: Option Description skip How many lines of the start of the file should you skip? col_names What would you like to use as the column names? col_types What would you like to use as the column types? n_max How many rows do you want to read in? na How are missing values coded? Remember that you can always find out more about a function by looking at its help file. For example, check out ?read_delim and ?read_fwf. You can also use the help files to determine the default values of arguments for each function. So far, we’ve only looked at functions from the readr package for reading in data files. There is a similar family of functions available in base R, the read.table family of functions. The readr family of functions is very similar to the base R read.table functions, but have some more sensible defaults. Compared to the read.table family of functions, the readr functions: Work better with large datasets: faster, includes progress bar Have more sensible defaults (e.g., characters default to characters, not factors) I recommend that you always use the readr functions rather than their base R alternatives, given these advantages. However, you are likely to come across code that someone else has written that uses one of these base R functions, so it’s helpful to know what they are. Functions in the read.table family include: read.csv read.delim read.table read.fwf The readr package is a member of the tidyverse of packages. The tidyverse describes an evolving collection of R packages with a common philosophy, and they are unquestionably changing the way people code in R. Many were developed in part or full by Hadley Wickham and others at RStudio. Many of these packages are less than ten years old, but have been rapidly adapted by the R community. As a result, newer examples of R code will often look very different from the code in older R scripts, including examples in books that are more than a few years old. In this course, I’ll focus on “tidyverse” functions when possible, but I do put in details about base R equivalent functions or processes at some points—this will help you interpret older code. You can download all the tidyverse packages using install.packages(“tidyverse”), library(tidyverse) makes all the tidyverse functions available for use. 2.2.2 Reading in other file types Later in the course, we’ll talk about how to open a variety of other file types in R. However, you might find it immediately useful to be able to read in files from other statistical programs. There are two “tidyverse” packages—readxl and haven—that help with this. They allow you to read in files from the following formats: File type Function Package Excel read_excel readxl SAS read_sas haven SPSS read_spss haven Stata read_stata haven 2.3 Directories and pathnames The following video covers this section on “Directories and pathnames”: 2.3.1 Directory structure So far, we’ve only looked at reading in files that are located in your current working directory. For example, if you’re working in an R Project, by default the project will open with that directory as the working directory, so you can read files that are saved in that project’s main directory using only the file name as a reference. However, you’ll often want to read in files that are located somewhere else on your computer, or even files that are saved on another computer (for example, data files that are posted online). Doing this is very similar to reading in a file that is in your current working directory; the only difference is that you need to give R some directions so it can find the file. The most common case will be reading in files in a subdirectory of your current working directory. For example, you may have created a “data” subdirectory in one of your R Projects directories to keep all the project’s data files in the same place while keeping the structure of the main directory fairly clean. In this case, you’ll need to direct R into that subdirectory when you want to read one of those files. To understand how to give R these directions, you need to have some understanding of the directory structure of your computer. It seems a bit of a pain and a bit complex to have to think about computer directory structure in the “basics” part of this class, but this structure is not terribly complex once you get the idea of it. There are a couple of very good reasons why it’s worth learning now. First, many of the most frustrating errors you get when you start using R trace back to understanding directories and filepaths. For example, when you try to read a file into R using only the filename, and that file is not in your current working directory, you will get an error like: Error in file(file, &quot;rt&quot;) : cannot open the connection In addition: Warning message: In file(file, &quot;rt&quot;) : cannot open file &#39;Ex.csv&#39;: No such file or directory This error is especially frustrating when you’re new to R because it happens at the very beginning of your analysis—you can’t even get your data in. Also, if you don’t understand a bit about working directories and how R looks for the file you’re asking it to find, you’d have no idea where to start to fix this error. Second, once you understand how to use pathnames, especially relative pathnames, to tell R how to find a file that is in a directory other than your working directory, you will be able to organize all of your files for a project in a much cleaner way. For example, you can create a directory for your project, then create one subdirectory to store all of your R scripts, and another to store all of your data, and so on. This can help you keep very complex projects more structured and easier to navigate. We’ll talk about these ideas more in the course sections on Reproducible Research, but it’s good to start learning how directory structures and filepaths work early. Your computer organizes files through a collection of directories. Chances are, you are fairly used to working with these in your daily life already (although you may call them “folders” rather than “directories”). For example, you’ve probably created new directories to store data files and Word documents for a specific project. Figure 2.1 gives an example file directory structure for a hypothetical computer. Directories are shown in blue, and files in green. Figure 2.1: An example of file directory structure. You can notice a few interesting things from Figure 2.1. First, you might notice the structure includes a few of the directories that you use a lot on your own computer, like Desktop, Documents, and Downloads. Next, the directory at the very top is the computer’s root directory, /. For a PC, the root directory might something like C:; for Unix and Macs, it’s usually /. Finally, if you look closely, you’ll notice that it’s possible to have different files in different locations of the directory structure with the same file name. For example, in the figure, there are files names heat_mort.csv in both the CourseText directory and in the example_data directory. These are two different files with different contents, but they can have the same name as long as they’re in different directories. This fact—that you can have files with the same name in different places—should help you appreciate how useful it is that R requires you to give very clear directions to describe exactly which file you want R to read in, if you aren’t reading in something in your current working directory. You will have a home directory somewhere near the top of your structure, although it’s likely not your root directory. In the hypothetic computer in Figure 2.1, the home directory is /Users/brookeanderson. I’ll describe just a bit later how you can figure out what your own home directory is on your own computer. 2.3.2 Working directory When you run R, it’s always running from within some working directory, which will be one of the directories somewhere in your computer’s directory structure. At any time, you can figure out which directory R is working in by running the command getwd() (short for “get working directory”). For example, my R session is currently running in the following directory: getwd() ## [1] &quot;/Users/_gbanders/r_course/RProgrammingForResearch&quot; This means that, for my current R session, R is working in the RProgrammingForResearch subdirectory of my brookeanderson directory (which is my home directory). There are a few general rules for which working directory R will start in when you open an R session. These are not absolute rules, but they’re generally true. If you have R closed, and you open it by double-clicking on an R script, then R will generally open with, as its working directory, the directory in which that script is stored. This is often a very convenient convention, because often any of the data you’ll be reading in for that script is somewhere near where the script file is saved in the directory structure. If you open R by double-clicking on the R icon in “Applications” (or something similar on a PC), R will start in its default working directory. You can find out what this is, or change it, in RStudio’s “Preferences”. Finally, later in the course, if you open an R Project, R will start in that project’s working directory (the directory in which the .Rproj file for the project is stored). 2.3.3 File and directory pathnames Once you get a picture of how your directories and files are organized, you can use pathnames, either absolute or relative, to read in files from different directories than your current working directory. Pathnames are the directions for getting to a directory or file stored on your computer. When you want to reference a directory or file, you can use one of two types of pathnames: Relative pathname: How to get to the file or directory from your current working directory Absolute pathname: How to get to the file or directory from anywhere on the computer Absolute pathnames are a bit more straightforward conceptually, because they don’t depend on your current working directory. However, they’re also a lot longer to write, and they’re much less convenient if you’ll be sharing some of your code with other people who might run it on their own computers. I’ll explain this second point a bit more later in this section. Absolute pathnames give the full directions to a directory or file, starting all the way at the root directory. For example, the heat_mort.csv file in the CourseText directory has the absolute pathname: &quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot; You can use this absolute pathname to read this file in using any of the readr functions to read in data. This absolute pathname will always work, regardless of your current working directory, because it gives directions from the root—it will always be clear to R exactly what file you’re talking about. Here’s the code to use to read that file in using the read.csv function with the file’s absolute pathname: heat_mort &lt;- read_csv(&quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot;) The relative pathname, on the other hand, gives R the directions for how to get to a directory or file from the current working directory. If the file or directory you’re looking for is pretty close to your current working directory in your directory structure, then a relative pathname can be a much shorter way to tell R how to get to the file than an absolute pathname. However, the relative pathname depends on your current working directory—the relative pathname that works perfectly when you’re working in one directory will not work at all once you move into a different working directory. As an example of a relative pathname, say you’re working in the directory RCourseFall2015 within the file structure shown in Figure 2.1, and you want to read in the heat_mort.csv file in the CourseText directory. To get from RCourseFall2015 to that file, you’d need to look in the subdirectory CourseText, where you could find heat_mort.csv. Therefore, the relative pathname from your working directory would be: &quot;CourseText/heat_mort.csv&quot; You can use this relative pathname to tell R where to find and read in the file: heat_mort &lt;- read_csv(&quot;CourseText/heat_mort.csv&quot;) While this pathname is much shorter than the absolute pathname, it is important to remember that if you are working in a different working directory, this relative pathname would no longer work. There are a few abbreviations that can be really useful for pathnames: Shorthand Meaning ~ Home directory . Current working directory .. One directory up from current working directory ../.. Two directories up from current working directory These can help you keep pathnames shorter and also help you move “up-and-over” to get to a file or directory that’s not on the direct path below your current working directory. For example, my home directory is /Users/brookeanderson. You can use the list.files() function to list all the files in a directory. If I wanted to list all the files in my Downloads directory, which is a direct sub-directory of my home directory, I could use: list.files(&quot;~/Downloads&quot;) As a second example, say I was working in the working directory CourseText, but I wanted to read in the heat_mort.csv file that’s in the example_data directory, rather than the one in the CourseText directory. I can use the .. abbreviation to tell R to look up one directory from the current working directory, and then down within a subdirectory of that. The relative pathname in this case is: &quot;../Week2_Aug31/example_data/heat_mort.csv&quot; This tells R to look one directory up from the working directory (..) (this is also known as the parent directory of the current directory), which in this case is to RCourseFall2015, and then down within that directory to Week2_Aug31, then to example_data, and then to look there for the file heat_mort.csv. The relative pathname to read this file while R is working in the CourseTest directory would be: heat_mort &lt;- read_csv(&quot;../Week2_Aug31/example_data/heat_mort.csv&quot;) Relative pathnames “break” as soon as you tried them from a different working directory—this fact might make it seem like you would never want to use relative pathnames, and would always want to use absolute ones instead, even if they’re longer. If that were the only consideration (length of the pathname), then perhaps that would be true. However, as you do more and more in R, there will likely be many occasions when you want to use relative pathnames instead. They are particularly useful if you ever want to share a whole directory, with all subdirectories, with a collaborator. In that case, if you’ve used relative pathnames, all the code should work fine for the person you share with, even though they’re running it on their own computer. Conversely, if you’d used absolute pathnames, none of them would work on another computer, because the “top” of the directory structure (i.e., for me, /Users/brookeanderson/Desktop) will almost definitely be different for your collaborator’s computer than it is for yours. If you’re getting errors reading in files, and you think it’s related to the relative pathname you’re using, it’s often helpful to use list.files() to make sure the file you’re trying to load is in the directory that the relative pathname you’re using is directing R to. 2.3.4 Diversion: paste This is a good opportunity to explain how to use some functions that can be very helpful when you’re using relative or absolute pathnames: paste() and paste0(). As a bit of important background information, it’s important that you understand that you can save a pathname (absolute or relative) as an R object, and then use that R object in calls to later functions like list.files() and read_csv(). For example, to use the absolute pathname to read the heat_mort.csv file in the CourseText directory, you could run: my_file &lt;- &quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot; heat_mort &lt;- read_csv(my_file) You’ll notice from this code that the pathname to get to a directory or file can sometimes become ungainly and long. To keep your code cleaner, you can address this by using the paste or paste0 functions. These functions come in handy in a lot of other applications, too, but this is a good place to introduce them. The paste() function is very straightforward. It takes, as inputs, a series of different character strings you want to join together, and it pastes them together in a single character string. (As a note, this means that your result vector will only be one element long, for basic uses of paste(), while the inputs will be several different character stings.) You separate all the different things you want to paste together using with commas in the function call. For example: paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;) ## [1] &quot;Sunday Monday Tuesday&quot; length(c(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;)) ## [1] 3 length(paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;)) ## [1] 1 The paste() function has an option called sep =. This tells R what you want to use to separate the values you’re pasting together in the output. The default is for R to use a space, as shown in the example above. To change the separator, you can change this option, and you can put in just about anything you want. For example, if you wanted to paste all the values together without spaces, you could use sep = &quot;&quot;: paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, sep = &quot;&quot;) ## [1] &quot;SundayMondayTuesday&quot; As a shortcut, instead of using the sep = &quot;&quot; option, you could achieve the same thing using the paste0 function. This function is almost exactly like paste, but it defaults to &quot;&quot; (i.e., no space) as the separator between values by default: paste0(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;) ## [1] &quot;SundayMondayTuesday&quot; With pathnames, you will usually not want spaces. Therefore, you could think about using paste0() to write an object with the pathname you want to ultimately use in commands like list.files() and setwd(). This will allow you to keep your code cleaner, since you can now divide long pathnames over multiple lines: my_file &lt;- paste0(&quot;/Users/brookeanderson/Desktop/&quot;, &quot;RCourseFall2015/CourseText/heat_mort.csv&quot;) heat_mort &lt;- read_csv(my_file) You will end up using paste() and paste0() for many other applications, but this is a good example of how you can start using these functions to start to get a feel for them. 2.3.5 Reading online flat files So far, I’ve only shown you how to read in data from files that are saved to your computer. R can also read in data directly from the web. If a flat file is posted online, you can read it into R in almost exactly the same way that you would read in a local file. The only difference is that you will use the file’s url instead of a local file path for the file argument. With the read_* family of functions, you can do this both for flat files from a non-secure webpage (i.e., one that starts with http) and for files from a secure webpage (i.e., one that starts with https), including GitHub and Dropbox. For example, to read in data from this GitHub repository of Ebola data, you can run: url &lt;- paste0(&quot;https://raw.githubusercontent.com/cmrivers/&quot;, &quot;ebola/master/country_timeseries.csv&quot;) ebola &lt;- read_csv(url) ebola[1:3, 1:3] ## # A tibble: 3 x 3 ## Date Day Cases_Guinea ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1/5/2015 289 2776 ## 2 1/4/2015 288 2775 ## 3 1/3/2015 287 2769 2.4 Data cleaning The following video covers the section on “Data Cleaning”: Once you have loaded data into R, you’ll likely need to clean it up a little before you’re ready to analyze it. Here, I’ll go over the first steps of how to do that with functions from dplyr, another package in the tidyverse. Here are some of the most common data-cleaning tasks, along with the corresponding dplyr function for each: Task dplyr function Renaming columns rename Filtering to certain rows filter Selecting certain columns select Adding or changing columns mutate In this section, I’ll describe how to do each of these four tasks; in later sections of the course, we’ll go much deeper into how to clean messier data. For the examples in this section, I’ll use example data listing guests to the Daily Show. To follow along with these examples, you’ll want to load that data, as well as load the dplyr package (install it using install.packages if you have not already): library(dplyr) daily_show &lt;- read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) I’ve used this data in previous examples, but as a reminder, here’s what it looks like: head(daily_show) ## # A tibble: 6 x 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin 2.4.1 Renaming columns A first step is often re-naming the columns of the dataframe. It can be hard to work with a column name that: is long includes spaces or other special characters includes upper case You can check out the column names for a dataframe using the colnames function, with the dataframe object as the argument. Several of the column names in daily_show have some of these issues: colnames(daily_show) ## [1] &quot;YEAR&quot; &quot;GoogleKnowlege_Occupation&quot; ## [3] &quot;Show&quot; &quot;Group&quot; ## [5] &quot;Raw_Guest_List&quot; To rename these columns, use rename. The basic syntax is: ## Generic code rename(dataframe, new_column_name_1 = old_column_name_1, new_column_name_2 = old_column_name_2) The first argument is the dataframe for which you’d like to rename columns. Then you list each pair of new versus old column names (in that order) for each of the columns you want to rename. To rename columns in the daily_show data using rename, for example, you would run: daily_show &lt;- rename(daily_show, year = YEAR, job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) head(daily_show, 3) ## # A tibble: 3 x 5 ## year job date category guest_name ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman Many of the functions in tidyverse packages, including those in dplyr, provide exceptions to the general rule about when to use quotation marks versus when to leave them off. Unfortunately, this may make it a bit hard to learn when to use quotation marks versus when not to. One way to think about this, which is a bit of an oversimplification but can help as you’re learning, is to assume that anytime you’re using a dplyr function, every column in the dataframe you’re working with has been loaded to your R session as its own object. 2.4.2 Selecting columns Next, you may want to select only some columns of the dataframe. You can use the select function from dplyr to subset the dataframe to certain columns. The basic structure of this command is: ## Generic code select(dataframe, column_name_1, column_name_2, ...) In this call, you first specify the dataframe to use and then list all of the column names to include in the output dataframe, with commas between each column name. For example, to select all columns in daily_show except year (since that information is already included in date), run: select(daily_show, job, date, category, guest_name) ## # A tibble: 2,693 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman ## 4 film actress 1/14/99 Acting Gillian Anderson ## 5 actor 1/18/99 Acting David Alan Grier ## 6 actor 1/19/99 Acting William Baldwin ## 7 Singer-lyricist 1/20/99 Musician Michael Stipe ## 8 model 1/21/99 Media Carmen Electra ## 9 actor 1/25/99 Acting Matthew Lillard ## 10 stand-up comedian 1/26/99 Comedy David Cross ## # ... with 2,683 more rows Don’t forget that, if you want to change column names in the saved object, you must reassign the object to be the output of rename. If you run one of these cleaning functions without reassigning the object, R will print out the result, but the object itself won’t change. You can take advantage of this, as I’ve done in this example, to look at the result of applying a function to a dataframe without changing the original dataframe. This can be helpful as you’re figuring out how to write your code. The select function also provides some time-saving tools. For example, in the last example, we wanted all the columns except one. Instead of writing out all the columns we want, we can use - with the columns we don’t want to save time: daily_show &lt;- select(daily_show, -year) head(daily_show, 3) ## # A tibble: 3 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman 2.4.3 Add or change columns You can change a column or add a new column using the mutate function from the dplyr package. That function has the syntax: # Generic code mutate(dataframe, changed_column = function(changed_column), new_column = function(other arguments)) For example, the job column in daily_show sometimes uses upper case and sometimes does not (this call uses the unique function to list only unique values in this column): head(unique(daily_show$job), 10) ## [1] &quot;actor&quot; &quot;Comedian&quot; &quot;television actress&quot; ## [4] &quot;film actress&quot; &quot;Singer-lyricist&quot; &quot;model&quot; ## [7] &quot;stand-up comedian&quot; &quot;actress&quot; &quot;comedian&quot; ## [10] &quot;Singer-songwriter&quot; To make all the observations in the job column lowercase, use the str_to_lower function from the stringr package within a mutate function: library(stringr) mutate(daily_show, job = str_to_lower(job)) ## # A tibble: 2,693 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman ## 4 film actress 1/14/99 Acting Gillian Anderson ## 5 actor 1/18/99 Acting David Alan Grier ## 6 actor 1/19/99 Acting William Baldwin ## 7 singer-lyricist 1/20/99 Musician Michael Stipe ## 8 model 1/21/99 Media Carmen Electra ## 9 actor 1/25/99 Acting Matthew Lillard ## 10 stand-up comedian 1/26/99 Comedy David Cross ## # ... with 2,683 more rows 2.4.4 Base R equivalents to dplyr functions Just so you know, all of these dplyr functions have alternatives, either functions or processes, in base R: dplyr Base R equivalent rename Reassign colnames select Square bracket indexing filter subset mutate Use $ to change / create columns You will see these alternatives used in older code examples. 2.5 Dates and filtering The following video covers the lecture material on working with dates in R and on filtering a dataframe to a subset of rows using logical operators: 2.5.1 Dates in R As part of the data cleaning process, you may want to change the class of some of the columns in the dataframe. For example, you may want to change a column from a character to a date. Here are some of the most common vector classes in R: Class Example character “Chemistry”, “Physics”, “Mathematics” numeric 10, 20, 30, 40 factor Male [underlying number: 1], Female [2] Date “2010-01-01” [underlying number: 14,610] logical TRUE, FALSE To find out the class of a vector (including a column in a dataframe – remember each column can be thought of as a vector), you can use class(): class(daily_show$date) ## [1] &quot;character&quot; It is especially common to need to convert dates during the data cleaning process, since date columns will usually be read into R as characters or factors – you can do some interesting things with vectors that are in a Date class that you cannot do with a vector in a character class. To convert a vector to the Date class, if you’d like to only use base R, you can use the as.Date function. I’ll walk through how to use as.Date, since it’s often used in older R code. However, I recommend in your own code that you instead use the lubridate package, which I’ll talk about later in this section. For example, to convert the date column in the daily_show data into a Date class, you can run: daily_show &lt;- mutate(daily_show, date = as.Date(date, format = &quot;%m/%d/%y&quot;)) head(daily_show, 3) ## # A tibble: 3 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1999-01-11 Acting Michael J. Fox ## 2 Comedian 1999-01-12 Comedy Sandra Bernhard ## 3 television actress 1999-01-13 Acting Tracey Ullman class(daily_show$date) ## [1] &quot;Date&quot; Once you have an object in the Date class, you can do things like plot by date, calculate the range of dates, and calculate the total number of days the dataset covers: range(daily_show$date) diff(range(daily_show$date)) You can convert dates expressed in a number of different ways into a Date class in R, as long as you can explain to R how to parse the format that the date is in before you convert it. The only tricky thing in converting objects into a Date class is learning the abbreviations for the format option of the as.Date function. Here are some common ones: Abbreviation Meaning %m Month as a number (e.g., 1, 05) %B Full month name (e.g., August) %b Abbreviated month name (e.g., Aug) %y Two-digit year (e.g., 99) %Y Four-digit year (e.g., 1999) %A Full weekday (e.g., Monday) %a Abberviated weekday (e.g., Mon) Here are some examples of what you would specify for the format argument of as.Date for some different original formats of date columns: Your date format 10/23/2008 “%m/%d%Y” 08-10-23 “%y-%m-%d” Oct. 23 2008 “%b. %d %Y” October 23, 2008 “%B %d, %Y” Thurs, 23 October 2008 “%a, %d %B %Y” You must use the format argument to specify what your date column looks like before it’s converted to a Date class, not how you’d like it to look after its converted. Once an objects is in a date class, it will always be printed out using a common format, unless you change it back into a character class. (Confusingly, there is a format function that you can use to convert from a Date class to a character class and, in that case, the format argument does specify how the final date will look. This is mainly useful as a last step in data analysis, when you’re creating plot labels of table columns, for example.) There is also a package in the tidyverse, called lubridate, that helps in parsing dates. In many cases you can use functions from this package to parse dates much more easily, without having to specify specific starting formats. The ymd function from lubridate can be used to parse a column into a Date class, regardless of the original format of the date, as long as the date elements are in the order: year, month, day. For example: library(lubridate) ## Warning: package &#39;lubridate&#39; was built under R version 3.4.4 ymd(&quot;2008-10-13&quot;) ## [1] &quot;2008-10-13&quot; ymd(&quot;&#39;08 Oct 13&quot;) ## [1] &quot;2008-10-13&quot; ymd(&quot;&#39;08 Oct 13&quot;) ## [1] &quot;2008-10-13&quot; The lubridate package has similar functions for other date orders or for date-times, including: dmy mdy ymd_h ymd_hm We could have used these to transform the date in daily_show, using the following pipe chain: daily_show &lt;- read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) %&gt;% rename(job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) %&gt;% select(-YEAR) %&gt;% mutate(date = mdy(date)) %&gt;% filter(category == &quot;Science&quot;) head(daily_show, 2) ## # A tibble: 2 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 neurosurgeon 2003-04-28 Science Dr Sanjay Gupta ## 2 scientist 2004-01-13 Science Catherine Weitz The lubridate package also includes functions to pull out certain elements of a date, including: wday mday yday month quarter year For example, we could use wday to create a new column with the weekday of each show: mutate(daily_show, show_day = wday(date, label = TRUE)) %&gt;% select(date, show_day, guest_name) %&gt;% slice(1:5) ## # A tibble: 5 x 3 ## date show_day guest_name ## &lt;date&gt; &lt;ord&gt; &lt;chr&gt; ## 1 2003-04-28 Mon Dr Sanjay Gupta ## 2 2004-01-13 Tue Catherine Weitz ## 3 2004-06-15 Tue Hassan Ibrahim ## 4 2005-09-06 Tue Dr. Marc Siegel ## 5 2006-02-13 Mon Astronaut Mike Mullane R functions tend to use the timezone of YOUR computer’s operating system by default, or UTC, or GMT. You need to be careful when working with dates and times to either specify the time zone or convince yourself the default behavior works for your application. 2.5.2 Filtering to certain rows Next, you might want to filter the dataset down so that it only includes certain rows. For example, you might want to get a dataset with only the guests from 2015, or only guests who are scientists. You can use the filter function from dplyr to filter a dataframe down to a subset of rows. The syntax is: ## Generic code filter(dataframe, logical statement) The logical statement in this call gives the condition that a row must meet to be included in the output data frame. For example, if you want to create a data frame that only includes guests who were scientists, you can run: scientists &lt;- filter(daily_show, category == &quot;Science&quot;) head(scientists) ## # A tibble: 6 x 4 ## job date category guest_name ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 neurosurgeon 2003-04-28 Science Dr Sanjay Gupta ## 2 scientist 2004-01-13 Science Catherine Weitz ## 3 physician 2004-06-15 Science Hassan Ibrahim ## 4 doctor 2005-09-06 Science Dr. Marc Siegel ## 5 astronaut 2006-02-13 Science Astronaut Mike Mullane ## 6 Astrophysicist 2007-01-30 Science Neil deGrasse Tyson To build a logical statement to use in filter, you’ll need to know some of R’s logical operators. Some of the most commonly used ones are: Operator Meaning Example == equals category == &quot;Acting&quot; != does not equal category != &quot;Comedy %in% is in category %in% c(&quot;Academic&quot;, &quot;Science&quot;) is.na() is missing is.na(job) !is.na() is not missing !is.na(job) &amp; and year == 2015 &amp; category == &quot;Academic&quot; | or year == 2015 | category == &quot;Academic&quot; We’ll use these logical operators a lot more as the course continues, so they’re worth learning by heart. Two common errors with logical operators are: (1) Using = instead of == to check if two values are equal; and (2) Using == NA instead of is.na to check for missing observations. 2.6 Piping The following video covers the lecture material on piping: So far, I’ve shown how to use these dplyr functions one at a time to clean up the data, reassigning the dataframe object at each step. However, there’s a trick called “piping” that will let you clean up your code a bit when you’re writing a script to clean data. If you look at the format of these dplyr functions, you’ll notice that they all take a dataframe as their first argument: # Generic code rename(dataframe, new_column_name_1 = old_column_name_1, new_column_name_2 = old_column_name_2) select(dataframe, column_name_1, column_name_2) filter(dataframe, logical statement) mutate(dataframe, changed_column = function(changed_column), new_column = function(other arguments)) Without piping, you have to reassign the dataframe object at each step of this cleaning if you want the changes saved in the object: daily_show &lt;-read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) daily_show &lt;- rename(daily_show, job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) daily_show &lt;- select(daily_show, -YEAR) daily_show &lt;- mutate(daily_show, job = tolower(job)) daily_show &lt;- filter(daily_show, category == &quot;Science&quot;) Piping lets you clean this code up a bit. It can be used with any function that inputs a dataframe as its first argument. It pipes the dataframe created right before the pipe (%&gt;%) into the function right after the pipe. With piping, therefore, the same data cleaning looks like: daily_show &lt;-read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) %&gt;% rename(job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) %&gt;% select(-YEAR) %&gt;% mutate(job = tolower(job)) %&gt;% filter(category == &quot;Science&quot;) Notice that, when piping, the first argument (the name of the dataframe) is excluded from all function calls that follow a pipe. This is because piping sends the dataframe from the last step into each of these functions as the dataframe argument. 2.7 In-course Exercise 2.7.1 Downloading and checking out the example data Download the whole directory for this week from Github (https://github.com/geanders/week_2_data). To do that, go the the GitHub page with data for this week’s exercise and, in the top right, choose “Clone or Download” and then choose “Download ZIP”. This will download a compressed file with the full directory of data, probably to your computer’s “Downloads” folder. Then move the directory into your course Project directory and “unzip” it (try double-clicking the file, or right click on the file and see if there’s a “decompress” or “unzip” option). All the files will be in a subdirectory—move them into the main Project directory (don’t do this in R, just use whatever technique you usually use on your computer to move files between directories). Look through the structure of the “data” directory. What files are in the directory? Which files are flat files? Which are delimited (one category of flat files), and what are their delimiters? Create a new R script to put all the code you use for this exercise. Create a subdirectory in your course directory called “R” and save this script there using a .R extension (e.g., “week_2.R”). 2.7.2 Reading in different types of files Now you’ll try reading in data from a variety of types of file formats. Try the following tasks: What type of flat file do you think the “ld_genetics.txt” file is? See if you can read it in and save it as the R object ld_genetics. Use the summary function to check out basic statistics on the data. Check out the file “measles_data/02-09-2015.txt”. What type of flat file do you think it is? Since it’s in a subdirectory, you’ll need to tell R how to get to it from the project directory, using something called a relative pathname (we’ll talk about this a lot more in the next section of the lecture). Read this file into R as an object named ca_measles, using the relative pathname (“measles_data/02-09-2015.txt”) in place of the file name in the read_tsv function call. Use the col_names option to name the columns “city” and “count”. What would the default column names be if you didn’t use this option (try this out by running read_csv without the col_names option)? Read in the Excel file “icd-10.xls” and assign it to the object name idc10. Use the readxl package to do that (examples are at the bottom of the linked page). Read in the SAS file icu.sas7bdat. To do this, use the haven package. Read the file into the R object icu. Example R code: # Load the `readr` package library(readr) # Use `read_tsv` to read this file. ld_genetics &lt;- read_tsv(&quot;ld_genetics.txt&quot;) ## Parsed with column specification: ## cols( ## pos = col_integer(), ## nA = col_integer(), ## nC = col_integer(), ## nG = col_integer(), ## nT = col_integer(), ## GCsk = col_integer(), ## TAsk = col_integer(), ## cGCsk = col_integer(), ## cTAsk = col_integer() ## ) summary(ld_genetics) ## pos nA nC nG ## Min. : 500 Min. :185 Min. :120.0 Min. : 85.0 ## 1st Qu.: 876000 1st Qu.:288 1st Qu.:173.0 1st Qu.:172.0 ## Median :1751500 Median :308 Median :190.0 Median :189.0 ## Mean :1751500 Mean :309 Mean :191.9 Mean :191.8 ## 3rd Qu.:2627000 3rd Qu.:329 3rd Qu.:209.0 3rd Qu.:208.0 ## Max. :3502500 Max. :463 Max. :321.0 Max. :326.0 ## nT GCsk TAsk cGCsk ## Min. :188.0 Min. :-189.0000 Min. :-254.000 Min. : -453 ## 1st Qu.:286.0 1st Qu.: -30.0000 1st Qu.: -36.000 1st Qu.:10796 ## Median :306.0 Median : 0.0000 Median : -2.000 Median :23543 ## Mean :307.2 Mean : -0.1293 Mean : -1.736 Mean :22889 ## 3rd Qu.:328.0 3rd Qu.: 29.0000 3rd Qu.: 32.500 3rd Qu.:34940 ## Max. :444.0 Max. : 134.0000 Max. : 205.000 Max. :46085 ## cTAsk ## Min. :-6247 ## 1st Qu.: 1817 ## Median : 7656 ## Mean : 7855 ## 3rd Qu.:15036 ## Max. :19049 # Use `read_tsv` to read this file. Because the first line # of the file is *not* the column names, you need to specify what the column # names should be with the `col_names` parameter. ca_measles &lt;- read_tsv(&quot;measles_data/02-09-2015.txt&quot;, col_names = c(&quot;city&quot;, &quot;count&quot;)) ## Parsed with column specification: ## cols( ## city = col_character(), ## count = col_integer() ## ) head(ca_measles) ## # A tibble: 6 x 2 ## city count ## &lt;chr&gt; &lt;int&gt; ## 1 ALAMEDA 6 ## 2 LOS ANGELES 20 ## 3 City of Long Beach 2 ## 4 City of Pasadena 4 ## 5 MARIN 2 ## 6 ORANGE 34 # You&#39;ll need the `readxl` package to read in the Excel file. Load that. library(readxl) # Use the `read_excel` function to read in the file. icd10 &lt;- read_excel(&quot;icd-10.xls&quot;) head(icd10) ## # A tibble: 6 x 2 ## Code `ICD Title` ## &lt;chr&gt; &lt;chr&gt; ## 1 A00-B99 I. Certain infectious and parasitic diseases ## 2 A00-A09 Intestinal infectious diseases ## 3 A00 Cholera ## 4 A00.0 Cholera due to Vibrio cholerae 01, biovar cholerae ## 5 A00.1 Cholera due to Vibrio cholerae 01, biovar eltor ## 6 A00.9 Cholera, unspecified # You&#39;ll need the `haven` function to read in the SAS file. Load that. library(haven) # Use the `read_sas` function to read in this file. icu &lt;- read_sas(&quot;icu.sas7bdat&quot;) icu[1:5, 1:5] ## # A tibble: 5 x 5 ## ID STA AGE GENDER RACE ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4. 1. 87. 1. 1. ## 2 8. 0. 27. 1. 1. ## 3 12. 0. 59. 0. 1. ## 4 14. 0. 77. 0. 1. ## 5 27. 1. 76. 1. 1. 2.7.3 Directory structure Once you have the data, I’d like you to try using getwd() to figure out your current working directory and list.files() to figure out which files you have in the directories near that current working directory. Start by creating a new subdirectory called “data” in your R Project directory for this class (if you don’t already have that subdirectory). Move the data you downloaded in the start of this In-Course Exercise into that “data” subdirectory. (For this, use whatever tools you would normally use on your computer to move files from one directory to another—you don’t have to do this part in R.) Keep the “measles” data in its own subdirectory (so, the “data” subdirectory of your project will have its own “measles” subdirectory, which will have those files). Check that you are, in fact, in the working directory you think you’re in. Run: getwd() Does it agree with the R project name in the top right hand corner of your R Studio window? Now, use the list.files function to print out which files or subdirectories you have in your current working directory: list.files() Try the following tasks: Read in the ebola data in country_timeseries.csv from your current working directory. This will require you to use a relative filename to direct R to how to find that file in the “data” subdirectory of your current working directory. Assign the data you read in to an R object named ebola. How many rows and columns does it have? What are the names of the columns? While staying in the same working directory, used list.files() to print the names of the available files in the “data” subdirectory. How about in the “R” subdirectory (if you have one)? Try to list the files in your “data” subdirectory using: A relative pathname An absolute pathname Now use a relative pathname along with list.files() to list all the files in the “measles_data” subdirectory. Then try to read in the Ebola data using the appropriate readr function and a relative pathname. Which method (absolute or relative pathnames) always used the same code, regardless of your current working directory? Which method used different code, depending on the starting working directory? Read in the ebola data in country_timeseries.csv from your current working directory. This will require you to use a relative filename to direct R to how to find that file in the “data” subdirectory of your current working directory. ebola &lt;- read_csv(&quot;data/country_timeseries.csv&quot;) How many rows and columns does it have? What are the names of the columns? dim(ebola) # Get the dimensions of the data (`nrow` and `ncol` would also work) colnames(ebola) # Get the column names (you can also just print the object: `ebola`) While staying in the same working directory, used list.files() to print the names of the available files in the “data” subdirectory. How about in the “R” subdirectory (if you have one)? list.files(&quot;data&quot;) list.files(&quot;R&quot;) Try to list the files in your “data” subdirectory using: + A relative pathname + An absolute pathname list.files(&quot;data&quot;) # This is using a relative pathname list.files(&quot;/Users/brookeanderson/Desktop/r_course_2018/data&quot;) # Absolute pathname # (Yours will be different and will depend on how your computer file # structure is set up.) Now use a relative pathname along with list.files() to list all the files in the “measles_data” subdirectory. list.files(&quot;data/measles_data&quot;) Then try to read in the Ebola data using the appropriate readr function and a relative pathname ebola &lt;- read_csv(&quot;data/country_timeseries.csv&quot;) If you have extra time: Find out some more about this Ebola dataset by checking out Caitlin Rivers’ Ebola data GitHub repository. Who is Caitlin Rivers? How did she put this dataset together? Search for R code related to Ebola research on GitHub. Go to the GitHub home page and use the search bar to search for “ebola”. On the results page, scroll down and use the “Language” sidebar on the left to choose repositories with R code. Did you find any interesting projects? When you list.files() for the “data” subdirectory, almost everything listed has a file extension, like .csv, .xls, .sas7bdat. One thing does not. Which one? Why does this listing not have a file extension? 2.7.4 Cleaning up data #1 Try out the following tasks: Copy the following code into an R script. Figure out what each line does, and add comments to each line of code describing what the code is doing. # Copy this code to an R script and add comments describing what each line is doing library(haven) icu &lt;- read_sas(&quot;data/icu.sas7bdat&quot;) icu &lt;- select(icu, ID, AGE, GENDER) icu &lt;- rename(icu, id = ID, age = AGE, gender = GENDER) icu &lt;- mutate(icu, gender = factor(gender, levels = c(0, 1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), id = as.character(id)) icu Following previous parts of the in-course exercise, you have an R object called ebola (if you need to, use some code from earlier in this in-course exercise to read in the data and create that object). Create an object called ebola_liberia that only has the columns with the date and the number of cases and deaths in Liberia. How many columns does this new dataframe have? How many observations? Change the column names to date, cases, and deaths. Add a column called ratio that has the ratio of deaths to cases for each observation (i.e., death counts divided by case counts). Example R code: # Load the dplyr package library(dplyr) ## Create a subset with just the Liberia columns and Date ebola_liberia &lt;- select(ebola, Date, Cases_Liberia, Deaths_Liberia) head(ebola_liberia) ## # A tibble: 6 x 3 ## Date Cases_Liberia Deaths_Liberia ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1/5/2015 NA NA ## 2 1/4/2015 NA NA ## 3 1/3/2015 8166 3496 ## 4 1/2/2015 8157 3496 ## 5 12/31/2014 8115 3471 ## 6 12/28/2014 8018 3423 ## How many colums and rows does the whole dataset have (could also use `dim`)? ncol(ebola_liberia) ## [1] 3 nrow(ebola_liberia) ## [1] 122 ## Rename the columns ebola_liberia &lt;- rename(ebola_liberia, date = Date, cases = Cases_Liberia, deaths = Deaths_Liberia) head(ebola_liberia) ## # A tibble: 6 x 3 ## date cases deaths ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1/5/2015 NA NA ## 2 1/4/2015 NA NA ## 3 1/3/2015 8166 3496 ## 4 1/2/2015 8157 3496 ## 5 12/31/2014 8115 3471 ## 6 12/28/2014 8018 3423 ## Add a `ratio` column ebola_liberia &lt;- mutate(ebola_liberia, ratio = deaths / cases) head(ebola_liberia) ## # A tibble: 6 x 4 ## date cases deaths ratio ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1/5/2015 NA NA NA ## 2 1/4/2015 NA NA NA ## 3 1/3/2015 8166 3496 0.428 ## 4 1/2/2015 8157 3496 0.429 ## 5 12/31/2014 8115 3471 0.428 ## 6 12/28/2014 8018 3423 0.427 2.7.5 Cleaning up data #2 For the ebola_liberia dataframe, what class is the date column currently in? Convert it to a Date class. What are the starting and ending dates of observations in this dataframe? This data has earliest dates last and latest dates first. Often, we want our data in chronological order. Change the dataset so it’s in chronological order, from the observation with the earliest date to the one with the latest date. Filter out all rows from the ebola_liberia dataframe that are missing death counts for Liberia. How many rows are in the dataframe now? Create a new object called first_five that has only the five observations with the highest death counts in Liberia. What date in this dataset had the most deaths? Example R code: ## What class is the `date` column? class(ebola_liberia$date) ## [1] &quot;character&quot; ## Use the `mdy` from `lubridate` to convert to Date class library(lubridate) ebola_liberia &lt;- mutate(ebola_liberia, date = mdy(date)) class(ebola_liberia$date) ## [1] &quot;Date&quot; head(ebola_liberia$date) ## [1] &quot;2015-01-05&quot; &quot;2015-01-04&quot; &quot;2015-01-03&quot; &quot;2015-01-02&quot; &quot;2014-12-31&quot; ## [6] &quot;2014-12-28&quot; ## What are the starting and ending dates? range(ebola_liberia$date) ## [1] &quot;2014-03-22&quot; &quot;2015-01-05&quot; ## Re-order the dataset from first date to last date ebola_liberia &lt;- arrange(ebola_liberia, date) head(ebola_liberia) ## # A tibble: 6 x 4 ## date cases deaths ratio ## &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2014-03-22 NA NA NA ## 2 2014-03-24 NA NA NA ## 3 2014-03-25 NA NA NA ## 4 2014-03-26 NA NA NA ## 5 2014-03-27 8 6 0.750 ## 6 2014-03-28 3 3 1.00 ## Filter out the rows that are missing death counts for Liberia ebola_liberia &lt;- filter(ebola_liberia, !is.na(deaths)) head(ebola_liberia) ## # A tibble: 6 x 4 ## date cases deaths ratio ## &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2014-03-27 8 6 0.750 ## 2 2014-03-28 3 3 1.00 ## 3 2014-03-29 7 2 0.286 ## 4 2014-03-31 8 4 0.500 ## 5 2014-04-01 8 5 0.625 ## 6 2014-04-04 18 7 0.389 nrow(ebola_liberia) ## [1] 81 ## Create an object with just the top five observations in terms of death counts first_five &lt;- arrange(ebola_liberia, desc(deaths)) # First, rearrange the rows by deaths first_five &lt;- slice(first_five, 1:5) # Limit the dataframe to the first five rows first_five # Two days tied for the highest deaths counts (Jan. 2 and 3, 2015). ## # A tibble: 5 x 4 ## date cases deaths ratio ## &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2015-01-02 8157 3496 0.429 ## 2 2015-01-03 8166 3496 0.428 ## 3 2014-12-31 8115 3471 0.428 ## 4 2014-12-28 8018 3423 0.427 ## 5 2014-12-24 7977 3413 0.428 If you have extra time: Try using the basic plotting function, plot(), to plot the number of cases of Ebola over time in Liberia from this dataframe. Do you think that the cases variable is measuring the count of cases for that day, or the cumulative number of cases up to that day? See if you can figure out more on Caitlin Rivers’ GitHub documentation. Do you notice any potential data quality issues in this data? Hint: The plot() function takes, as required arguments, the vector you want to plot on the x-axis and then the vector you want to plot on the y-axis, like plot([x vector], [y vector]). If you are pulling the vectors from a dataset, you will need to use indexing to pull out the column you want as a vector, like plot([dataframe name]$[column name for x], [dataframe]$[column name for y]). Example R code: ## Plot the data plot(ebola_liberia$date, ebola_liberia$cases) 2.7.6 Piping Try the following tasks: Copy the following “piped” code into an R script. Figure out what each line does, and add comments to each line of code describing what the code is doing. # Copy this code to an R script and add comments describing what each line is doing library(haven) icu &lt;- read_sas(&quot;data/icu.sas7bdat&quot;) %&gt;% select(ID, AGE, GENDER) %&gt;% rename(id = ID, age = AGE, gender = GENDER) %&gt;% mutate(gender = factor(gender, levels = c(0, 1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), id = as.character(id)) %&gt;% arrange(age) %&gt;% slice(1:10) icu In previous sections of the in-course exercise, you have created code to read in and clean the Ebola dataset to create ebola_liberia. This included the following cleaning steps: (1) selecting certain columns, (2) renaming those columns, (3) adding a ratio column, (4) mutating the date column to a Date class, (5) re-ordering the observations from earliest to latest date, and (6) removing observations for which the count of deaths in Liberia is missing. Re-write this code to create and clean ebola_liberia as “piped” code. Start from reading in the raw data. Example R code: ebola_liberia &lt;- read_csv(&quot;data/country_timeseries.csv&quot;) %&gt;% select(Date, Cases_Liberia, Deaths_Liberia) %&gt;% rename(date = Date, cases = Cases_Liberia, deaths = Deaths_Liberia) %&gt;% mutate(ratio = deaths / cases) %&gt;% mutate(date = mdy(date)) %&gt;% arrange(date) %&gt;% filter(!is.na(cases)) head(ebola_liberia) ## # A tibble: 6 x 4 ## date cases deaths ratio ## &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2014-03-27 8 6 0.750 ## 2 2014-03-28 3 3 1.00 ## 3 2014-03-29 7 2 0.286 ## 4 2014-03-31 8 4 0.500 ## 5 2014-04-01 8 5 0.625 ## 6 2014-04-04 18 7 0.389 "],
["exploring-data-1.html", "Chapter 3 Exploring data #1 3.1 Data from a package 3.2 Logical vectors 3.3 Simple statistics functions 3.4 Plots to explore data 3.5 In-course exercise", " Chapter 3 Exploring data #1 Download a pdf of the lecture slides covering this topic. 3.1 Data from a package So far we’ve covered two ways to get data into R: From flat files (either on your computer or online) From binary file formats like SAS and Excel. Many R packages come with their own data, which is very easy to load and use. For example, the faraway package, which complements Julian Faraway’s book Linear Models with R, has a dataset called worldcup that I’ll use for some examples and that you’ll use for part of this week’s in-course exercise. To load this dataset, first load the package with the data (faraway) and then use the data() function with the dataset name (“worldcup”) as the argument to the data function: library(faraway) data(&quot;worldcup&quot;) Unlike most data objects you’ll work with, datasets that are part of an R package will often have their own help files. You can access this help file for a dataset using the ? operator with the dataset’s name: ?worldcup This helpful will usually include information about the size of the dataset, as well as definitions for each of the columns. To get a list of all of the datasets that are available in the packages you currently have loaded, run data() without an option inside the parentheses: data() If you run the library function without any arguments—library()—it works in a similar way. R will open a list of all the R packages that you have installed on your computer and can open with a library call. For this chapter, we’ll be working with a modified version of the nepali dataset from the faraway package. This gives data from a study of the health of a group of Nepalese children. Each observation is a single measurement for a child; there can be multiple observations per child. We’ll use a modified version of this dataframe that limits it to the columns with the child’s id, sex, weight, height, and age, and limited to each child’s first measurement. To create this modified dataset, run the following code: library(dplyr) library(faraway) data(nepali) nepali &lt;- nepali %&gt;% # Limit to certain columns select(id, sex, wt, ht, age) %&gt;% # Convert id and sex to factors mutate(id = factor(id), sex = factor(sex, levels = c(1, 2), labels = c(&quot;Male&quot;, &quot;Female&quot;))) %&gt;% # Limit to first obs. per child distinct(id, .keep_all = TRUE) The first few rows of the data should now look like: nepali %&gt;% slice(1:4) ## # A tibble: 4 x 5 ## id sex wt ht age ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 120011 Male 12.8 91.2 41 ## 2 120012 Female 14.9 104. 57 ## 3 120021 Female 7.70 70.1 8 ## 4 120022 Female 12.1 86.4 35 3.2 Logical vectors Last week, you learned a lot about logical statements and how to use them with the filter function from the dplyr package. You can also use logical vectors, created with these logical statements, for a lot of other things. For example, you can use them directly in the square bracket indexing ([..., ...]) to pull out just the rows of a dataframe that meet a certain condition. For using logical statements in either context, it is helpful to understand a bit more about logical vectors. When you run a logical statement on a vector, you create a logical vector the same length as the original vector: length(nepali$sex) ## [1] 200 length(nepali$sex == &quot;Male&quot;) ## [1] 200 The logical vector (nepali$sex == &quot;Male&quot; in this example) will have the value TRUE at any position where the original vector (nepali$sex in this example) met the logical condition you tested, and FALSE anywhere else: head(nepali$sex) ## [1] Male Female Female Female Male Male ## Levels: Male Female head(nepali$sex == &quot;Male&quot;) ## [1] TRUE FALSE FALSE FALSE TRUE TRUE You can “flip” this logical vector (i.e., change every TRUE to FALSE and vice-versa) using the bang operator, !: is_male &lt;- nepali$sex == &quot;Male&quot; # Save this logical vector as the object named `is_male` head(is_male) ## [1] TRUE FALSE FALSE FALSE TRUE TRUE head(!is_male) ## [1] FALSE TRUE TRUE TRUE FALSE FALSE The bang operator turns out to be very useful. You will often find cases where it’s difficult to write a logical vector to get what you want, but fairly easy to write the inverse (find everything you don’t want). One example is filtering down to non-missing values—the is.na function will return TRUE for any value that is NA, so you can use !is.na() to identify any non-missing values. You can do a few cool things with a logical vector. For example, you can use it inside a filter function to pull out just the rows of a dataframe where is_male is TRUE: nepali %&gt;% filter(is_male) %&gt;% head() ## id sex wt ht age ## 1 120011 Male 12.8 91.2 41 ## 2 120023 Male 14.2 99.4 49 ## 3 120031 Male 13.9 96.4 46 ## 4 120051 Male 8.3 69.5 8 ## 5 120053 Male 15.8 96.0 54 ## 6 120062 Male 12.1 89.9 57 Or, with !, just the rows where is_male is FALSE: nepali %&gt;% filter(!is_male) %&gt;% head() ## id sex wt ht age ## 1 120012 Female 14.9 103.9 57 ## 2 120021 Female 7.7 70.1 8 ## 3 120022 Female 12.1 86.4 35 ## 4 120052 Female 11.8 83.6 32 ## 5 120061 Female 8.7 78.5 26 ## 6 120082 Female 11.2 79.8 36 You can also use sum() and table() with a logical vector to find out how many of the values in the vector are TRUE AND FALSE. You can use sum because R saves logical vectors at a basic level as 0 for FALSE and 1 for TRUE. Therefore, if you add up all the values in a logical vector, you’re adding up the number of observations with the value TRUE. In the example, you can use these functions to find out how many males and females are in the dataset: sum(is_male) ## [1] 107 sum(!is_male) ## [1] 93 table(is_male) ## is_male ## FALSE TRUE ## 93 107 Note that you could also achieve the same thing with dplyr functions. For example, you could use mutate with a logical statement to create an is_male column in the nepali dataframe, then group by the new is_male column and count the number of observations in each group using count: library(dplyr) nepali %&gt;% mutate(is_male = sex == &quot;Male&quot;) %&gt;% group_by(is_male) %&gt;% count() ## # A tibble: 2 x 2 ## # Groups: is_male [2] ## is_male n ## &lt;lgl&gt; &lt;int&gt; ## 1 FALSE 93 ## 2 TRUE 107 We will cover using summarize, including with data that has been grouped with group_by, later in this chapter. 3.3 Simple statistics functions 3.3.1 Summary statistics To explore your data, you’ll need to be able to calculate some simple statistics for vectors, including calculating the mean and range of continuous variables and counting the number of values in each category of a factor or logical vector. Here are some simple statistics functions you will likely use often: Function Description range() Range (minimum and maximum) of vector min(), max() Minimum or maximum of vector mean(), median() Mean or median of vector sd() Standard deviation of vector table() Number of observations per level for a factor vector cor() Determine correlation(s) between two or more vectors summary() Summary statistics, depends on class All of these functions take, as the main argument, the vector or vectors for which you want the statistic. If there are missing values in the vector, you’ll typically need to add an argument to say what to do with the missing values. The parameter name for this varies by function, but for many of these functions it’s na.rm = TRUE or use=&quot;complete.obs&quot;. mean(nepali$wt, na.rm = TRUE) ## [1] 10.18432 range(nepali$ht, na.rm = TRUE) ## [1] 52.4 104.1 sd(nepali$ht, na.rm = TRUE) ## [1] 12.64529 table(nepali$sex) ## ## Male Female ## 107 93 Most of these functions take a single vector as the input. The cor function, however, calculates the correlation between vectors and so takes two or more vectors. If you give it multiple values, it will give the correlation matrix for all the vectors. cor(nepali$wt, nepali$ht, use = &quot;complete.obs&quot;) ## [1] 0.9571535 cor((nepali %&gt;% select(wt, ht, age)), use = &quot;complete.obs&quot;) ## wt ht age ## wt 1.0000000 0.9571535 0.8931195 ## ht 0.9571535 1.0000000 0.9287129 ## age 0.8931195 0.9287129 1.0000000 R supports object-oriented programming. Your first taste of this shows up with the summary function. For the summary function, R does not run the same code every time. Instead, R first checks what type of object was input to summary, and then it runs a function (method) specific to that type of object. For example, if you input a continuous vector, like the ht column in nepali, to summary, the function will return the mean, median, range, and 25th and 75th percentile values: summary(nepali$wt) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 3.80 7.90 10.10 10.18 12.40 16.70 15 However, if you submit a factor vector, like the sex column in nepali, the summary function will return a count of how many elements of the vector are in each factor level (as a note, you could do the same thing with the table function): summary(nepali$sex) ## Male Female ## 107 93 The summary function can also input other data structures, including dataframes, lists, and special object types, like regression model objects. In each case, it performs different actions specific to the object type. Later in this section, we’ll cover regression models, and see what the summary function returns when it is used with regression model objects. 3.3.2 summarize function You will often want to use these functions in conjunction with the summarize function in dplyr. For example, to create a new dataframe with the mean weight of children in the nepali dataset, you can use mean inside a summarize function: library(dplyr) nepali %&gt;% summarize(mean_wt = mean(wt, na.rm = TRUE)) ## mean_wt ## 1 10.18432 There are also some special functions that are particularly useful with summarize and other dplyr functions. For example, the n function will calculate the number of observations and the first function will return the first value of a column: nepali %&gt;% summarize(n_children =n(), first_id = first(id)) ## n_children first_id ## 1 200 120011 See the “summary function” section of the the RStudio Data Wrangling cheatsheet for more examples of these special functions. Often, you will be more interested in summaries within certain groupings of your data, rather than overall summaries. For example, you may be interested in mean height and weight by sex, rather than across all children, for the nepali data. It is very easy to calculate these grouped summaries using dplyr—you just need to group data using the group_by function (also a dplyr function) before you run the summarize function: nepali %&gt;% group_by(sex) %&gt;% summarize(mean_wt = mean(wt, na.rm = TRUE), n_children =n(), first_id = first(id)) ## # A tibble: 2 x 4 ## sex mean_wt n_children first_id ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; ## 1 Male 10.5 107 120011 ## 2 Female 9.82 93 120012 Don’t forget that you need to save the output to a new object if you want to use it later. The above code, which creates a dataframe with summaries for Nepali children by sex, will only be printed out to your console if run as-is. If you’d like to save this output as an object to use later (for example, for a plot or table), you need to assign it to an R object. 3.4 Plots to explore data Exploratory data analysis is a key step in data analysis and plotting your data in different ways is an important part of this process. In this section, I will focus on the basics of ggplot2 plotting, to get you started creating some plots to explore your data. This section will focus on making useful, rather than attractive graphs, since at this stage we are focusing on exploring data for yourself rather than presenting results to others. Next week, I will explain more about how you can customize ggplot objects, to help you make plots to communicate with others. All of the plots we’ll make today will use the ggplot2 package (another member of the tidyverse!). If you don’t already have that installed, you’ll need to install it. You then need to load the package in your current session of R: # install.packages(&quot;ggplot2&quot;) ## Uncomment and run if you don&#39;t have `ggplot2` installed library(ggplot2) The process of creating a plot using ggplot2 follows conventions that are a bit different than most of the code you’ve seen so far in R (although it is somewhat similar to the idea of piping I introduced in the last chapter). The basic steps behind creating a plot with ggplot2 are: Create an object of the ggplot class, typically specifying the data and some or all of the aesthetics; Add on geoms and other elements to create and customize the plot, using +. You can add on one or many geoms and other elements to create plots that range from very simple to very customized. This week, we’ll focus on simple geoms and added elements, and then explore more detailed customization next week. If R gets to the end of a line and there is not some indication that the call is not over (e.g., %&gt;% for piping or + for ggplot2 plots), R interprets that as a message to run the call without reading in further code. A common error when writing ggplot2 code is to put the + to add a geom or element at the beginning of a line rather than the end of a previous line– in this case, R will try to execute the call too soon. To avoid errors, be sure to end lines with +, don’t start lines with it. 3.4.1 Initializing a ggplot object The first step in creating a plot using ggplot2 is to create a ggplot object. This object will not, by itself, create a plot with anything in it. Instead, it typically specifies the data frame you want to use and which aesthetics will be mapped to certain columns of that data frame (aesthetics are explained more in the next subsection). Use the following conventions to initialize a ggplot object: ## Generic code object &lt;- ggplot(dataframe, aes(x = column_1, y = column_2)) The data frame is the first parameter in a ggplot call and, if you like, you can use the parameter definition with that call (e.g., data = dataframe). Aesthetics are defined within an aes function call that typically is used within the ggplot call. While the ggplot call is the place where you will most often see an aes call, aes can also be used within the calls to add specific geoms. This can be particularly useful if you want to map aesthetics differently for different geoms in your plot. We’ll see some examples of this use of aes more in later sections, when we talk about customizing plots. The data parameter can also be used in geom calls, to use a different data frame from the one defined when creating the original ggplot object, although this tends to be less common. 3.4.2 Plot aesthetics Aesthetics are properties of the plot that can show certain elements of the data. For example, in Figure 3.1, color shows (is mapped to) gender, x-position shows height, and y-position shows weight in a sample data set of measurements of children in Nepal. Figure 3.1: Example of how different properties of a plot can show different elements to the data. Here, color indicates gender, position along the x-axis shows height, and position along the y-axis shows weight. This example is a subset of data from the nepali dataset in the faraway package. Any of these aesthetics could also be given a constant value, instead of being mapped to an element of the data. For example, all the points could be red, instead of showing gender. Which aesthetics are required for a plot depend on which geoms (more on those in a second) you’re adding to the plot. You can find out the aesthetics you can use for a geom in the “Aesthetics” section of the geom’s help file (e.g., ?geom_point). Required aesthetics are in bold in this section of the help file and optional ones are not. Common plot aesthetics you might want to specify include: Code Description x Position on x-axis y Position on y-axis shape Shape color Color of border of elements fill Color of inside of elements size Size alpha Transparency (1: opaque; 0: transparent) linetype Type of line (e.g., solid, dashed) 3.4.3 Adding geoms Next, you’ll want to add one or more geoms to create the plot. You can add these with + after the ggplot statement to initialize the ggplot object. Some of the most common geoms are: Plot type ggplot2 function Histogram (1 numeric variable) geom_histogram Scatterplot (2 numeric variables) geom_point Boxplot (1 numeric variable, possibly 1 factor variable) geom_boxplot Line graph (2 numeric variables) geom_line 3.4.4 Constant aesthetics Instead of mapping an aesthetic to an element of your data, you can use a constant value for it. For example, you may want to make all the points green, rather than having color map to gender: In this case, you’ll define that aesthetic when you add the geom, outside of an aes statement. In R, you can specify the shape of points with a number. Figure 3.2 shows the shapes that correspond to the numbers 1 to 25 in the shape aesthetic. This figure also provides an example of the difference between color (black for all these example points) and fill (red for these examples). You can see that some point shapes include a fill (21 for example), while some are either empty (1) or solid (19). Figure 3.2: Examples of the shapes corresponding to different numeric choices for the shape aesthetic. For all examples, color is set to black and fill to red. If you want to set color to be a constant value, you can do that in R using character strings for different colors. Figure 3.3 gives an example of some of the different blues available in R. To find links to listings of different R colors, google “R colors” and search by “Images”. Figure 3.3: Example of available shades of blue in R. 3.4.5 Useful plot additions There are also a number of elements that you can add onto a ggplot object using +. A few that are used very frequently are: Element Description ggtitle Plot title xlab, ylab x- and y-axis labels xlim, ylim Limits of x- and y-axis 3.4.6 Example dataset For the example plots, I’ll use a dataset in the faraway package called nepali. This gives data from a study of the health of a group of Nepalese children. library(faraway) data(nepali) I’ll be using functions from dplyr and ggplot2, so those need to be loaded: library(dplyr) library(ggplot2) Each observation is a single measurement for a child; there can be multiple observations per child. I used the following code to select only the columns for child id, sex, weight, height, and age. I also used distinct to limit the dataset to only include one measurement for each chile, the child’s first measurement in the dataset. nepali &lt;- nepali %&gt;% select(id, sex, wt, ht, age) %&gt;% mutate(id = factor(id), sex = factor(sex, levels = c(1, 2), labels = c(&quot;Male&quot;, &quot;Female&quot;))) %&gt;% distinct(id, .keep_all = TRUE) After this cleaning, the data looks like this: head(nepali) ## id sex wt ht age ## 1 120011 Male 12.8 91.2 41 ## 2 120012 Female 14.9 103.9 57 ## 3 120021 Female 7.7 70.1 8 ## 4 120022 Female 12.1 86.4 35 ## 5 120023 Male 14.2 99.4 49 ## 6 120031 Male 13.9 96.4 46 3.4.7 Histograms Histograms show the distribution of a single variable. Therefore, geom_histogram() requires only one main aesthetic, x, the (numeric) vector for which you want to create a histogram. For example, to create a histogram of children’s heights for the Nepali dataset (Figure 3.4), run: ggplot(nepali, aes(x = ht)) + geom_histogram() Figure 3.4: Basic example of plotting a histogram with ggplot2. This histogram shows the distribution of heights for the first recorded measurements of each child in the nepali dataset. If you run the code with no arguments for binwidth or bins in geom_histogram, you will get a message saying “stat_bin() using bins = 30. Pick better value with binwidth.”. This message is just saying that a default number of bins was used to create the histogram. You can use arguments to change the number of bins used, but often this default is fine. You may also get a message that observations with missing values were removed. You can add some elements to the histogram now to customize it a bit. For example (Figure @ref()), you can add a figure title (ggtitle) and clearer labels for the x-axis (xlab). You can also change the range of values shown by the x-axis (xlim). ggplot(nepali, aes(x = ht)) + geom_histogram(fill = &quot;lightblue&quot;, color = &quot;black&quot;) + ggtitle(&quot;Height of children&quot;) + xlab(&quot;Height (cm)&quot;) + xlim(c(0, 120)) Figure 3.5: Example of adding ggplot elements to customize a histogram. The geom geom_histogram also has special argument for setting the number of width of the bins used in the histogram. Figure ?? shows an example of how you can use the bins argument to change the number of bins that are used to make the histogram of height for the nepali dataset. ggplot(nepali, aes(x = ht)) + geom_histogram(fill = &quot;lightblue&quot;, color = &quot;black&quot;, bins = 40) Figure 3.6: Example of using the bins argument to change the number of bins used in a histogram. Similarly, the binwidth argument can be used to set the width of bins. Figure 3.7 shows an example of using this function to create a histogram of the Nepali children’s heights with binwidths of 10 centimeters (note that this argument is set in the same units as the x variable). ggplot(nepali, aes(x = ht)) + geom_histogram(fill = &quot;lightblue&quot;, color = &quot;black&quot;, binwidth = 10) Figure 3.7: Example of using the binwidth argument to set the width of each bin used in a histogram. 3.4.8 Scatterplots A scatterplot shows how one variable changes as another changes. You can use the geom_point geom to create a scatterplot. For example, to create a scatterplot of height versus age for the Nepali data (Figure 3.8), you can run the following code: ggplot(nepali, aes(x = ht, y = wt)) + geom_point() Figure 3.8: Example of creating a scatterplot. This scatterplot shows the relationship between children’s heights and weights within the nepali dataset. Again, you can use some of the options and additions to change the plot appearance. For example, to add a title, change the x- and y-axis labels, and change the color and size of the points on the scatterplot (Figure 3.9), you can run: ggplot(nepali, aes(x = ht, y = wt)) + geom_point(color = &quot;blue&quot;, size = 0.5) + ggtitle(&quot;Weight versus Height&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Weight (kg)&quot;) Figure 3.9: Example of adding ggplot elements to customize a scatterplot. You can also try mapping another variable in the dataset to the color aesthetic. For example, to use color to show the sex of each child in the scatterplot (Figure 3.10), you can run: ggplot(nepali, aes(x = ht, y = wt, color = sex)) + geom_point(size = 0.5) + ggtitle(&quot;Weight versus Height&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Weight (kg)&quot;) Figure 3.10: Example of mapping color to an element of the data in a scatterplot. 3.4.9 Boxplots Boxplots can be used to show the distribution of a continuous variable. To create a boxplot, you can use the geom_boxplot geom. To plot a boxplot for a single, continuous variable, you can map that variable to y in the aes call, and map x to the constant 1. For example, to create a boxplot of the heights of children in the Nepali dataset (Figure 3.11), you can run: ggplot(nepali, aes(x = 1, y = ht)) + geom_boxplot() + xlab(&quot;&quot;)+ ylab(&quot;Height (cm)&quot;) Figure 3.11: Example of creating a boxplot. The example shows the distribution of height data for children in the nepali dataset. You can also create separate boxplots, one for each level of a factor (Figure 3.12). In this case, you’ll need to include two aesthetics (x and y) when you initialize the ggplot object The y variable is the variable for which the distribution will be shown, and the x variable should be a discrete (categorical or TRUE/FALSE) variable, and will be used to group the variable. This x variable should also be specified as the grouping variable, using group within the aesthetic call. ggplot(nepali, aes(x = sex, y = ht, group = sex)) + geom_boxplot() + xlab(&quot;Sex&quot;)+ ylab(&quot;Height (cm)&quot;) Figure 3.12: Example of creating separate boxplots, divided by a categorical grouping variable in the data. 3.5 In-course exercise 3.5.1 Loading data from an R package The data we’ll be using today is from a dataset called worldcup in the package faraway. Load that data so you can use it on your computer (note: you will need to load and install the faraway package to do this). Use the help file for the data to find out more about the dataset. Use some basic functions, like head, tail, colnames, str, and summary to check out the data a bit. See if you can figure out: What variables are included in this dataset? (Check the column names.) What class is each column currently? In particular, which are numbers and which are factors? 3.5.1.1 Example R code: Load the faraway package using library() and then load the data using data(): ## Uncomment the next line if you need to install the package # install.packages(&quot;faraway&quot;) library(faraway) data(&quot;worldcup&quot;) Check out the help file for the worldcup dataset to find out more about the data. (Note: Only datasets that are parts of packages will have help files.) ?worldcup Check out the data a bit: str(worldcup) ## &#39;data.frame&#39;: 595 obs. of 7 variables: ## $ Team : Factor w/ 32 levels &quot;Algeria&quot;,&quot;Argentina&quot;,..: 1 16 9 9 5 32 11 11 18 20 ... ## $ Position: Factor w/ 4 levels &quot;Defender&quot;,&quot;Forward&quot;,..: 4 4 1 4 2 2 1 2 4 1 ... ## $ Time : int 16 351 180 270 46 72 138 33 21 103 ... ## $ Shots : int 0 0 0 1 2 0 0 0 5 0 ... ## $ Passes : int 6 101 91 111 16 15 51 9 22 38 ... ## $ Tackles : int 0 14 6 5 0 0 2 0 0 1 ... ## $ Saves : int 0 0 0 0 0 0 0 0 0 0 ... head(worldcup) ## Team Position Time Shots Passes Tackles Saves ## Abdoun Algeria Midfielder 16 0 6 0 0 ## Abe Japan Midfielder 351 0 101 14 0 ## Abidal France Defender 180 0 91 6 0 ## Abou Diaby France Midfielder 270 1 111 5 0 ## Aboubakar Cameroon Forward 46 2 16 0 0 ## Abreu Uruguay Forward 72 0 15 0 0 tail(worldcup) ## Team Position Time Shots Passes Tackles Saves ## van Bommel Netherlands Midfielder 540 2 307 31 0 ## van Bronckhorst Netherlands Defender 540 1 271 10 0 ## van Persie Netherlands Forward 479 14 108 1 0 ## von Bergen Switzerland Defender 234 0 79 3 0 ## Alvaro Pereira Uruguay Midfielder 409 6 140 17 0 ## Ozil Germany Midfielder 497 7 266 3 0 colnames(worldcup) ## [1] &quot;Team&quot; &quot;Position&quot; &quot;Time&quot; &quot;Shots&quot; &quot;Passes&quot; &quot;Tackles&quot; ## [7] &quot;Saves&quot; summary(worldcup) ## Team Position Time Shots ## Slovakia : 21 Defender :188 Min. : 1.0 Min. : 0.000 ## Uruguay : 21 Forward :143 1st Qu.: 88.0 1st Qu.: 0.000 ## Argentina: 20 Goalkeeper: 36 Median :191.0 Median : 1.000 ## Cameroon : 20 Midfielder:228 Mean :208.9 Mean : 2.304 ## Chile : 20 3rd Qu.:270.0 3rd Qu.: 3.000 ## Paraguay : 20 Max. :570.0 Max. :27.000 ## (Other) :473 ## Passes Tackles Saves ## Min. : 0.00 Min. : 0.000 Min. : 0.0000 ## 1st Qu.: 29.00 1st Qu.: 1.000 1st Qu.: 0.0000 ## Median : 61.00 Median : 3.000 Median : 0.0000 ## Mean : 84.52 Mean : 4.192 Mean : 0.6672 ## 3rd Qu.:115.50 3rd Qu.: 6.000 3rd Qu.: 0.0000 ## Max. :563.00 Max. :34.000 Max. :20.0000 ## 3.5.2 Exploring the data using logical statements Next, try checking out the data using logical statements and some of the dplyr code we covered last week (filter and arrange, for example), to help you answer the following questions: What is the range of time that players spent in the game? Which player or players played the most time in this World Cup? How many players are goalies in this dataset? Create a new R object named brazil_players that is limited to the players in this dataset that are (1) on the Brazil team and (2) not goalies. If you have additional time, look over the “Data Manipulation” cheatsheet available in RStudio’s Help section. Make a list of questions you would like to figure out from this example data, and start to plan out how you might be able to answer those questions using functions from dplyr. Write the related code and see if it works. 3.5.2.1 Example R code: To figure out the range of time, you could use arrange twice, once with desc and once without, to figure out the maximum and minimum values # Minimum time arrange(worldcup, Time) %&gt;% select(Time) %&gt;% slice(1) ## # A tibble: 1 x 1 ## Time ## &lt;int&gt; ## 1 1 # Maximum time arrange(worldcup, desc(Time)) %&gt;% select(Time) %&gt;% slice(1) ## # A tibble: 1 x 1 ## Time ## &lt;int&gt; ## 1 570 Later, we will learn about the n() function, which you can use within piped code to represent the total number of rows in the dataframe. If you’d like to get the full range of the Time column in one pipeline of code, you can use n() as a reference within slice, to pull both the first and last rows of the dataframe: arrange(worldcup, Time) %&gt;% select(Time) %&gt;% slice(c(1, n())) ## # A tibble: 2 x 1 ## Time ## &lt;int&gt; ## 1 1 ## 2 570 Finally, as a further hint at things you’ll learn later in the lecture, you could also use min() and max() functions to get the minimum and maximum values of the Time column in the worldcup dataframe (remember that you can use the dataframe$column_name notation to pull a column from a dataframe). Similarly, you could use range() to find out the range of time these players played in the World Cup. range(worldcup$Time) ## [1] 1 570 To figure out which player or players played for the most time, there are a few approaches you can take. Here I’m showing two: (1) using filter from the dplyr package to filter down to rows where where the Time for that row equals the maximum play time that you determined from an earlier task (570 minutes); and (2) using the top_n function from dplyr to pick out the rows with the maximum value (n = 1) of the Time column (see the help file for top_n if you are unfamiliar with this function; we have not covered it in class yet). worldcup %&gt;% filter(Time == 570) ## Team Position Time Shots Passes Tackles Saves ## 1 Uruguay Midfielder 570 5 195 21 0 ## 2 Uruguay Midfielder 570 5 182 15 0 ## 3 Uruguay Goalkeeper 570 0 75 0 16 worldcup %&gt;% top_n(n = 1, wt = Time) ## Team Position Time Shots Passes Tackles Saves ## 1 Uruguay Midfielder 570 5 195 21 0 ## 2 Uruguay Midfielder 570 5 182 15 0 ## 3 Uruguay Goalkeeper 570 0 75 0 16 Note: You may have noticed that you lost the players names when you did this using the dplyr pipechain. That’s because dplyr functions convert the data to a dataframe format that does not include rownames. If you want to keep players’ names, you can use a function from the tibble package called rownames_to_column to move those names from the rownames of the data into a column in the dataframe. Use the var parameter of this function to specify what you want the new column to be named. For example: library(tibble) worldcup %&gt;% rownames_to_column(var = &quot;Name&quot;) %&gt;% filter(Time == 570) ## Name Team Position Time Shots Passes Tackles Saves ## 1 Arevalo Rios Uruguay Midfielder 570 5 195 21 0 ## 2 Maxi Pereira Uruguay Midfielder 570 5 182 15 0 ## 3 Muslera Uruguay Goalkeeper 570 0 75 0 16 There are a few ways to figure out how many players are goalies in this dataset. One way is to use sum() on a logical vector of whether the player’s position is “Goalkeeper”: is_goalie &lt;- worldcup$Position == &quot;Goalkeeper&quot; sum(is_goalie) ## [1] 36 Another way is to use filter from dplyr, along with a logical statement, to filter the data to only players with the position of “Goalkeeper”, and then pipe that filtered subset into the nrow function to count the number of rows in the filtered dataframe: worldcup %&gt;% filter(Position == &quot;Goalkeeper&quot;) %&gt;% nrow() ## [1] 36 Next, create a new R object named brazil_players that is limited to the players in this dataset that are (1) on the Brazil team and (2) not goalies. You can use a logical statement to filter to rows that meet both these conditions by joing two logical statements in the filter function with an &amp;: brazil_players &lt;- worldcup %&gt;% filter(Team == &quot;Brazil&quot; &amp; Position != &quot;Goalkeeper&quot;) head(brazil_players) ## Team Position Time Shots Passes Tackles Saves ## 1 Brazil Midfielder 82 0 42 1 0 ## 2 Brazil Defender 310 11 215 6 0 ## 3 Brazil Midfielder 140 5 57 6 0 ## 4 Brazil Forward 418 9 89 4 0 ## 5 Brazil Defender 33 0 6 4 0 ## 6 Brazil Midfielder 450 3 299 11 0 3.5.3 Exploring the data using simple statistics and summarize Next, try checking out the data using some basic commands for simple statistics, like mean(), range(), max(), and min(), as well as the summarize and group_by functions from the dplyr package. Try to answer the following questions: What is the mean number of saves that players made? What is the mean number of saves just among the goalkeepers? Did players from any position other than goalkeeper make a save? How many players were there in each position? How many forwards were there on each team? Which team had the most shots in total among all its forwards? Which team(s) had the defender with the most tackles? If you have extra time, continuing using the “Data Wrangling” cheatsheet to come up with some other ideas for how you can explore this data, and write up and test code to do that. 3.5.3.1 Example R code: To calculate the mean number of saves among all the players, use the mean function, either by itself or within a summarize call: mean(worldcup$Saves) ## [1] 0.6672269 worldcup %&gt;% summarize(mean_saves = mean(Saves)) ## mean_saves ## 1 0.6672269 There are a few ways to figure out the mean number of saves just among the goalkeepers. One way is to filter the dataset to only goalies and then use summarize to calculate the mean number of saves in this filtered subset of the data: worldcup %&gt;% filter(Position == &quot;Goalkeeper&quot;) %&gt;% summarize(mean_saves = mean(Saves)) ## mean_saves ## 1 11.02778 The next question is if players from any position other than goalkeeper made a save. One way to figure this out is to group the data by position and then summarize the maximum number of saves. Based on this, it looks like there were not saves from players in any position except goalie: worldcup %&gt;% group_by(Position) %&gt;% summarize(max_saves = max(Saves)) ## # A tibble: 4 x 2 ## Position max_saves ## &lt;fct&gt; &lt;dbl&gt; ## 1 Defender 0. ## 2 Forward 0. ## 3 Goalkeeper 20. ## 4 Midfielder 0. To figure out how many players were there in each position, you can can group the data by position and then use the n function from dplyr to count the number of observations in each group: worldcup %&gt;% group_by(Position) %&gt;% summarize(n_players = n()) ## # A tibble: 4 x 2 ## Position n_players ## &lt;fct&gt; &lt;int&gt; ## 1 Defender 188 ## 2 Forward 143 ## 3 Goalkeeper 36 ## 4 Midfielder 228 For the next set of questions, you can filter the data to only forwards, then group by team to use summarize to count up the number of forwards on each team. You can also use the same summarize call to figure out the total number of shots by all forwards on each team. To figure out which team had the most shots in total among all its forwards, you can use the arrange function to re-order the data from the team with the most total shots to the least. It turns out that Uruguay had the most shots by forwards on its team, with a total of 46 shots. worldcup %&gt;% filter(Position == &quot;Forward&quot;) %&gt;% group_by(Team) %&gt;% summarize(n_forwards = n(), total_forward_shots = sum(Shots)) %&gt;% arrange(desc(total_forward_shots)) ## # A tibble: 32 x 3 ## Team n_forwards total_forward_shots ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; ## 1 Uruguay 5 46 ## 2 Argentina 6 45 ## 3 Germany 6 41 ## 4 Netherlands 5 34 ## 5 Spain 3 33 ## 6 Ghana 5 32 ## 7 Portugal 4 28 ## 8 Paraguay 5 25 ## 9 Brazil 4 23 ## 10 USA 5 21 ## # ... with 22 more rows To figure out which team(s) had the defender with the most tackles, you can filter to only defenders and then use the top_n function to identify the players with the top number of tackles. It turns out these players were on the England, Germany, and Chile teams. worldcup %&gt;% filter(Position == &quot;Defender&quot;) %&gt;% top_n(n = 1, wt = Tackles) ## Team Position Time Shots Passes Tackles Saves ## 1 England Defender 357 3 173 17 0 ## 2 Germany Defender 540 0 360 17 0 ## 3 Chile Defender 306 6 178 17 0 3.5.4 Exploring the data using basic plots #1 Use some basic plots to check out this data. Try the following: Create a scatterplot of the worldcup data, where each point is a player, the x-axis shows the amount of time the player played in the World Cup, and the y-axis shows the number of passes the player had. Try writing the code both with and without “piping in” the data you want to plot into the ggplot function. Create the same scatterplot, but have each point in the scatterplot show that player’s position using some aesthetic besides the x or y position (e.g., color, point shape). Add “rug plots” to the margins. Create a scatterplot of number of shots (x-axis) versus number of tackles (y-axis) for just players on one of the four teams that made the semi-finals (Spain, Netherlands, Germany, Uruguay). Use color to show player’s position and shape to show player’s team. (Hint: you will want to use some dplyr code to clean the data before plotting to do this.) Create a scatterplot of player time versus passes. Use color to show whether the player was on one of the top 4 teams or not. (Hint: Again, you’ll want to use some dplyr code before plotting to do this.) For an extra challenge, also try adding each player’s name on top of each point. (Hint: check out the rownames_to_column function from the tibble package to help with this.) Did you notice any interesting features of the data when you did any of the graphs in this section? 3.5.4.1 Example R code: Create a scatterplot of Time versus Passes. # Without piping ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes)) # With piping worldcup %&gt;% ggplot() + geom_point(mapping = aes(x = Time, y = Passes)) Create the same scatterplot, but have each point in the scatterplot show that player’s position. ggplot(worldcup, mapping = aes(x = Time, y = Passes, color = Position)) + geom_point() + geom_rug() Create a scatterplot of number of shots (x-axis) versus number of tackles (y-axis) for just players on one of the four teams that made the semi-finals (Spain, Netherlands, Germany, Uruguay). Use color to show player’s position and shape to show player’s team. For an extra challenge, also try adding each player’s name on top of each point. worldcup %&gt;% rownames_to_column(var = &quot;Name&quot;) %&gt;% filter(Team %in% c(&quot;Spain&quot;, &quot;Netherlands&quot;, &quot;Germany&quot;, &quot;Uruguay&quot;)) %&gt;% ggplot() + geom_point(aes(x = Shots, y = Tackles, color = Position, shape = Team)) + geom_text(mapping = aes(x = Shots, y = Tackles, color = Position, label = Name), size = 2.5) Create a scatterplot of player time versus passes. Use color to show whether the player was on one of the top 4 teams or not. worldcup %&gt;% mutate(top_4 = Team %in% c(&quot;Spain&quot;, &quot;Netherlands&quot;, &quot;Germany&quot;, &quot;Uruguay&quot;)) %&gt;% ggplot() + geom_point(aes(x = Time, y = Passes, color = top_4)) 3.5.5 Exploring the data using basic plots #2 Go back to the code you used in the previous section to create a scatterplot of the worldcup data, where each point is a player, the x-axis shows the amount of time the player played in the World Cup, and the y-axis shows the number of passes the player had. Try the following modifications: Make all the points blue. Google “R colors” to find a list of color names in R. Pick your favorite and make all the points in the scatterplot that color. Change the size of the points to make them smaller (hint: check out the size aesthetic). Make it so the color of the points shows the player’s position and all the points are slightly transparent. Change the title of the x-axis to “Time (minutes)” and the y-axis to “Number of passes”. Add the title “World Cup statistics” and the subtitle “2010 World Cup”. 3.5.5.1 Example R code: Make all the points blue. ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes), color = &quot;blue&quot;) Google “R colors” to find a list of color names in R. Pick your favorite and make all the points in the scatterplot that color. # Make the points &quot;darkseagreen4&quot; ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes), color = &quot;darkseagreen4&quot;) Change the size of the points to make them smaller (hint: check out the size aesthetic). ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes), size = 0.8) Make it so the color of the points shows the player’s position and all the points are slightly transparent. ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes), alpha = 0.3) Change the title of the x-axis to “Time (minutes)” and the y-axis to “Number of passes”. ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes)) + labs(x = &quot;Time (minutes)&quot;, y = &quot;Number of passes&quot;) Add the title “World Cup statistics” and the subtitle “2010 World Cup”. ggplot(worldcup) + geom_point(mapping = aes(x = Time, y = Passes)) + ggtitle(&quot;World Cup statistics&quot;, subtitle = &quot;2010 World Cup&quot;) 3.5.6 Exploring the data using basic plots #3 Try out creating some plots using the “statistical” geoms to check out this data. Try the following: Plot histograms of all the numeric variables (Time, Shot, Passes, Tackles, Saves) in the dataset. Try customizing the number of bins used for one of the histograms plotted in the previous step. Try using constant values for some of the aesthetics (e.g., customize the color and the fill) of the histogram created in the previous step. Create a boxplot of Shots by position. Create a top_teams subset with just the four teams that made the semi-finals in the 2010 World Cup (Spain, the Netherlands, Germany, and Uruguay). Plot boxplots of Shots and Saves by team for just these teams. Create a histogram using data only from the four top teams for the amount of time each player played. Use the color aesthetic of the histogram to show team. 3.5.6.1 Example R code Use histograms to explore the distribution of different variables. If you want to change the number of bins in the histogram, try playing around with the bins and binwidth arguments. You can use the bins argument to say how many bins you want (e.g., bins = 50). You can use the binwidth argument to say how wide you want the bins to be (e.g., binwidth = 10 if you wanted bins to be 10 units wide, in the units of the variable mapped to the x aesthetic. Try using fill and color to change the appearance of the plot. Google “R colors” and search the images to find links to listings of different R colors. ggplot(worldcup, aes(x = Time)) + geom_histogram() ggplot(worldcup, aes(x = Time)) + geom_histogram(bins = 50) ggplot(worldcup, aes(x = Time)) + geom_histogram(binwidth = 100) ggplot(worldcup, aes(x = Time)) + geom_histogram(binwidth = 50, color = &quot;white&quot;, fill = &quot;cyan4&quot;) To create a boxplot of Shots by Position, you can use geom_boxplot: ggplot(worldcup, aes(x = Position, y = Shots)) + geom_boxplot() The top four teams in this World Cup were Spain, the Netherlands, Germany, and Uruguay. Create a subset with just the data for these four teams: top_teams &lt;- worldcup %&gt;% filter(Team %in% c(&quot;Spain&quot;, &quot;Netherlands&quot;, &quot;Germany&quot;, &quot;Uruguay&quot;)) Now, you can plot the boxplots, mapping Team to the x aesthetic and Shots to the y aesthetic: ggplot(top_teams, aes(x = Team, y = Shots)) + geom_boxplot() + ggtitle(&quot;Shots per player in World Cup 2010&quot;) Create a histogram using data only from the four top teams for the amount of time each player played. Use the color aesthetic of the histogram to show team. ggplot(data = top_teams) + geom_histogram(aes(x = Time, fill = Team)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Note that you can also explore other values for geom_histogram arguments. For example, you could change the binwidths to be 90 minutes (since games are 90 minutes). ggplot(data = top_teams) + geom_histogram(aes(x = Time, fill = Team), binwidth = 90) "],
["reporting-data-results-1.html", "Chapter 4 Reporting data results #1 4.1 Guidelines for good plots 4.2 High data density 4.3 Meaningful labels 4.4 References 4.5 Highlighting 4.6 Order 4.7 Small multiples 4.8 Advanced customization 4.9 To find out more 4.10 In-course exercise", " Chapter 4 Reporting data results #1 Download a pdf of the lecture slides covering this topic. 4.1 Guidelines for good plots There are a number of very thoughtful books and articles about creating graphics that effectively communicate information. Some of the authors I highly recommend (and from whose work I’ve pulled the guidelines for good graphics we’ll talk about this week) are: Edward Tufte Howard Wainer Stephen Few Nathan Yau You should plan, in particular, to read The Visual Display of Quantitative Information by Edward Tufte before you graduate. This week, we’ll focus on six guidelines for good graphics, based on the writings of these and other specialists in data display. The guidelines are: Aim for high data density. Use clear, meaningful labels. Provide useful references. Highlight interesting aspects of the data. Make order meaningful. When possible, use small multiples. For the examples, I’ll use dplyr for data cleaning and, for plotting, the packages ggplot2, gridExtra, and ggthemes. library(tidyverse) ## Loads `dplyr` and `ggplot2` ## Warning: package &#39;purrr&#39; was built under R version 3.4.4 library(gridExtra) library(ggthemes) You can load the data for today’s examples with the following code: library(faraway) data(nepali) data(worldcup) library(dlnm) data(chicagoNMMAPS) chic &lt;- chicagoNMMAPS chic_july &lt;- chic %&gt;% filter(month == 7 &amp; year == 1995) 4.2 High data density Guideline 1: Aim for high data density. You should try to increase, as much as possible, the data to ink ratio in your graphs. This is the ratio of “ink” providing information to all ink used in the figure. One way to think about this is that the only graphs you make that use up a lot of your printer’s ink should be packed with information. The two graphs in Figure 4.1 show the same information, but use very different amounts of ink. Each shows the number of players in each of four positions in the worldcup dataset. Notice how, in the plot on the right, a single dot for each category shows the same information that a whole filled bar is showing on the left. Further, the plot on the right has removed the gridded background, removing even more “ink”. Figure 4.1: Example of plots with lower (left) and higher (right) data-to-ink ratios. Each plot shows the number of players in each position in the worldcup dataset from the faraway package. Figure 4.2 gives another example of two plots that show the same information but with very different data densities. This figure uses the chicagoNMMAPS data from the dlnm package, which includes daily mortality, weather, and air pollution data for Chicago, IL. Both plots show daily mortality counts during July 1995, when a very severe heat wave hit Chicago. Notice how many of the elements in the plot on the left, including the shading under the mortality time series and the colored background and grid lines, are unnecessary for interpreting the message from the data. Figure 4.2: Example of plots with lower (left) and higher (right) data-to-ink ratios. Each plot shows daily mortality in Chicago, IL, in July 1995 using the chicagoNMMAPS data from the dlnm package. By increasing the data-to-ink ratio in a plot, you can help viewers see the message of the data more quickly. A cluttered plot is harder to interpret. Further, you leave room to add some of the other elements I’ll talk about, including highlighting interesting data and adding useful references. Notice how the plots on the left in Figures 4.1 and 4.2 are already cluttered and leave little room for adding extra elements, while the plots on the right of those figures have much more room for additions. One quick way to increase data density in ggplot2 is to change the theme for the plot. The theme specifies a number of the “background” elements to a plot, including elements like the plot grid, background color, and the font used for labeling. Some themes come with ggplot2, including: theme_bw theme_minimal theme_void You can find more themes in packages that extend ggplot2. The ggthemes package, in particular, has some excellent additional themes. Figures 4.3 shows some examples of the effects of using different themes. All show the same information– a plot of daily deaths in Chicago in July 1995. The top left graph shows the graph with the default theme. The other plots show the effects of adding different themes, including the black-and-white theme that comes with ggplot2 (top right) and various themes from the ggthemes package. You can even use themes to add some questionable choices for different elements, like the Excel theme (bottom left). Figure 4.3: Daily mortality in Chicago, IL, in July 1995. This figure gives an example of the plot using different themes. 4.3 Meaningful labels Guideline 2: Use clear, meaningful labels. Graphs often default to use abbreviations for axis labels and other labeling. For example, the default is for ggplot2 plots to use column names for the x- and y-axes of a scatterplot. While this is convenient for exploratory plots, it’s often not adequate for plots for presentations and papers. You’ll want to use short and easy-to-type column names in your dataframe to make coding easier, but you should use longer and more meaningful labeling in plots and tables that others need to interpret. Furthermore, text labels can sometimes be aligned in a way that makes them hard to read. For example, when plotting a categorical variable along the x-axis, it can be difficult to fit labels for each category that are long enough to be meaningful. Figure 4.4 gives an example of the same information shown with labels that are harder to interpret (left) versus with clear, meaningful labels (right). Notice how the graph on the left is using abbreviations for the categorical variable (“DF” for “Defense”), abbreviations for axis labels (“Pos” for “Position” and “Pls” for “Number of players”), and has the player position labels in a vertical alignment. On the right graph, I have made the graph easier to quickly read and interpret by spelling out all labels and switching the x- and y-axes, so that there’s room to fully spell out each position while still keeping the alignment horizontal, so the reader doesn’t have to turn the page (or their head) to read the values. Figure 4.4: The number of players in each position in the worldcup data from the faraway package. Both graphs show the same information, but the left graph has murkier labels, while the right graph has labels that are easier to read and interpret. There are a few strategies you can use to make labels clearer when plotting with ggplot2: Add xlab and ylab elements to the plot, rather than relying on the column names in the original data. You can also relabel x- and y-axes with scale elements (e.g., scale_x_continuous), and the scale functions give you more power to also make other changes to the x- and y-axes (e.g., changing break points for the axis ticks). However, if you only need to change axis labels, xlab and ylab are often quicker. Include units of measurement in axis titles when relevant. If units are dollars or percent, check out the scales package, which allows you to add labels directly to axis elements by including arguments like labels = percent in scale elements. See the helpfile for scale_x_continuous for some examples. If the x-variable requires longer labels, as is often the case with categorical data (for example, player positions Figure 4.4), consider flipping the coordinates, rather than abbreviating or rotating the labels. You can use coord_flip to do this. 4.4 References Guideline 3: Provide useful references. Data is easier to interpret when you add references. For example, if you show what it typical, it helps viewers interpret how unusual outliers are. Figure 4.5 shows daily mortality during July 1995 in Chicago, IL. The graph on the right has added shading showing the range of daily death counts in July in Chicago for neighboring years (1990–1994 and 1996–2000). This added reference helps clarify for viewers how unusual the number of deaths during the July 1995 heat wave was. Figure 4.5: Daily mortality during July 1995 in Chicago, IL. In the graph on the right, I have added a shaded region showing the range of daily mortality counts for neighboring years, to show how unusual this event was. Another useful way to add references is to add a linear or smooth fit to the data, to help clarify trends in the data. Figure 4.6 shows the relationship between passes and shots for Forwards in the worldcup dataset. The plot on the right has added a smooth function of the relationship between these two variables. Figure 4.6: Relationship between passes and shots taken among Forwards in the worldcup dataset from the faraway package. The plot on the right has a smooth function added to help show the relationship between these two variables. For scatterplots created with ggplot2, you can use the function geom_smooth to add a smooth or linear reference line. Here is the code that produces Figure 4.6: ggplot(filter(worldcup, Position == &quot;Forward&quot;), geom_point(size = 1.5) + theme_few() + geom_smooth() The most useful geom_smooth parameters to know are: method: The default is to add a loess curve if the data includes less than 1000 points and a generalized additive model for 1000 points or more. However, you can change to show the fitted line from a linear model using method = &quot;lm&quot; or from a generalized linear model using method = &quot;glm&quot;. span: How wiggly or smooth the smooth line should be (smaller value: more wiggly; larger value: more smooth) se: TRUE or FALSE, indicating whether to include shading for 95% confidence intervals. level: Confidence level for confidence interval (e.g., 0.90 for 90% confidence intervals) Lines and polygons can also be useful for adding references, as in Figure 4.5. Useful geoms for such shapes include: geom_hline, geom_vline: Add a horizontal or vertical line geom_abline: Add a line with an intercept and slope geom_polygon: Add a filled polygon geom_path: Add an unfilled polygon You want these references to support the main data shown in the plot, but not overwhelm it. When adding these references: Add reference elements first, so they will be plotted under the data, instead of on top of it. Use alpha to add transparency to these elements. Use colors that are unobtrusive (e.g., grays). For lines, consider using non-solid line types (e.g., linetype = 3). 4.5 Highlighting Guideline 4: Highlight interesting aspects. Consider adding elements to highlight noteworthy elements of the data. For example, in the graph on the right of Figure 4.7, the days of the heat wave (based on temperature measurements) have been highlighted over the mortality time series by using a thick red line. Figure 4.7: Mortality in Chicago, July 1995. In the plot on the right, a thick red line has been added to show the dates of a heat wave. In the below graphs, the names of the players with the most shots and passes have been added to highlight these unusual points. One helpful way to annotate is with text, using geom_text(). For this, you’ll first need to create a dataframe with the hottest day in the data: hottest_day &lt;- chic_july %&gt;% filter(temp == max(temp)) hottest_day[ , 1:6] ## date time year month doy dow ## 1 1995-07-13 3116 1995 7 194 Thursday chic_plot + geom_text(data = hottest_day, label = &quot;Max&quot;, size = 3) With geom_text, you’ll often want to use position adjustment (the position parameter) to move the text so it won’t be right on top of the data points: chic_plot + geom_text(data = hottest_day, label = &quot;Max&quot;, size = 3, hjust = 0, vjust = -1) You can also use lines to highlight. For this, it is often useful to create a new dataframe with data for the reference. To add a line for the Chicago heat wave, I’ve added a dataframe called hw with the relevant date range. I’m setting the y-value to be high enough (425) to ensure the line will be placed above the mortality data. hw &lt;- data.frame(date = c(as.Date(&quot;1995-07-12&quot;), as.Date(&quot;1995-07-16&quot;)), death = c(425, 425)) b &lt;- chic_plot + geom_line(data = hw, aes(x = date, y = death), size = 2) b 4.6 Order Guideline 5: Make order meaningful. You can make the ranking of data clearer from a graph by using order to show rank. Often, factor or categorical variables are ordered by something that is not interesting, like alphabetical order. You can re-order factor variables in a graph by resetting the factor using the factor function and changing the order that levels are included in the levels parameter. 4.7 Small multiples Guideline 6: When possible, use small multiples. Small multiples are graphs that use many small plots showing the same thing for different facets of the data. For example, instead of using color in a single plot to show data for males and females, you could use two small plots, one each for males and females. Typically, in small multiples, all plots use the same x- and y-axes. This makes it easier to compare across plots, and it also allows you to save room by limiting axis annotation. You can use the facet functions to create small multiples. This separates the graph into several small graphs, one for each level of a factor. The facet functions are: facet_grid() facet_wrap() For example, to create small multiples by sex for the Nepali dataset, when plotting height versus weight, you can call: ggplot(nepali, aes(ht, wt)) + geom_point() + facet_grid(. ~ sex) The facet_grid function can facet by one or two variables. One will be shown by rows, and one by columns: ## Generic code facet_grid([factor for rows] ~ [factor for columns]) The facet_wrap() function can only facet by one variable, but it can “wrap” the small graphs for that variable, so the don’t all have to be in one row or column: ## Generic code facet_wrap(~ [factor for faceting], ncol = [number of columns]) Often, when you do faceting, you’ll want to re-name your factors levels or re-order them. For this, you’ll need to use the factor() function on the original vector. For example, to rename the sex factor levels from “1” and “2” to “Male” and “Female”, you can run: nepali &lt;- nepali %&gt;% mutate(sex = factor(sex, levels = c(1, 2), labels = c(&quot;Male&quot;, &quot;Female&quot;))) Notice that the labels for the two graphs have now changed: ggplot(nepali, aes(ht, wt)) + geom_point() + facet_grid(. ~ sex) To re-order the factor, and show the plot for “Female” first, you can use factor to change the order of the levels: nepali &lt;- nepali %&gt;% mutate(sex = factor(sex, levels = c(&quot;Female&quot;, &quot;Male&quot;))) Now notice that the order of the plots has changed: ggplot(nepali, aes(ht, wt)) + geom_point() + facet_grid(. ~ sex) 4.8 Advanced customization 4.8.1 Scales There are a number of different functions for adjusting scales. These follow the following convention: ## Generic code scale_[aesthetic]_[vector type] For example, to adjust the x-axis scale for a continuous variable, you’d use scale_x_continuous. You can use a scale function for an axis to change things like the axis label (which you could also change with xlab or ylab) as well as position and labeling of breaks. For example, here is the default for plotting time versus passes for the worldcup dataset, with the number of shots taken shown by size and position shown by color: ggplot(worldcup, aes(x = Time, y = Passes, color = Position, size = Shots)) + geom_point(alpha = 0.5) ggplot(worldcup, aes(x = Time, y = Passes, color = Position, size = Shots)) + geom_point(alpha = 0.5) + scale_x_continuous(name = &quot;Time played (minutes)&quot;, breaks = 90 * c(2, 4, 6), minor_breaks = 90 * c(1, 3, 5)) Parameters you might find useful in scale functions include: Parameter Description name Label or legend name breaks Vector of break points minor_breaks Vector of minor break points labels Labels to use for each break limits Limits to the range of the axis For dates, you can use scale functions like scale_x_date and scale_x_datetime. For example, here’s a plot of deaths in Chicago in July 1995 using default values for the x-axis: ggplot(chic_july, aes(x = date, y = death)) + geom_line() And here’s an example of changing the formating and name of the x-axis: ggplot(chic_july, aes(x = date, y = death)) + geom_line() + scale_x_date(name = &quot;Date in July 1995&quot;, date_labels = &quot;%m-%d&quot;) You can also use the scale functions to transform an axis. For example, to show the Chicago plot with “deaths” on a log scale, you can run: ggplot(chic_july, aes(x = date, y = death)) + geom_line() + scale_y_log10() For colors and fills, the conventions for the names of the scale functions can vary. For example, to adjust the color scale when you’re mapping a discrete variable (i.e., categorical, like gender or animal breed) to color, you’d use scale_color_hue. To adjust the color scale for a continuous variable, like age, you’ll use scale_color_gradient. For any color scales, consider starting with brewer first (e.g., scale_color_brewer, scale_color_distiller). Scale functions from brewer allow you to set colors using different palettes. You can explore these palettes at http://colorbrewer2.org/. The Brewer palettes fall into three categories: sequential, divergent, and qualitative. You should use sequential or divergent for continuous data and qualitative for categorical data. Use display.brewer.pal to show the palette for a given number of colors. library(RColorBrewer) display.brewer.pal(name = &quot;Set1&quot;, n = 8) display.brewer.pal(name = &quot;PRGn&quot;, n = 8) display.brewer.pal(name = &quot;PuBuGn&quot;, n = 8) Use the palette argument within a scales function to customize the palette: a &lt;- ggplot(data.frame(x = 1:5, y = rnorm(5), group = letters[1:5]), aes(x = x, y = y, color = group)) + geom_point() b &lt;- a + scale_color_brewer(palette = &quot;Set1&quot;) c &lt;- a + scale_color_brewer(palette = &quot;Pastel2&quot;) + theme_dark() grid.arrange(a, b, c, ncol = 3) ggplot(worldcup, aes(x = Time, y = Passes, color = Position, size = Shots)) + geom_point(alpha = 0.5) + scale_color_brewer(palette = &quot;Dark2&quot;, name = &quot;Player position&quot;) You can also set colors manually: ggplot(worldcup, aes(x = Time, y = Passes, color = Position, size = Shots)) + geom_point(alpha = 0.5) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;, &quot;darkgreen&quot;, &quot;darkgray&quot;)) 4.9 To find out more Some excellent further references for plotting are: R Graphics Cookbook (book and website) Google images For more technical details about plotting in R: ggplot2: Elegant Graphics for Data Analysis, Hadley Wickham R Graphics, Paul Murrell 4.10 In-course exercise 4.10.1 Designing a plot For today’s exercise, you’ll be building a plot using the worldcup data from the faraway package. First, load in that data. The name of each player is in the rownames of this data. Use the tibble::rownames_to_column() function to move those rownames into a new column named Player. Also install and load the ggplot2 and ggthemes packages. Next, say you want to look at the relationship between the number of minutes that a player played in the 2010 World Cup (Time) and the number of shots the player took on goal (Shots). On a sheet of paper, and talking with your partner, decide how the two of you would design a plot to explore and present this relationship. How would you incorporate some of the principles of creating good graphs? 4.10.1.1 Example R code For this section, the only code needed is code to load the required packages, load the data, and move the rownames to a column named Player. library(faraway) data(worldcup) head(worldcup, 2) ## Team Position Time Shots Passes Tackles Saves ## Abdoun Algeria Midfielder 16 0 6 0 0 ## Abe Japan Midfielder 351 0 101 14 0 This dataset has the players’ names as rownames, rather than in a column. Once we start using dplyr functions, we’ll lose these rownames. Therefore, start by converting the rownames to a column called Player: library(dplyr) worldcup &lt;- worldcup %&gt;% tibble::rownames_to_column(var = &quot;Player&quot;) head(worldcup, 2) ## Player Team Position Time Shots Passes Tackles Saves ## 1 Abdoun Algeria Midfielder 16 0 6 0 0 ## 2 Abe Japan Midfielder 351 0 101 14 0 Install and load the ggplot2 package: # install.packages(&quot;ggplot2&quot;) library(ggplot2) # install.packages(&quot;ggthemes&quot;) library(ggthemes) 4.10.2 Implementing plot guidelines #1 In this section, we’ll work on creating a plot like this: Do the following tasks: Create a simple scatterplot of Time versus Shots for the World Cup data. It should look like this: Next, before any more coding, talk with your group members about how this graph is different from the simple one you created with ggplot in the last section. Also discuss what you can figure out from this new graph that was less clear from a simpler scatterplot of Time versus Shots for this data. Often, in graphs with a lot of points, it’s hard to see some of the points, because they overlap other points. Three strategies to address this are: (a) make the points smaller; and (b) make the points somewhat transparent. Try doing these first two with the scatterplot you’re creating. At this point, the plot should look something like this: Create a new column in the worldcup data called top_four that specifies whether or not the Team for that observation was one of the top four teams in the tournament (Netherlands, Uruguay, Spain, and Germany). Make the colors of the points correspond to whether the team was a top-four team. At this point, the plot should look something like this: Increase data density: Try changing the theme, to come up with a graph with a bit less non-data ink. From the ggthemes package, try some of the following themes: theme_few(), theme_tufte(), theme_stata(), theme_fivethirtyeight(), theme_economist_white(), and theme_wsj(). Pick a theme that helps increase the graph’s data density. At this point, the plot should look something like this: Use meaningful labels: Use the labs() function to make a clearer title for the x-axis. (You may have already written this code in the last section of this exercise.) In addition to setting the x-axis title with the labs function, you can also set the title for the color scale (use color = within the labs function). You may want to make a line break in the color title– you can use the linebreak character (\\n) inside the character string with the title to do that. At this point, the plot should look something like this: Provide useful references: The standard time for a soccer game is 90 minutes. In the World Cup, all teams play at least three games, and then the top teams continue and play more games. Add a reference line at 270 minutes (i.e., the amount of standard time played for the three games that all teams play). At this point, the plot should look something like this: 4.10.2.1 Example R code As a reminder, here’s the code to do a simple scatterplot ot Shots by Time for the worldcup data: ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots)) Next, try to make it clearer to see the points by making them smaller and somewhat transparent. This can be done with the size and alpha aesthetics for geom_points. For the size aesthetic, a value smaller than about 2 = smaller than default, larger than about 2 = larger than default. For the alpha aesthetic, closer to 0 = more tranparent, closer to 1 = more opaque. As a reminder, in this case you are changing all of the points in the same way, so you will be setting those aesthetics to constant values. That means that you should specify the values outside of an aes call. This code could make these changes: ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots), size = 1, alpha = 0.5) To create a new column called top_four, first create vector that lists those top four teams, then create a logical vector in the dataframe for whether the team for that observation is in one of the top four teams: worldcup &lt;- worldcup %&gt;% mutate(top_4 = Team %in% c(&quot;Spain&quot;, &quot;Germany&quot;, &quot;Uruguay&quot;, &quot;Netherlands&quot;)) head(worldcup) ## Team Position Time Shots Passes Tackles Saves Player top_4 ## 1 Algeria Midfielder 16 0 6 0 0 Abdoun FALSE ## 2 Japan Midfielder 351 0 101 14 0 Abe FALSE ## 3 France Defender 180 0 91 6 0 Abidal FALSE ## 4 France Midfielder 270 1 111 5 0 Abou Diaby FALSE ## 5 Cameroon Forward 46 2 16 0 0 Aboubakar FALSE ## 6 Uruguay Forward 72 0 15 0 0 Abreu TRUE summary(worldcup$top_4) ## Mode FALSE TRUE ## logical 517 78 To color points by this variable, use color = in the aes() part of the ggplot() call: ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) To increase the data density, try out different themes for the plot. First, I’ll save everything we’ve done so far as the object shot_plot, then I’ll try adding different themes: shot_plot &lt;- ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) shot_plot + theme_few() shot_plot + theme_tufte() shot_plot + theme_wsj() shot_plot + theme_fivethirtyeight() shot_plot + theme_stata() shot_plot + theme_economist_white() The data density is increased with the theme_few() theme, so I’ll use that: ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) + theme_few() To change the titles for some of the scales (the x-axis and color scale), you can use the labs() function. Note that you can use \\n to add a line break inside one of these titles (I’ve done that for the title for the color scale): ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) + theme_few() + labs(x = &quot;Time played in World Cup (minutes)&quot;, color = &quot;Team&#39;s final\\nranking&quot;) As an extra note, if you want to create nicer labels for the legend for color, convert the top_four column into the factor class, with the labels you want to use in the figure legend: worldcup &lt;- worldcup %&gt;% mutate(top_4 = factor(top_4, levels = c(TRUE, FALSE), labels = c(&quot;Top 4&quot;, &quot;Other&quot;))) summary(worldcup$top_4) ## Top 4 Other ## 78 517 ggplot(data = worldcup) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) + theme_few() + labs(x = &quot;Time played in World Cup (minutes)&quot;, color = &quot;Team&#39;s final\\nranking&quot;) To add a reference line at 270 minutes of time, use the geom_vline() function. You’ll want to make it a light color (like light gray) and dashed or dotted (linetype of 2 or 3), so it won’t be too prominent on the graph: ggplot(data = worldcup) + geom_vline(xintercept = 270, color = &quot;lightgray&quot;, linetype = 2) + geom_point(mapping = aes(x = Time, y = Shots, color = top_4), size = 1, alpha = 0.5) + theme_few() + labs(x = &quot;Time played in World Cup (minutes)&quot;, color = &quot;Team&#39;s final\\nranking&quot;) 4.10.3 Implementing plot guidelines #2 Highlighting interesting data: Who had the most shots in the 2010 World Cup? Was he on a top-four team? Use geom_text() to label his point on the graph with his name (try out some different values of hjust and vjust in this function call to get the label in a place you like). At this point, the plot should look something like this: For labeling the player with the top number of shots, instead of only using the player’s name, use the following format: “[Player’s name], [Player’s team]”. (Hint: You may want to use mutate to add a new column, where you used paste0 to paste together the player’s name, &quot;, &quot;, and the team name.) At this point, the plot should look something like this: Create small multiples. The relationship between time played and shots taken is probably different by the players’ positions. Use faceting to create different graphs for each position. At this point, the plot should look something like this: Make order meaningful: What order are the faceted graphs currently in? Offensive players have more chances to take shots than defensive players, so that might be a useful ordering for the facets. Re-order the Position factor column to go from nearest your own goal to nearest the opponents goal, and then re-plot the graph from the previous step. 4.10.3.1 Example R code To add a text label with just the player with the most shots, you’ll want to create a new dataframe with just the top player. You can use the top_n function to do that (the wt option is specifying that we want the top player in terms of values in the Shots column): top_player &lt;- worldcup %&gt;% top_n(n = 1, wt = Shots) Now you can use geom_text() to label this player’s point on the graph with his name. You may need to mess around with some of the options in geom_text(), like size, hjust, and vjust (hjust and vjust say where, in relation to the point location, to put the label), to get something you’re happy with. If you want to put both the player’s name and his team, you can add a mutate() function when you create the new dataframe with just the top player, and then use this for the label: To create small multiples, use the facet_wrap() command (you’ll probably want to use ncol to specify to use four columns): To re-order the Position column of the dataframe, add a mutate statement before you pipe into the plotting code. Use the levels option of the factor() function– whatever order you put the factors in for this argument will be the new order in which R saves the levels of this factor. Note from this code example that you can use the levels function to find out the levels and their order for a factor-class vector. worldcup &lt;- worldcup %&gt;% mutate(Position = factor(Position, levels = c(&quot;Goalkeeper&quot;, &quot;Defender&quot;, &quot;Midfielder&quot;, &quot;Forward&quot;))) levels(worldcup$Position) ## [1] &quot;Goalkeeper&quot; &quot;Defender&quot; &quot;Midfielder&quot; &quot;Forward&quot; 4.10.4 Data visualization cheatsheet RStudio comes with some excellent cheatsheets, which provide quick references to functions and code you might find useful for different tasks. For this part of the group exercise, you’ll explore their cheatsheet for data visualization, both to learn some new ggplot2 code and to become familiar with how to use this cheatsheet as you do your own analysis. Open the data visualization cheatsheet. You can do this from RStudio by going to “Help” -&gt; “Cheatsheets” -&gt; “Data Visualization with ggplot2”. Notice that different sections give examples with some datasets that come with either base R or ggplot2. For example, under the “Graphical Primitives” section, there is code defining the object a as a ggplot object using the “seals” dataset: a &lt;- ggplot(seals, aes(x = long, y = lat)). Go through the cheatsheet and list all of the example datasets that are used in this cheatsheet. Open their helpfiles to learn more about the data. Create the example datasets a through l and s through t using the code given on the cheatsheet. Pick at least one example to try out from each of the following sections: “Graphical Primitives”, “One Variable”, at least three subsections of “Two Variables”, “Three Variables”, “Scales”, “Faceting”, and “Position Adjustments”. As you try these, try to figure out any aesthetics that you aren’t familiar with (e.g., ymin, ymax). Also, use helpfiles for the geoms to look up parameters you aren’t familiar with (e.g., stat for geom_area). If you can’t figure out how to interpret a plot, check the helpfile for the associated geom. Note: For the n geom used in “scales”, it should be defined as n &lt;- d + geom_bar(aes(fill = fl)). 4.10.4.1 Example R code The code for opening the helpfiles for the example datasets is: ?seals ?economics ?mpg ?diamonds ?USArrests Note that, for USArrests, only some of the columns are pulled out (e.g., murder = USArrests$murder) to use in the data example dataframe. Further, the “Visualizing error” examples use a dataframe created specifically for these examples, called df. Some of the base R and ggplot2 example datasets have become fairly well-known. Some that you’ll see very often in examples are the iris, mpg, and diamonds datasets. All of the code to create the datasets a through l and s through t is given somewhere on the cheatsheet. Here it is in full: a &lt;- ggplot(seals, aes(x = long, y = lat)) b &lt;- ggplot(economics, aes(date, unemploy)) c &lt;- ggplot(mpg, aes(hwy)) d &lt;- ggplot(mpg, aes(fl)) e &lt;- ggplot(mpg, aes(cty, hwy)) f &lt;- ggplot(mpg, aes(class, hwy)) g &lt;- ggplot(diamonds, aes(cut, color)) h &lt;- ggplot(diamonds, aes(carat, price)) i &lt;- ggplot(economics, aes(date, unemploy)) df &lt;- data.frame(grp = c(&quot;A&quot;, &quot;B&quot;), fit = 4.5, se = 1:2) j &lt;- ggplot(df, aes(grp, fit, ymin = fit - se, ymax = fit + se)) data &lt;- data.frame(murder = USArrests$Murder, state = tolower(rownames(USArrests))) map &lt;- map_data(&quot;state&quot;) k &lt;- ggplot(data, aes(fill = murder)) seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2)) l &lt;- ggplot(seals, aes(long, lat)) s &lt;- ggplot(mpg, aes(fl, fill = drv)) t &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point() Notice that, in some places, the aesthetics are defined using the full aesthetic name-value pair (e.g., aes(x = long, y = lat)), while in other places the code relies on position for defining which column of a dataframe maps to which aesthetic (e.g., aes(cty, hwy) or aes(fl)). Either is fine, although relying on position can result in errors if you are not very familiar with the order in which parameters are defined for a function. This code will vary based on the examples you try, but here is some code for one set of examples: b + geom_ribbon(aes(ymin = unemploy - 900, ymax = unemploy + 900)) c + geom_dotplot() f + geom_violin(scale = &quot;area&quot;) h + geom_hex() j + geom_pointrange() k + geom_map(aes(map_id = state), map = map) + expand_limits(x = map$long, y = map$lat) l + geom_contour(aes(z = z)) n &lt;- d + geom_bar(aes(fill = fl)) n + scale_fill_brewer(palette = &quot;Blues&quot;) o &lt;- c + geom_dotplot(aes(fill = ..x..)) o + scale_fill_gradient(low = &quot;red&quot;, high = &quot;yellow&quot;) t + facet_grid(year ~ fl) s + geom_bar(position = &quot;fill&quot;) "],
["appendix-a-vocabulary.html", "A Appendix A: Vocabulary A.1 Quiz 1—R Preliminaries (Updated for 2018) A.2 Quiz 2—Entering / cleaning data #1 (Updated for 2018) A.3 Quiz 3 A.4 Quiz 4 A.5 Quiz 5 A.6 Quiz 6 A.7 Quiz 7 A.8 Quiz 8", " A Appendix A: Vocabulary You will be responsible for knowing the following functions and vocabulary for the weekly quizzes. A.1 Quiz 1—R Preliminaries (Updated for 2018) Grading policies for the course Course requirements / policies for in-class quizzes Open source software “free as in beer” versus “free as in speech” Difference between R and RStudio R packages CRAN Installing packages install.packages() Loading a package library() package::function() notation Types of package documentation: vignettes and helpfiles vignette(), option package = Accessing a function’s helpfile using ? R objects and object names “gets arrow”: &lt;- = vs. &lt;- for object assignment Rules and style guidelines for naming objects Tab completion ls() Vectors c() Two of the basic classes of vectors: character and numeric class() Square bracket indexing for vectors: [...] Dataframes data_frame() Square bracket indexing for dataframes: [..., ...] read_csv, option skip = str() summary() dim() ncol() nrow() Nate Silver FiveThirtyEight R session R scripts Working at the console versus working from an R script # comment character NA for missing values $ to get a column from a dataframe paste(), option sep = paste0() A.2 Quiz 2—Entering / cleaning data #1 (Updated for 2018) What kinds of data can be read into R? delimited files (csv, tsv) fixed width files delimiter read_delim, options delim =, skip =, n_max =, col_names = read_fwf read_csv, options skip =, n_max =, col_names = readxl package and its read_excel() function haven package and its read_sas() function NA Computer directory structure working directory getwd() list.files() relative pathnames absolute pathnames shorthand for pathnames: ., .., ../data, etc. Reading in data from either a local or online flat file paste(), option sep = paste0() How to read flat files of data that are online directly into R dplyr package rename() Why you might want to rename column names (e.g., uppercase, long, unusual characters) select() slice() mutate() filter() arrange(), including with desc() Main types of vector classes in R: character, numeric, factor, date, logical lubridate functions, include ymd, ymd_hm, mdy, wday, and mday %&gt;%, advantages of piping Common logical operators in R (==, !=, %in%, is.na(), &amp;, |) A.3 Quiz 3 The tidyverse data() (with and without the name of a dataset as an option) library() (with and without an argument in the parentheses) logical vectors, including running sum on a logical vector What the bang operator (!) does to a logical operator range() min() max() mean() median() table() cor(), both for two variables in a dataframe, and to get the correlation matrix for several variables in a dataframe summary(), as applied to: different classes of vectors (numeric, factor, logical) and dataframes What to do if you want to apply a summary statistic function to a vector with missing values (you do not need to know every option name for all the functions, just know that you would need to include an option like na.rm= or use=, and that you can use the help file for a function to figure out the option call for that function). The following about object-oriented programming: In R, it means that some functions, like summary(), will do different things depending on what type of object you call it on. summarize() Special functions to use with summarize(): n(), n_distinct(), first(), last() Using group_by() before using summarize() The three basic elements of a ggplot plot: data, aesthetics, and geoms aes function and common aesthetics, including color, shape, x, y, alpha, size, and fill Mapping an aesthetic to a column in the data versus setting it to a constant value Some common geoms: geom_histogram, geom_points, geom_lines, geom_boxplot() The difference between “statistical” geoms (e.g., geom_boxplot, geom_smooth) and “non-statistical” (e.g., geom_point, geom_line) Common additions to ggplot objects: ggtitle, labs, xlim, ylim, expand_limits A.4 Quiz 4 Guidelines for good graphics Data density / data-to-ink ratio Small multiples Edward Tufte Hadley Wickham Where to put the + in ggplot statements to avoid problems (ends of lines instead of starts of new lines) Can you save a ggplot object as an R object that you can reference later? If so, how would you add elements on to that object? How would you print it when you were ready to print the graph to your RStudio graphics window? geom_hline(), geom_vline() geom_text() facet_grid(), facet_wrap() grid.arrange() from the gridExtra package ggthemes package, including theme_few() and theme_tufte() Setting point color for geom_point() both as a constant (all points red) and as a way to show the level of a factor for each observation size, alpha, color Re-naming and re-ordering factors Note: If you read this and find and bring in an example of a “small multiples” graph (from a newspaper, a website, an academic paper), you can get one extra point on this quiz A.5 Quiz 5 Reproducible research, including what it is and advantages to aiming to make your research reproducible R style guidelines on variable names, &lt;- vs. =, line length, spacing, semicolons, commenting, indentation, and code grouping Markup languages (concept and examples) Basic conventions for Markdown (bold, italics, links, headers, lists) Literate programming What working directory R uses for code in an .Rmd document Basic syntax for RMarkdown chunks, including how to name them Options for RMarkdown chunks: echo, eval, messages, warnings, include, fig.width, fig.height, results Difference between global options and chunk options, and which takes precendence What inline code is and how to write it in RMarkdown How to set global options Why style is important in coding RPubs A.6 Quiz 6 Three characteristics of tidy data Five common problems with tidy data and how to resolve them (make sure you understand the examples shown, which you can find out more about in the Hadley Wickham paper I reference in the slides) group_by with mutate, slice, and arrange lag and lead with mutate separate and unite gather and spread The *_join family of functions (left_join, right_join, inner_join, full_join, anti_join, semi_join) A.7 Quiz 7 lists indexing from lists ([[ and $) exploring lists (class, names, str functions) Regression modeling with lm, glm Writing a formula with ~ syntax Using functions from broom to tidy model output (augment, tidy, glance) autoplot kable() from the knitr package How many objects a function can input. How many objects a function can output. if / else if / else structures inside functions Idea of error checking (e.g., with assertive package) A.8 Quiz 8 Regular expressions (the concept and which package you would use) nest and unnest (from purrr package) map family of functions basics of writing a function Mapping using ggplot2 framework with dataframes of geographical data (in the slides, “Point maps”) Choropleths, choroplethr map_data get_map ggmap "],
["appendix-b-homework.html", "B Appendix B: Homework B.1 Homework #1 (Updated for 2018) B.2 Homework #2 B.3 Homework #3 B.4 Homework #4 B.5 Homework #5 B.6 Homework #6", " B Appendix B: Homework The following are six homework assignments for the course. B.1 Homework #1 (Updated for 2018) Due date: Sept. 12 For your first homework assignment, you’ll be working through a few swirl lessons that are relevant to the material we’ve covered so far. Swirl is a platform that helps you learn R in R—you can complete the lessons right in your R console. Depending on your familiarity with R, you can either work through seven lessons of your choice in the R Programming: The basics of programming in R and Getting and Cleaning Data courses (suggested lessons are listed further below) (Option #1), or you can work through seven lessons of your choice taken from any number of swirl’s available courses (Option #2) . For each lesson completed, please write a few sentences that cover: 1. A summary of the topic(s) covered in that lesson, and 2. The most interesting thing that you learned from that lesson. Turn in a hardcopy of this (with your first and last name at the top) during class on the due date. To begin, you’ll first need to install the swirl package: install.packages(&quot;swirl&quot;) If you’ve never run swirl() before, you will be prompted to install a course. You can do that with the install_course function. For example, to install the R Programming course, you would run: library(swirl) install_course(&quot;R Programming&quot;) Once you’ve installed a course, every time you enter the swirl environment with swirl(), R Progamming should show up as a course option to select. You can enter R Programming to start lessons in that course by typing the number in fromt of it when you run swirl(). Once you have at least one course installed, you call the swirl() function to enter the interactive platform in RStudio. The console will take you through a few prompts: you’ll give swirl a name to call you, and take a look at some commands that are useful in the swirl environment. Those commands are listed further below. library(swirl) swirl() After calling swirl(), you may be prompted to clear your workspace variables by running rm=(list=ls()). Running this code will clear any variables you already have saved in your global environment. While swirl recommends that you do this, it’s not necessary. Some of these lessons complement online courses through Coursera, so sometimes you will be asked after you complete a lesson if you want to report your results to Coursera. You should select “No” for that option each time. B.1.1 Option 1 For Option 1 of this homework, you will need to work through seven of the 15 available lessons in the R Programming course. Here are some suggestions for particularly uesful lessons that you could choose (the lesson number within the course is in parentheses): R Programming course: Basic Building Blocks (1) Sequences of Numbers (3) Vectors (4) Missing Values (5) Subsetting Vectors (6) Logic (8) Looking at Data (12) Dates and Times (14) Getting and Cleaning Data course: Manipulating Data with dplyr (1) Grouping and Chaining with dplyr (2) Dates and Times with lubridate (4) Each lesson should take at most 10–15 minutes, but some are much shorter. You can complete the lessons in any order you want, but you may find it easiest to start with the lowest-numbered lessons and work your way up, in the order we’ve listed the lessons here. You’ll be able to get started on some of these lessons after your first day in class (“Basic Building Blocks”“, for example), but others cover topics that we’ll get to in weeks 2 and 3. Whether or not we’ve covered a swirl topic in class, you should be able to successfully work through the lesson. At the end of each lesson, you may be asked if you would like to receive credit for completing this course on Coursera.org. Type 2 for no. Again, you’ll need to compose and turn in a few sentences for each lesson. Make sure to include a summary of what each lesson was about, and the most interesting thing about that lesson. B.1.2 Option 2 If you’re already somewhat familiar with R, you might want to choose your seven lessons from other swirl courses instead of or in addition to those available in the R Programming and Getting and Cleaning Data courses. Check out the list of available Swirl Courses to see which ones you would like to install and check out available lessons for. For example, to choose a lesson in the Exploratory Data Analysis course, you would run: library(swirl) install_course(&quot;Exploratory Data Analysis&quot;) swirl() After entering the Exploratory Data Analysis course, you could choose from any one of its available lessons. In your written summary for each lesson (again, a few sentences that cover a summary of the lesson and the most interesting thing you learned), make sure to specify which course each lesson you completed was from. B.1.3 Special swirl commands In the swirl environment, knowing about the following commands will be helpful: Within each lesson, the prompt ... indicates that you should hit Enter to move on to the next section. skip(): skip the current question. play(): temporarily exit swirl. It can be useful during a swirl lesson to play around in the R console to try things out. nxt(): regain swirl’s attention after play()ing around in the console. main(): return to swirl’s main menu. bye(): exit swirl. Swirl will save your progress if you exit in the middle of a lesson. You can also hit the Esc. key to exit. (To re-enter swirl, run swirl(). In a new R session you will have to first load the swirl library: library(swirl).) B.1.3.1 For fun While they aren’t required for class, you should consider trying out some other swirl lessons later in the course. You can look through the course directory to see what other courses and lessons are available. For the first part of our course, you might find the “Exploratory Data Analysis” course helpful. If you would like to learn more about using R for statistical analysis, you might find the “Regression Models” course helpful. B.2 Homework #2 Due date: Sept. 27 For Homework 2, recreate the R Markdown document that you can download from here. Here are some initial instructions and tips: Your goal is to create an R Markdown document that you can compile to create a Word document that looks just like the example document we’ve linked above. You will turn in (by email) both the compiled Word document and the .Rmd original file. Add your name as “Author” and the due date of the assignment as “Date”. You should add these within the R Markdown document, rather than changing them in the final, compiled Word document. If you want to get started before you know how to use R Markdown, you can go ahead and write all of the necessary code to replicate the output and figures in the document in an R script. The code chunks here have been hidden with the option echo = FALSE, but you should include your code in your final document. Set the chunk options warning = FALSE and message = FALSE to prevent warnings and messages from being printed out. You will get some messages and warnings in the code from things like missing values and from loading packages, but you want to hide all of those messages in your final document. For things like templates, colors, level of transparency, and point size, you will receive full credit if you create figures that are visually similar to the ones shown in the example document. In other words, if the example document shows some transparency in points, you will get full credit if you also include some transparency in the points in your plot, but you do not have to include the exact same value of alpha. Pay close attention to the typeface used in text of the original document. If something is shown in boldface or “typewriter” fontface in the original, make sure you’ve written your Rmarkdown code to have the same type. In R, there are often many different ways to achieve something. As long as your code works, it’s fine if you haven’t coded it exactly like we have in our version. However, your output should look identical to ours (or, in the case of color, transparency, point size, and themes, visually similar). You will not lose points if you cannot recreate the table in the document (although you should try to!). The last section, under the heading “Extra challenge– not graded”, is not graded. However, if you’d like an extra challenge, you’re welcome to try it out and include it in your final submission! If you need them, here are some further tips: You will learn Rmarkdown in Week 5 of the course. However, if you want to get started on this exercise before you learn how to use Rmarkdown, you can start by working on the regular R code to read in the data and create the figures shown in the document. Functions from the tidyverse (especially from dplyr, readr, and ggplot packages) will make your life much easier for this exercise. You can now install and load the tidyverse package to load them all at once. To rename column names with “special” characters in them, wrap the whole old column name in backticks. For example, to change a column name that has a dollar sign in it, you would use something like “rename(new_col_name = `old_col_name$`)”. To change the size of a figure in a report, use the “fig.width” and “fig.height” chunk options. You will want to use scale_fill_brewer in several of the figures. Don’t forget that, within functions like scale_x_continuous, you can use the argument breaks to set where the axis has breaks, and then labels to set what will actually be shown at each break. The string “\\n” can be included in legends and labels to include a carriage return. Coordinates can be flipped in a graph with the coord_flip geom. So, if you can figure out a way to make a graph with the coordinates flipped, use that code and just add coord_flip at the end. B.3 Homework #3 Due date: Oct. 11 For Homework 3, recreate the R Markdown document that you can download from here. Here are some initial tips: Your goal is to create an R Markdown document that you can compile to create a Word document that looks just like the target document we’ve linked above. The only difference is that you will use echo = TRUE to show your code within the rendered Word document. All formating within the text should be similar or identical to the target document. You will turn in (by email) both the compiled Word document and the .Rmd original file. Add your name as “Author” and the due date of the assignment as “Date”. You should add these within the R Markdown document, rather than changing them in the final, compiled Word document. Set the chunk options warning = FALSE and message = FALSE to prevent warnings and messages from being printed out. You will get some messages and warnings in the code from things like missing values and from loading packages, but you want to hide all of those messages in your final document. For things like templates, colors, level of transparency, and point size, you will receive full credit if you create figures that are visually similar to the ones shown in the example document. In other words, if the example document shows some transparency in points, you will get full credit if you also include some transparency in the points in your plot, but you do not have to include the exact same value of alpha. In R, there are often many different ways to achieve something. As long as your code works, it’s fine if you haven’t coded it exactly like we have in our version. However, your output should look identical to ours (or, in the case of color, transparency, point size, and themes, visually similar). There is one formated table in the target document. Be sure that you render this as a formated table, not as raw R output. You will be graded on whether the size of each figure is similar to that in the example file. There is a tip in the “Further tips” section below about how to change figure size in the output. If you need them, here are some further tips: Functions from the tidyverse (especially from dplyr, readr, and ggplot packages) will make your life much easier for this exercise. To reference column names with “special” characters in them, like dollar signs or spaces, wrap the whole old column name in backticks. For example, to change a column name that has a dollar sign in it, you would use something like “rename(new_col_name = `old_col_name$`)”. To change the size of a figure in a report, use the “fig.width” and “fig.height” chunk options. B.4 Homework #4 Optional due date: Oct. 25 All instructions for this homework can be downloaded here. The example “fars_analysis.pdf” document you will try to recreate is here. You have the option to turn in parts of this homework (up through creating a clean dataset) by Oct. 28. If you do so, I will email you the code I used to clean the data, so you can check your own code and be sure you have a reasonable version of the clean data as you do the final parts of the assignment. B.5 Homework #5 Due date: Nov. 8 All instructions for this homework can be downloaded here. The example “fars_analysis.pdf” document you will try to recreate is here. You will submit this homework by posting a repo with your project directory on GitHub. We will work on setting that up during an in-course exercise. B.6 Homework #6 Due date: Nov. 29 Read the article Good Enough Practices in Scientific Computing by Wilson et al. (available here). In a half page, describe which of these “pretty good practices” your last homework incorporated. Also list one or two practices that you did not follow in your last homework but that would have made sense and how you could have followed them. Read the article Science Isn’t Broken on FiveThirtyEight. This article includes an interactive graphic. In a half page, give your opinion on whether this interactive graphic helps convey the main message of the article. Also, describe in general details how you might be able to create a graphic like this in R. Find an article in The R Journal that describes an R package that you could use in your own research or otherwise find interesting. Describe why the package was created and what you think it’s most interesting features are. In an R Markdown document, run one or two of the R examples included in the article. "]
]
